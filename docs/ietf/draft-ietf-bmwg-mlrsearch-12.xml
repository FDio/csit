<?xml version="1.0" encoding="us-ascii"?>
  <?xml-stylesheet type="text/xsl" href="rfc2629.xslt" ?>
  <!-- generated by https://github.com/cabo/kramdown-rfc version 1.7.29 (Ruby 3.1.2) -->


<!DOCTYPE rfc  [
  <!ENTITY nbsp    "&#160;">
  <!ENTITY zwsp   "&#8203;">
  <!ENTITY nbhy   "&#8209;">
  <!ENTITY wj     "&#8288;">

<!ENTITY RFC1242 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.1242.xml">
<!ENTITY RFC2119 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.2119.xml">
<!ENTITY RFC2285 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.2285.xml">
<!ENTITY RFC2544 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.2544.xml">
<!ENTITY RFC8174 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.8174.xml">
<!ENTITY RFC5180 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.5180.xml">
<!ENTITY RFC6349 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.6349.xml">
<!ENTITY RFC6985 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.6985.xml">
<!ENTITY RFC8219 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.8219.xml">
]>


<rfc ipr="trust200902" docName="draft-ietf-bmwg-mlrsearch-12" category="info" submissionType="IETF" tocInclude="true" sortRefs="true" symRefs="true">
  <front>
    <title abbrev="MLRsearch">Multiple Loss Ratio Search</title>

    <author initials="M." surname="Konstantynowicz" fullname="Maciek Konstantynowicz">
      <organization>Cisco Systems</organization>
      <address>
        <email>mkonstan@cisco.com</email>
      </address>
    </author>
    <author initials="V." surname="Polak" fullname="Vratko Polak">
      <organization>Cisco Systems</organization>
      <address>
        <email>vrpolak@cisco.com</email>
      </address>
    </author>

    <date year="2025" month="September" day="04"/>

    <area>ops</area>
    <workgroup>Benchmarking Working Group</workgroup>
    <keyword>Internet-Draft</keyword>

    <abstract>


<?line 72?>

<t>This document specifies extensions to &quot;Benchmarking Methodology for
Network Interconnect Devices&quot; (RFC 2544) throughput search by
defining a new methodology called Multiple Loss Ratio search
(MLRsearch). MLRsearch aims to minimize search duration,
support multiple loss ratio searches, and improve result repeatability
and comparability.</t>

<t>MLRsearch is motivated by the pressing need to address the challenges of
evaluating and testing the various data plane solutions, especially in
software-based networking systems based on Commercial Off-the-Shelf
(COTS) CPU hardware vs purpose-built ASIC / NPU / FPGA hardware.</t>



    </abstract>



  </front>

  <middle>


<?line 86?>


<section anchor="introduction"><name>Introduction</name>

<t>This document describes the Multiple Loss Ratio search
(MLRsearch) methodology, optimized for determining data plane
throughput in software-based networking functions running on commodity systems with
x86/ARM CPUs (vs purpose-built ASIC / NPU / FPGA). Such network
functions can be deployed on dedicated physical appliance (e.g., a
standalone hardware device) or as virtual appliance (e.g., Virtual
Network Function running on shared servers in the compute cloud).</t>

<section anchor="purpose"><name>Purpose</name>

<t>The purpose of this document is to describe the Multiple Loss Ratio search
(MLRsearch) methodology, optimized for determining
data plane throughput in software-based networking devices and functions.</t>

<t>Applying the vanilla throughput binary search,
as specified for example in <xref target="TST009"></xref> and <xref target="RFC2544"></xref>
to software devices under test (DUTs) results in several problems:</t>

<t><list style="symbols">
  <t>Binary search takes long as most trials are done far from the
eventually found throughput.</t>
  <t>The required final trial duration and pauses between trials
prolong the overall search duration.</t>
  <t>Software DUTs show noisy trial results,
leading to a big spread of possible discovered throughput values.</t>
  <t>Throughput requires a loss of exactly zero frames, but the industry best practices
frequently allow for low but non-zero losses tolerance (<xref target="Y.1564"></xref>, test-equipment manuals).</t>
  <t>The definition of throughput is not clear when trial results are inconsistent.
(e.g., when successive trials at the same - or even a higher - offered
load yield different loss ratios, the classical <xref target="RFC1242"></xref> / <xref target="RFC2544"></xref>
throughput metric can no longer be pinned to a single, unambiguous
value.)</t>
</list></t>

<t>To address these problems,
early MLRsearch implementations employed the following enhancements:</t>

<t><list style="numbers" type="1">
  <t>Allow multiple short trials instead of one big trial per load.
  <list style="symbols">
      <t>Optionally, tolerate a percentage of trial results with higher loss.</t>
    </list></t>
  <t>Allow searching for multiple Search Goals, with differing loss ratios.
  <list style="symbols">
      <t>Any trial result can affect each Search Goal in principle.</t>
    </list></t>
  <t>Insert multiple coarse targets for each Search Goal, earlier ones need
to spend less time on trials.
  <list style="symbols">
      <t>Earlier targets also aim for lesser precision.</t>
      <t>Use Forwarding Rate (FR) at Maximum Offered Load (FRMOL), as defined
in Section 3.6.2 of <xref target="RFC2285"></xref>, to initialize bounds.</t>
    </list></t>
  <t>Be careful when dealing with inconsistent trial results.
  <list style="symbols">
      <t>Reported throughput is smaller than the smallest load with high loss.</t>
      <t>Smaller load candidates are measured first.</t>
    </list></t>
  <t>Apply several time-saving load selection heuristics that deliberately
prevent the bounds from narrowing unnecessarily.</t>
</list></t>

<t>Enhancements 1, 2 and partly 4 are formalized as MLRsearch Specification
within this document, other implementation details are out the scope.</t>

<t>The remaining enhancements are treated as implementation details,
thus achieving high comparability without limiting future improvements.</t>

<t>MLRsearch configuration
supports both conservative settings and aggressive settings.
Conservative enough settings lead to results
unconditionally compliant with <xref target="RFC2544"></xref>,
but without much improvement on search duration and repeatability - see
<xref target="mlrsearch-compliant-with-rfc-2544">MLRsearch Compliant with RFC 2544</xref>.
Conversely, aggressive settings lead to shorter search durations
and better repeatability, but the results are not compliant with <xref target="RFC2544"></xref>.
Exact settings are not specified, but see the discussion in
<xref target="overview-of-rfc-2544-problems">Overview of RFC 2544 Problems</xref>
for the impact of different settings on result quality.</t>

<t>This document does not change or obsolete any part of <xref target="RFC2544"></xref>.</t>

</section>
<section anchor="positioning-within-bmwg-methodologies"><name>Positioning within BMWG Methodologies</name>

<t>The Benchmarking Methodology Working Group (BMWG) produces recommendations (RFCs)
that describe various benchmarking methodologies for use in a controlled laboratory environment.
A large number of these benchmarks are based on the terminology from <xref target="RFC1242"></xref>
and the foundational methodology from <xref target="RFC2544"></xref>.
A common pattern has emerged where BMWG documents reference the methodology of <xref target="RFC2544"></xref>
and augment it with specific requirements for testing particular network systems or protocols,
without modifying the core benchmark definitions.</t>

<t>While BMWG documents are formally recommendations,
they are widely treated as industry norms to ensure the comparability of results between different labs.
The set of benchmarks defined in <xref target="RFC2544"></xref>, in particular,
became a de facto standard for performance testing.
In this context, the MLRsearch Specification formally defines a new
class of benchmarks that fits within the wider <xref target="RFC2544"></xref> framework
(see <xref target="scope">Scope </xref>).</t>

<t>A primary consideration in the design of MLRsearch is the trade-off
between configurability and comparability. The methodology&#39;s flexibility,
especially the ability to define various sets of Search Goals,
supporting both single-goal and multiple-goal benchmarks in an unified way
is powerful for detailed characterization and internal testing.
However, this same flexibility is detrimental to inter-lab comparability
unless a specific, common set of Search Goals is agreed upon.</t>

<t>Therefore, MLRsearch should not be seen as a direct extension
nor a replacement for the <xref target="RFC2544"></xref> Throughput benchmark.
Instead, this document provides a foundational methodology
that future BMWG documents can use to define new, specific, and comparable benchmarks
by mandating particular Search Goal configurations.
For operators of existing test procedures, it is worth noting
that many test setups measuring <xref target="RFC2544"></xref> Throughput
can be adapted to produce results compliant with the MLRsearch Specification,
often without affecting Trials,
merely by augmenting the content of the final test report.</t>

</section>
</section>
<section anchor="overview-of-rfc-2544-problems"><name>Overview of RFC 2544 Problems</name>

<t>This section describes the problems affecting usability
of various performance testing methodologies,
mainly a binary search for <xref target="RFC2544"></xref> unconditionally compliant throughput.</t>

<section anchor="long-search-duration"><name>Long Search Duration</name>

<t>The proliferation of software DUTs, with frequent software updates
and a number of different frame processing modes and configurations,
has increased both the number of performance tests
required to verify the DUT update and the frequency of running those tests.
This makes the overall test execution time even more important than before.</t>

<t>The throughput definition per <xref target="RFC2544"></xref> restricts the potential
for time-efficiency improvements.
The bisection method, when used in a manner unconditionally compliant
with <xref target="RFC2544"></xref>, is excessively slow due to two main factors.</t>

<t>Firstly, a significant amount of time is spent on trials
with loads that, in retrospect, are far from the final determined throughput.</t>

<t>Secondly, <xref target="RFC2544"></xref> does not specify any stopping condition for
throughput search, so users of testing equipment implementing the
procedure already have access to a limited trade-off
between search duration and achieved precision.
However, each of the full 60-second trials doubles the precision.</t>

<t>As such, not many trials can be removed without a substantial loss of precision.</t>

<t>For reference, here is a brief <xref target="RFC2544"></xref> throughput binary
(bisection) reminder, based on Sections 24 and 26 of [RFC2544:</t>

<t><list style="symbols">
  <t>Set Max = line-rate and Min = a proven loss-free load.</t>
  <t>Run a single 60-s trial at the midpoint.</t>
  <t>Zero-loss -&gt; midpoint becomes new Min; any loss-&gt; new Max.</t>
  <t>Repeat until the Max-Min gap meets the desired precision, then report
the highest zero-loss rate for every mandatory frame size.</t>
</list></t>

</section>
<section anchor="dut-in-sut"><name>DUT in SUT</name>

<t><xref target="RFC2285"></xref> defines:</t>

<t>DUT as:</t>

<t><list style="symbols">
  <t>The network frame forwarding device to which stimulus is offered and
response measured Section 3.1.1 of <xref target="RFC2285"></xref>.</t>
</list></t>

<t>SUT as:</t>

<t><list style="symbols">
  <t>The collective set of network devices as a single entity to which
stimulus is offered and response measured Section 3.1.2 of <xref target="RFC2285"></xref>.</t>
</list></t>

<t>Section 19 of <xref target="RFC2544"></xref> specifies a test setup with an external tester
stimulating the networking system, treating it either as a single
Device Under Test (DUT), or as a system of devices, a System Under
Test (SUT).</t>

<t>For software-based data-plane forwarding running on commodity x86/ARM
CPUs, the SUT comprises not only the forwarding application itself, the
DUT, but the entire execution environment: host hardware, firmware and
kernel/hypervisor services, as well as any other software workloads
that share the same CPUs, memory and I/O resources.</t>

<t>Given that a SUT is a shared multi-tenant environment,
the DUT might inadvertently
experience interference from the operating system
or from other software operating on the same server.</t>

<t>Some of this interference can be mitigated.
For instance, in multi-core CPU systems, pinning DUT program threads to
specific CPU cores
and isolating those cores can prevent context switching.</t>

<t>Despite taking all feasible precautions, some adverse effects may still impact
the DUT&#39;s network performance.
In this document, these effects are collectively
referred to as SUT noise, even if the effects are not as unpredictable
as what other engineering disciplines call noise.</t>

<t>A DUT can also exhibit fluctuating performance itself,
for reasons not related to the rest of SUT. For example, this can be
due to pauses in execution as needed for internal stateful processing.
In many cases this may be an expected per-design behavior,
as it would be observable even in a hypothetical scenario
where all sources of SUT noise are eliminated.
Such behavior affects trial results in a way similar to SUT noise.
As the two phenomena are hard to distinguish,
in this document the term &#39;noise&#39; is used to encompass
both the internal performance fluctuations of the DUT
and the genuine noise of the SUT.</t>

<t>A simple model of SUT performance consists of an idealized noiseless performance,
and additional noise effects.
For a specific SUT, the noiseless performance is assumed to be constant,
with all observed performance variations being attributed to noise.
The impact of the noise can vary in time, sometimes wildly,
even within a single trial.
The noise can sometimes be negligible, but frequently
it lowers the observed SUT performance as observed in trial results.</t>

<t>In this simple model, a SUT does not have a single performance value, it has a spectrum.
One end of the spectrum is the idealized noiseless performance value,
the other end can be called a noiseful performance.
In practice, trial results close to the noiseful end of the spectrum
happen only rarely.
The worse a possible performance value is, the more rarely it is seen in a trial.
Therefore, the extreme noiseful end of the SUT spectrum is not observable
among trial results.</t>

<t>Furthermore, the extreme noiseless end of the SUT spectrum is unlikely
to be observable, this time because minor noise events almost always
occur during each trial, nudging the measured performance slightly
below the theoretical maximum.</t>

<t>Unless specified otherwise, this document&#39;s focus is
on the potentially observable ends of the SUT performance spectrum,
as opposed to the extreme ones.</t>

<t>When focusing on the DUT, the benchmarking effort should ideally aim
to eliminate only the SUT noise from SUT measurements.
However, this is currently not feasible in practice,
as there are no realistic enough models that would be capable
to distinguish SUT noise from DUT fluctuations
(based on the available literature at the time of writing).</t>

<t>Provided SUT execution environment and any co-resident workloads place
only negligible demands on SUT shared resources, so that
the DUT remains the principal performance limiter,
the DUT&#39;s ideal noiseless performance is defined
as the noiseless end of the SUT performance spectrum.</t>

<t>Note that by this definition, DUT noiseless performance
also minimizes the impact of DUT fluctuations, as much as realistically possible
for a given trial duration.</t>

<t>The MLRsearch methodology aims to solve the DUT in SUT problem
by estimating the noiseless end of the SUT performance spectrum
using a limited number of trial results.</t>

<t>Improvements to the throughput search algorithm, aimed at better dealing
with software networking SUT and DUT setups, should adopt methods that
explicitly model SUT-generated noise, enabling to derive surrogate
metrics that approximate the (proxies for) DUT noiseless performance
across a range of SUT noise-tolerance levels.</t>

</section>
<section anchor="repeatability-and-comparability"><name>Repeatability and Comparability</name>

<t><xref target="RFC2544"></xref> does not suggest repeating throughput search. Also, note that
from simply one discovered throughput value,
it cannot be determined how repeatable that value is.
Unsatisfactory repeatability then leads to unacceptable comparability,
as different benchmarking teams may obtain varying throughput values
for the same SUT, exceeding the expected differences from search precision.
Repeatability is important also when the test procedure is kept the same,
but SUT is varied in small ways. For example, during development
of software-based DUTs, repeatability is needed to detect small regressions.</t>

<t><xref target="RFC2544"></xref> throughput requirements (60 seconds trial and
no tolerance of a single frame loss) affect the throughput result as follows:</t>

<t>The SUT behavior close to the noiseful end of its performance spectrum
consists of rare occasions of significantly low performance,
but the long trial duration makes those occasions not so rare on the trial level.
Therefore, the binary search results tend to spread away from the noiseless end
of SUT performance spectrum, more frequently and more widely than shorter
trials would, thus causing unacceptable throughput repeatability.</t>

<t>The repeatability problem can be better addressed by defining a search procedure
that identifies a consistent level of performance,
even if it does not meet the strict definition of throughput in <xref target="RFC2544"></xref>.</t>

<t>According to the SUT performance spectrum model, better repeatability
will be at the noiseless end of the spectrum.
Therefore, solutions to the DUT in SUT problem
will help also with the repeatability problem.</t>

<t>Conversely, any alteration to <xref target="RFC2544"></xref> throughput search
that improves repeatability should be considered
as less dependent on the SUT noise.</t>

<t>An alternative option is to simply run a search multiple times, and
report some statistics (e.g., average and standard deviation, and/or
percentiles like p95).</t>

<t>This can be used for a subset of tests deemed more important,
but it makes the search duration problem even more pronounced.</t>

</section>
<section anchor="throughput-with-non-zero-loss"><name>Throughput with Non-Zero Loss</name>

<dl>
  <dt>Section 3.17 of <xref target="RFC1242"></xref> defines throughput as:</dt>
  <dd>
    <t>The maximum rate at which none of the offered frames
are dropped by the device.</t>
  </dd>
  <dt>Then, it says:</dt>
  <dd>
    <t>Since even the loss of one frame in a
data stream can cause significant delays while
waiting for the higher-level protocols to time out,
it is useful to know the actual maximum data
rate that the device can support.</t>
  </dd>
</dl>

<t>However, many benchmarking teams accept a low,
non-zero loss ratio as the goal for their load search.</t>

<t>Motivations are many:</t>

<t><list style="symbols">
  <t>Networking protocols tolerate frame loss better,
compared to the time when <xref target="RFC1242"></xref> and <xref target="RFC2544"></xref> were specified.</t>
  <t>Increased link speeds require trials sending more frames within the same duration,
increasing the chance of a small SUT performance fluctuation
being enough to cause frame loss.</t>
  <t>Because noise-related drops usually arrive in small bursts, their
impact on the trial&#39;s overall frame loss ratio is diluted by the
longer intervals in which the SUT operates close to its noiseless
performance; consequently, the averaged Trial Loss Ratio can still
end up below the specified Goal Loss Ratio value.</t>
  <t>If an approximation of the SUT noise impact on the Trial Loss Ratio is known,
it can be set as the Goal Loss Ratio (see definitions of
Trial and Goal terms in <xref target="trial-terms">Trial Terms</xref> and <xref target="goal-terms">Goal Terms</xref>).</t>
  <t>For more information, see an earlier draft <xref target="Lencze-Shima"></xref> (Section 5)
and references there.</t>
</list></t>

<t>Regardless of the validity of all similar motivations,
support for non-zero loss goals makes a
search algorithm more user-friendly.
<xref target="RFC2544"></xref> throughput is not user-friendly in this regard.</t>

<t>Furthermore, allowing users to specify multiple loss ratio values,
and enabling a single search to find all relevant bounds,
significantly enhances the usefulness of the search algorithm.</t>

<t>Searching for multiple Search Goals also helps to describe the SUT performance
spectrum better than the result of a single Search Goal.
For example, the repeated wide gap between zero and non-zero loss loads
indicates the noise has a large impact on the observed performance,
which is not evident from a single goal load search procedure result.</t>

<t>It is easy to modify the vanilla bisection to find a lower bound
for the load that satisfies a non-zero Goal Loss Ratio.
But it is not that obvious how to search for multiple goals at once,
hence the support for multiple Search Goals remains a problem.</t>

<t>At the time of writing there does not seem to be a consensus in the industry
on which ratio value is the best.
For users, performance of higher protocol layers is important, for
example, goodput of TCP connection (TCP throughput, <xref target="RFC6349"></xref>), but relationship
between goodput and loss ratio is not simple. Refer to
<xref target="Lencze-Kovacs-Shima"></xref> for examples of various corner cases,
Section 3 of <xref target="RFC6349"></xref> for loss ratios acceptable for an accurate
measurement of TCP throughput, and <xref target="Ott-Mathis-Semke-Mahdavi"></xref> for
models and calculations of TCP performance in presence of packet loss.</t>

</section>
<section anchor="inconsistent-trial-results"><name>Inconsistent Trial Results</name>

<t>While performing throughput search by executing a sequence of
measurement trials, there is a risk of encountering inconsistencies
between trial results.</t>

<t>Examples include, but are not limited to:</t>

<t><list style="symbols">
  <t>A trial at the same load (same or different trial duration) results
in a different Trial Loss Ratio.</t>
  <t>A trial at a larger load (same or different trial duration) results
in a lower Trial Loss Ratio.</t>
</list></t>

<t>The plain bisection never encounters inconsistent trials.
But <xref target="RFC2544"></xref> hints about the possibility of inconsistent trial results,
in two places in its text.
The first place is Section 24 of <xref target="RFC2544"></xref>,
where full trial durations are required,
presumably because they can be inconsistent with the results
from short trial durations.
The second place is Section 26.3 of <xref target="RFC2544"></xref>,
where two successive zero-loss trials
are recommended, presumably because after one zero-loss trial
there can be a subsequent inconsistent non-zero-loss trial.</t>

<t>A robust throughput search algorithm needs to decide how to continue
the search in the presence of such inconsistencies.
Definitions of throughput in <xref target="RFC1242"></xref> and <xref target="RFC2544"></xref> are not specific enough
to imply a unique way of handling such inconsistencies.</t>

<t>Ideally, there will be a definition of a new quantity which both generalizes
throughput for non-zero Goal Loss Ratio values
(and other possible repeatability enhancements), while being precise enough
to force a specific way to resolve trial result inconsistencies.
But until such a definition is agreed upon, the correct way to handle
inconsistent trial results remains an open problem.</t>

<t>Relevant Lower Bound is the MLRsearch term that addresses this problem.</t>

</section>
</section>
<section anchor="requirements-language"><name>Requirements Language</name>

<t>The key words &quot;MUST&quot;, &quot;MUST NOT&quot;, &quot;REQUIRED&quot;, &quot;SHALL&quot;, &quot;SHALL NOT&quot;, &quot;SHOULD&quot;,
&quot;SHOULD NOT&quot;, &quot;RECOMMENDED&quot;, &quot;NOT RECOMMENDED&quot;, &quot;MAY&quot;, and &quot;OPTIONAL&quot;
in this document are to be interpreted as described in BCP 14, <xref target="RFC2119"></xref>
and <xref target="RFC8174"></xref> when, and only when, they appear in all capitals, as shown here.</t>

<t>This document is categorized as an Informational RFC.
While it does not mandate the adoption of the MLRsearch methodology,
it uses the normative language of BCP 14 to provide an unambiguous specification.
This ensures that if a test procedure or test report claims compliance with the MLRsearch Specification,
it MUST adhere to all the absolute requirements defined herein.
The use of normative language is intended to promote repeatable and comparable results
among those who choose to implement this methodology.</t>

</section>
<section anchor="mlrsearch-specification"><name>MLRsearch Specification</name>

<t>This chapter provides all technical definitions
needed for evaluating whether a particular test procedure
complies with MLRsearch Specification.</t>

<t>Some terms used in the specification are capitalized.
It is just a stylistic choice for this document,
reminding the reader this term is introduced, defined or explained
elsewhere in the document. Lower case variants are equally valid.</t>

<t>This document does not separate terminology from methodology. Terms are
fully specified and discussed in their own subsections, under sections
titled &quot;Terms&quot;. This way, the list of terms is visible in table of
contents.</t>

<t>Each per term subsection contains a short <em>Definition</em> paragraph
containing a minimal definition and all strict requirements, followed
by <em>Discussion</em> paragraphs focusing on important consequences and
recommendations. Requirements about how other components can use the
defined quantity are also included in the discussion.</t>

<section anchor="scope"><name>Scope</name>

<t>This document specifies the Multiple Loss Ratio search (MLRsearch) methodology.
The MLRsearch Specification details a new class of benchmarks
by listing all terminology definitions and methodology requirements.
The definitions support &quot;multi-goal&quot; benchmarks, with &quot;single-goal&quot; as a subset.</t>

<t>The normative scope of this specification includes:</t>

<t><list style="symbols">
  <t>The terminology for all required quantities and their attributes.</t>
  <t>An abstract architecture consisting of functional components
(Manager, Controller, Measurer) and the requirements for their inputs and outputs.</t>
  <t>The required structure and attributes of the Controller Input,
including one or more Search Goal instances.</t>
  <t>The required logic for Load Classification, which determines whether a given Trial Load
qualifies as a Lower Bound or an Upper Bound for a Search Goal.</t>
  <t>The required structure and attributes of the Controller Output,
including a Goal Result for each Search Goal.</t>
</list></t>

<section anchor="relationship-to-rfc-2544"><name>Relationship to RFC 2544</name>

<t>MLRsearch Specification is an independent methodology
and does not change or obsolete any part of <xref target="RFC2544"></xref>.</t>

<t>This specification permits deviations from the Trial procedure
as described in <xref target="RFC2544"></xref>. Any deviation from the <xref target="RFC2544"></xref> procedure
must be documented explicitly in the Test Report,
and such variations remain outside the scope of the original <xref target="RFC2544"></xref> benchmarks.</t>

<t>A specific single-goal MLRsearch benchmark can be configured
to be compliant with <xref target="RFC2544"></xref> Throughput,
and most procedures reporting <xref target="RFC2544"></xref> Throughput
can be adapted to satisfy also MLRsearch requirements for specific search goal.</t>

</section>
<section anchor="applicability-of-other-specifications"><name>Applicability of Other Specifications</name>

<t>Methodology extensions from other BMWG documents that specify details
for testing particular DUTs, configurations, or protocols
(e.g., by defining a particular Traffic Profile) are considered orthogonal
to MLRsearch and are applicable to a benchmark conducted using MLRsearch methodology.</t>

</section>
<section anchor="out-of-scope"><name>Out of Scope</name>

<t>The following aspects are explicitly out of the normative scope of this document:</t>

<t><list style="symbols">
  <t>This specification does not mandate or recommend any single,
universal Search Goal configuration for all use cases.
The selection of Search Goal parameters is left
to the operator of the test procedure or may be defined by future specifications.</t>
  <t>The internal heuristics or algorithms used by the Controller to select Trial Input values
(e.g., the load selection strategy) are considered implementation details.</t>
  <t>The potential for, and the effects of, interference between different Search Goal instances
within a multiple-goal search are considered outside the normative scope of this specification.</t>
</list></t>

</section>
</section>
<section anchor="architecture-overview"><name>Architecture Overview</name>

<t>Although the normative text references only terminology that has already
been introduced, explanatory passages beside it sometimes profit from
terms that are defined later in the document. To keep the initial
read-through clear, this informative section offers a concise, top-down
sketch of the complete MLRsearch architecture.</t>

<t>The architecture is modelled as a set of abstract, interacting
components. Information exchange between components is expressed in an
imperative-programming style: one component &quot;calls&quot; another, supplying
inputs (arguments) and receiving outputs (return values). This notation
is purely conceptual; actual implementations need not exchange explicit
messages. When the text contrasts alternative behaviours, it refers to
the different implementations of the same component.</t>

<t>A test procedure is considered compliant with the MLRsearch
Specification if it can be conceptually decomposed into the abstract
components defined herein, and each component satisfies the
requirements defined for its corresponding MLRsearch element.</t>

<t>The Measurer component is tasked to perform Trials,
the Controller component is tasked to select Trial Durations and Loads,
the Manager component is tasked to pre-configure involved entities
and to produce the Test Report.
The Test Report explicitly states Search Goals (as Controller Input)
and corresponding Goal Results (Controller Output).</t>

<t>This constitutes one benchmark (single-goal or multi-goal).
Repeated or slightly differing benchmarks are realized
by calling Controller once for each benchmark.</t>

<t>The Manager calls a Controller once,
and the Controller then invokes the Measurer repeatedly
until Controller decides it has enough information to return outputs.</t>

<t>The part during which the Controller invokes the Measurer is termed the
Search. Any work the Manager performs either before invoking the
Controller or after Controller returns, falls outside the scope of the
Search.</t>

<t>MLRsearch Specification prescribes Regular Search Results and recommends
corresponding search completion conditions.</t>

<t>Irregular Search Results are also allowed,
they have different requirements and their corresponding stopping conditions are out of scope.</t>

<t>Search Results are based on Load Classification. When measured enough,
a chosen Load can either achieve or fail each Search Goal
(separately), thus becoming a Lower Bound or an Upper Bound for that
Search Goal.</t>

<t>When the Relevant Lower Bound is close enough to Relevant Upper Bound
according to Goal Width, the Regular Goal Result is found.
Search stops when all Regular Goal Results are found,
or when some Search Goals are proven to have only Irregular Goal Results.</t>

<section anchor="test-report"><name>Test Report</name>

<t>A primary responsibility of the Manager is to produce a Test Report,
which serves as the final and formal output of the test procedure.</t>

<t>This document does not provide a single, complete, normative definition
for the structure of the Test Report. For example, Test Report may contain
results for a single benchmark, or it could aggregate results of many benchmarks.</t>

<t>Instead, normative requirements for the content of the Test Report
are specified throughout this document in conjunction
with the definitions of the quantities and procedures to which they apply.
Readers should note that any clause requiring a value to be &quot;reported&quot;
or &quot;stated in the test report&quot; constitutes a normative requirement
on the content of this final artifact.</t>

<t>Even where not stated explicitly, the &quot;Reporting format&quot;
paragraphs in <xref target="RFC2544"></xref> sections are still requirements on Test Report
if they apply to a MLRsearch benchmark.</t>

</section>
<section anchor="behavior-correctness"><name>Behavior Correctness</name>

<t>MLRsearch Specification by itself does not guarantee that
the Search ends in finite time, as the freedom the Controller has
for Load selection also allows for clearly deficient choices.</t>

<t>For deeper insights on these matters, refer to <xref target="FDio-CSIT-MLRsearch"></xref>.</t>

<t>The primary MLRsearch implementation, used as the prototype
for this specification, is <xref target="PyPI-MLRsearch"></xref>.</t>

</section>
</section>
<section anchor="quantities"><name>Quantities</name>

<t>MLRsearch Specification
uses a number of specific quantities,
some of them can be expressed in several different units.</t>

<t>In general, MLRsearch Specification does not require particular units to be used,
but it is REQUIRED for the test report to state all the units.
For example, ratio quantities can be dimensionless numbers between zero and one,
but may be expressed as percentages instead.</t>

<t>For convenience, a group of quantities can be treated as a composite quantity.
One constituent of a composite quantity is called an attribute.
A group of attribute values is called an instance of that composite quantity.</t>

<t>Some attributes may depend on others and can be calculated from other
attributes. Such quantities are called derived quantities.</t>

<section anchor="current-and-final-values"><name>Current and Final Values</name>

<t>Some quantities are defined in a way that makes it possible to compute their
values in the middle of a Search. Other quantities are specified so
that their values can be computed only after a Search ends. Some
quantities are important only after a Search ended, but their values
are computable also before a Search ends.</t>

<t>For a quantity that is computable before a Search ends,
the adjective <strong>current</strong> is used to mark a value of that quantity
available before the Search ends.
When such value is relevant for the search result, the adjective <strong>final</strong>
is used to denote the value of that quantity at the end of the Search.</t>

<t>If a time evolution of such a dynamic quantity is guided by
configuration quantities, those adjectives can be used to distinguish
quantities. For example, if the current value of &quot;duration&quot;
(dynamic quantity) increases from &quot;initial duration&quot; to &quot;final
duration&quot; (configuration quantities), all the quoted names denote
separate but related quantities. As the naming suggests, the final
value of &quot;duration&quot; is expected to be equal to &quot;final duration&quot; value.</t>

</section>
</section>
<section anchor="existing-terms"><name>Existing Terms</name>

<t>This specification relies on the following three documents that should
be consulted before attempting to make use of this document:</t>

<t><list style="symbols">
  <t>&quot;Benchmarking Terminology for Network Interconnect Devices&quot; <xref target="RFC1242"></xref>
contains basic term definitions.</t>
  <t>&quot;Benchmarking Terminology for LAN Switching Devices&quot; <xref target="RFC2285"></xref> adds
more terms and discussions, describing some known network
benchmarking situations in a more precise way.</t>
  <t>&quot;Benchmarking Methodology for Network Interconnect Devices&quot;
 <xref target="RFC2544"></xref> contains discussions about terms and additional
 methodology requirements.</t>
</list></t>

<t>Definitions of some central terms from above documents are copied and
discussed in the following subsections.</t>

<section anchor="sut"><name>SUT</name>

<t>Defined in Section 3.1.2 of <xref target="RFC2285"></xref> as follows.</t>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The collective set of network devices to which stimulus is offered
as a single entity and response measured.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>An SUT consisting of a single network device is allowed by this definition.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In software-based networking SUT may comprise multitude of
networking applications and the entire host hardware and software
execution environment.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>SUT is the only entity that can be benchmarked directly,
even though only the performance of some sub-components are of interest.</t>
  </dd>
</dl>

</section>
<section anchor="dut"><name>DUT</name>

<t>Defined in Section 3.1.1 of <xref target="RFC2285"></xref> as follows.</t>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The network forwarding device
to which stimulus is offered and response measured.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Contrary to SUT, the DUT stimulus and response are frequently
initiated and observed only indirectly, on different parts of SUT.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>DUT, as a sub-component of SUT, is only indirectly mentioned in
MLRsearch Specification, but is of key relevance for its motivation.
The device can represent a software-based networking functions running
on commodity x86/ARM CPUs (vs purpose-built ASIC / NPU / FPGA).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>A well-designed SUTs should have the primary DUT as their performance bottleneck.
The ways to achieve that are outside of MLRsearch Specification scope.</t>
  </dd>
</dl>

</section>
<section anchor="trial"><name>Trial</name>

<t>A trial is the part of the test described in Section 23 of <xref target="RFC2544"></xref>.</t>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A particular test consists of multiple trials.  Each trial returns
one piece of information, for example the loss rate at a particular
input frame rate.  Each trial consists of a number of phases:</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>a) If the DUT is a router, send the routing update to the &quot;input&quot;
port and pause two seconds to be sure that the routing has settled.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>b)  Send the &quot;learning frames&quot; to the &quot;output&quot; port and wait 2
seconds to be sure that the learning has settled.  Bridge learning
frames are frames with source addresses that are the same as the
destination addresses used by the test frames.  Learning frames for
other protocols are used to prime the address resolution tables in
the DUT.  The formats of the learning frame that should be used are
shown in the Test Frame Formats document.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>c) Run the test trial.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>d) Wait for two seconds for any residual frames to be received.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>e) Wait for at least five seconds for the DUT to restabilize.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The traffic is sent only in phase c) and received in phases c) and d).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Trials are the only stimuli the SUT is expected to experience during the Search.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In some discussion paragraphs, it is useful to consider the traffic
as sent and received by a tester, as implicitly defined
in Section 6 of <xref target="RFC2544"></xref>.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The definition describes some traits, not using capitalized verbs
to signify strength of the requirements.
For the purposes of the MLRsearch Specification,
the test procedure MAY deviate from the <xref target="RFC2544"></xref> description,
but any such deviation MUST be described explicitly in the Test Report.
It is still RECOMMENDED to not deviate from the description,
as any deviation weakens comparability.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>An example of deviation from <xref target="RFC2544"></xref> is using shorter wait times,
compared to those described in phases a), b), d) and e).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The <xref target="RFC2544"></xref> document itself seems to be treating phase b)
as any type of configuration that cannot be configured only once (by Manager,
before Search starts), as some crucial SUT state could time-out during the Search.
It is RECOMMENDED to interpret the &quot;learning frames&quot; to be
any such time-sensitive per-trial configuration method,
with bridge MAC learning being only one possible examples.
Appendix C.2.4.1 of <xref target="RFC2544"></xref> lists another example: ARP with wait time of 5 seconds.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Some methodologies describe recurring tests.
If those are based on Trials, they are treated as multiple independent Trials.</t>
  </dd>
</dl>

</section>
</section>
<section anchor="trial-terms"><name>Trial Terms</name>

<t>This section defines new and redefine existing terms for quantities
relevant as inputs or outputs of a Trial, as used by the Measurer component.
This includes also any derived quantities related to results of one Trial.</t>

<section anchor="trial-duration"><name>Trial Duration</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Duration is the intended duration of the phase c) of a Trial.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The value MUST be positive.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>While any positive real value may be provided, some Measurer
implementations MAY limit possible values, e.g., by rounding down to
nearest integer in seconds. In that case, it is RECOMMENDED to give
such inputs to the Controller so that the Controller
only uses the accepted values.</t>
  </dd>
</dl>

</section>
<section anchor="trial-load"><name>Trial Load</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Load is the per-interface Intended Load for a Trial.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Load is equivalent to the quantities defined
as constant load (Section 3.4 of <xref target="RFC1242"></xref>),
data rate (Section 14 of <xref target="RFC2544"></xref>),
and Intended Load (Section 3.5.1 of <xref target="RFC2285"></xref>),
in the sense that all three definitions specify that this value
applies to one (input or output) interface.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For specification purposes, it is assumed that this is a constant load by default,
as specified in Section 3.4 of <xref target="RFC1242"></xref>).
Informally, Traffic Load is a single number that can &quot;scale&quot; any traffic pattern
as long as the intuition of load intended against a single interface can be applied.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It MAY be possible to use a Trial Load value to describe a non-constant traffic
(using average load when the traffic consists of repeated bursts of frames
e.g., as suggested in Section 21 of <xref target="RFC2544"></xref>).
In the case of a non-constant load, the Test Report
MUST explicitly mention how exactly non-constant the traffic is
and how it reacts to Traffic Load value.
But the rest of the MLRsearch Specification assumes that is not the case,
to avoid discussing corner cases (e.g., which values are possible within medium limitations).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Similarly, traffic patterns where different interfaces are subject to different loads
MAY be described by a single Trial Load value (e.g. using largest load among interfaces),
but again the Test Report MUST explicitly describe how the traffic pattern
reacts to Traffic Load value,
and this specification does not discuss all the implications of that approach.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In the common case of bidirectional traffic, as described in
Section 14. Bidirectional Traffic of <xref target="RFC2544"></xref>,
Trial Load is the data rate per direction, half of aggregate data rate.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Traffic patterns where a single Trial Load does not describe their scaling
cannot be used for MLRsearch benchmarks.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Similarly to Trial Duration, some Measurers MAY limit the possible values
of Trial Load. Contrary to Trial Duration,
documenting such behavior in the test report is OPTIONAL.
This is because the load differences are negligible (and frequently
undocumented) in practice.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The Controller MAY select Trial Load and Trial Duration values in a way
that would not be possible to achieve using any integer number of data frames.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>If a particular Trial Load value is not tied to a single Trial,
e.g., if there are no Trials yet or if there are multiple Trials,
this document uses a shorthand <strong>Load</strong>.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The test report MAY present the aggregate load across multiple
interfaces, treating it as the same quantity expressed using different
units. Each reported Trial Load value MUST state unambiguously whether
it refers to (i) a single interface, (ii) a specified subset of
interfaces (such as all logical interfaces mapped to one physical
port), or (iii) the total across every interface. For any aggregate
load value, the report MUST also give the fixed conversion factor that
links the per-interface and multi-interface load values.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The per-interface value remains the primary unit, consistent
with prevailing practice in <xref target="RFC1242"></xref>, <xref target="RFC2544"></xref>, and <xref target="RFC2285"></xref>.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The last paragraph also applies to other terms related to Load.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For example, tests with symmetric bidirectional traffic
can report load-related values as &quot;bidirectional load&quot;
(double of &quot;unidirectional load&quot;).</t>
  </dd>
</dl>

</section>
<section anchor="trial-input"><name>Trial Input</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Input is a composite quantity, consisting of two attributes:
Trial Duration and Trial Load.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>When talking about multiple Trials, it is common to say &quot;Trial Inputs&quot;
to denote all corresponding Trial Input instances.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>A Trial Input instance acts as the input for one call of the Measurer component.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Contrary to other composite quantities, MLRsearch implementations
MUST NOT add optional attributes into Trial Input.
This improves interoperability between various implementations of
a Controller and a Measurer.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Note that both attributes are <strong>intended</strong> quantities,
as only those can be fully controlled by the Controller.
The actual offered quantities, as realized by the Measurer, can be different
(and must be different if not multiplying into integer number of frames),
but questions around those offered quantities are generally
outside of the scope of this document.</t>
  </dd>
</dl>

</section>
<section anchor="traffic-profile"><name>Traffic Profile</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Traffic Profile is a composite quantity containing
all attributes other than Trial Load and Trial Duration,
that are needed for unique determination of the Trial to be performed.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>All the attributes are assumed to be constant during the Search,
and the composite is configured on the Measurer by the Manager
before the Search starts.
This is why the traffic profile is not part of the Trial Input.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Specification of traffic properties included in the Traffic Profile is
the responsibility of the Manager, but the specific configuration mechanisms
are outside of the scope of this document.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, implementations of the Manager and the Measurer
must be aware of their common set of capabilities,
so that Traffic Profile instance uniquely defines the traffic during the Search.
Typically, Manager and Measurer implementations are tightly integrated.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Integration efforts between independent Manager and Measurer implementations
are outside of the scope of this document.
An example standardization effort is <xref target="Vassilev"></xref>.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Examples of traffic properties include:
- Data link frame size
- Fixed sizes as listed in Section 3.5 of <xref target="RFC1242"></xref> and in Section
  9 of <xref target="RFC2544"></xref>
- IMIX mixed sizes as defined in <xref target="RFC6985"></xref>
- Frame formats and protocol addresses
- Section 8, 12 and Appendix C of <xref target="RFC2544"></xref>
- Symmetric bidirectional traffic
- Section 14 of <xref target="RFC2544"></xref>.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Other traffic properties that need to be somehow specified
in Traffic Profile, and MUST be mentioned in Test Report
if they apply to the benchmark, include:</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t><list style="symbols">
      <t>bidirectional traffic from Section 14 of <xref target="RFC2544"></xref>,</t>
      <t>fully meshed traffic from Section 3.3.3 of <xref target="RFC2285"></xref>,</t>
      <t>modifiers from Section 11 of <xref target="RFC2544"></xref>.</t>
      <t>IP version mixing from Section 5.3 of <xref target="RFC8219"></xref>.</t>
    </list></t>
  </dd>
</dl>

</section>
<section anchor="trial-forwarding-ratio"><name>Trial Forwarding Ratio</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Trial Forwarding Ratio is a dimensionless floating point value.
It MUST range between 0.0 and 1.0, both inclusive.
It is calculated by dividing the number of frames
successfully forwarded by the SUT
by the total number of frames expected to be forwarded during the trial.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>For most Traffic Profiles, &quot;expected to be forwarded&quot; means
&quot;intended to get received by SUT from tester&quot;.
This SHOULD be the default interpretation.
Only if this is not the case, the test report MUST describe the Traffic Profile
in a detail sufficient to imply how Trial Forwarding Ratio should be calculated.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Forwarding Ratio MAY be expressed in other units
(e.g., as a percentage) in the test report.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Note that, contrary to Load terms, frame counts used to compute
Trial Forwarding Ratio are generally aggregates over all SUT output interfaces,
as most test procedures verify all outgoing frames.
The procedure for <xref target="RFC2544"></xref> Throughput counts received frames,
so implicitly it implies bidirectional counts for bidirectional traffic,
even though the final value is &quot;rate&quot; that is still per-interface.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For example, in a test with symmetric bidirectional traffic,
if one direction is forwarded without losses, but the opposite direction
does not forward at all, the Trial Forwarding Ratio would be 0.5 (50%).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In future extensions, more general ways to compute Trial Forwarding Ratio
may be allowed, but the current MLRsearch Specification relies on this specific
averaged counters approach.</t>
  </dd>
</dl>

</section>
<section anchor="trial-loss-ratio"><name>Trial Loss Ratio</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Trial Loss Ratio is equal to one minus the Trial Forwarding Ratio.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>100% minus the Trial Forwarding Ratio, when expressed as a percentage.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>This is almost identical to Frame Loss Rate of Section 3.6 of <xref target="RFC1242"></xref>.
The only minor differences are that Trial Loss Ratio does not need to
be expressed as a percentage, and Trial Loss Ratio is explicitly
based on averaged frame counts when more than one data stream is present.</t>
  </dd>
</dl>

</section>
<section anchor="trial-forwarding-rate"><name>Trial Forwarding Rate</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Trial Forwarding Rate is a derived quantity, calculated by
multiplying the Trial Load by the Trial Forwarding Ratio.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>This quantity differs from the Forwarding Rate described in Section
3.6.1 of <xref target="RFC2285"></xref>. Under the RFC 2285 method, each output interface is
measured separately, so every interface may report a distinct rate. The
Trial Forwarding Rate, by contrast, uses a single set of frame counts
and therefore yields one value that represents the whole system,
while still preserving the direct link to the per-interface load.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>When the Traffic Profile is symmetric and bidirectional, as defined in
Section 14 of <xref target="RFC2544"></xref>, the Trial Forwarding Rate is numerically equal
to the arithmetic average of the individual per-interface forwarding rates
that would be produced by the RFC 2285 procedure.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For more complex traffic patterns, such as many-to-one as mentioned
in Section 3.3.2 Partially Meshed Traffic of <xref target="RFC2285"></xref>,
the meaning of Trial Forwarding Rate is less straightforward.
For example, if two input interfaces receive one million frames per second each,
and a single interface outputs 1.4 million frames per second (fps),
Trial Load is 1 million fps, Trial Loss Ratio is 30%,
and Trial Forwarding Rate is 0.7 million fps.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Because this rate is anchored to the Load defined for one interface,
a test report MAY show it either as the single averaged figure just described,
or as the sum of the separate per-interface forwarding rates.
For the example above, the aggregate trial forwarding rate is 1.4 million fps.</t>
  </dd>
</dl>

</section>
<section anchor="trial-effective-duration"><name>Trial Effective Duration</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Effective Duration is a time quantity related to a Trial,
by default equal to the Trial Duration.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>This is an optional feature.
If the Measurer does not return any Trial Effective Duration value,
the Controller MUST use the Trial Duration value instead.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Effective Duration may be any positive time quantity
chosen by the Measurer to be used for time-based decisions in the Controller.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The test report MUST explain how the Measurer computes the returned
Trial Effective Duration values, if they are not always
equal to the Trial Duration.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>This feature can be beneficial for time-critical benchmarks
designed to manage the overall search duration,
rather than solely the traffic portion of it.
An approach is to measure the duration of the whole trial (including all wait times)
and use that as the Trial Effective Duration.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>This is also a way for the Measurer to inform the Controller about
its surprising behavior, for example, when rounding the Trial Duration value.</t>
  </dd>
</dl>

</section>
<section anchor="trial-output"><name>Trial Output</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Output is a composite quantity consisting of several attributes.
Required attributes are: Trial Loss Ratio, Trial Effective Duration and
Trial Forwarding Rate.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>When referring to more than one trial, plural term &quot;Trial Outputs&quot; is
used to collectively describe multiple Trial Output instances.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Measurer implementations may provide additional optional attributes.
The Controller implementations SHOULD
ignore values of any optional attribute
they are not familiar with,
except when passing Trial Output instances to the Manager.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Example of an optional attribute:
The aggregate number of frames expected to be forwarded during the trial,
especially if it is not (a rounded-down value)
implied by Trial Load and Trial Duration.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>While Section 3.5.2 of <xref target="RFC2285"></xref> requires the Offered Load value
to be reported for forwarding rate measurements,
it is not required in MLRsearch Specification,
as search results do not depend on it.</t>
  </dd>
</dl>

</section>
<section anchor="trial-result"><name>Trial Result</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Result is a composite quantity,
consisting of the Trial Input and the Trial Output.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>When referring to more than one trial, plural term &quot;Trial Results&quot; is
used to collectively describe multiple Trial Result instances.</t>
  </dd>
</dl>

</section>
</section>
<section anchor="goal-terms"><name>Goal Terms</name>

<t>This section defines new terms for quantities relevant (directly or indirectly)
for inputs and outputs of the Controller component.</t>

<t>Several goal attributes are defined before introducing
the main composite quantity: the Search Goal.</t>

<t>Contrary to other sections, definitions in subsections of this section
are necessarily vague, as their fundamental meaning is to act as
coefficients in formulas for Controller Output, which are not defined yet.</t>

<t>The discussions in this section relate the attributes to concepts mentioned in Section
<xref target="overview-of-rfc-2544-problems">Overview of RFC 2544 Problems</xref>, but even these discussion
paragraphs are short, informal, and mostly referencing later sections,
where the impact on search results is discussed after introducing
the complete set of auxiliary terms.</t>

<section anchor="goal-final-trial-duration"><name>Goal Final Trial Duration</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Minimal value for Trial Duration that must be reached.
The value MUST be positive.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Certain trials must reach this minimum duration before a load can be
classified as a lower bound.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The Controller may choose shorter durations,
results of those may be enough for classification as an Upper Bound.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It is RECOMMENDED for all search goals to share the same
Goal Final Trial Duration value. Otherwise, Trial Duration values larger than
the Goal Final Trial Duration may occur, weakening the assumptions
the <xref target="load-classification-logic">Load Classification Logic</xref> is based on.</t>
  </dd>
</dl>

</section>
<section anchor="goal-duration-sum"><name>Goal Duration Sum</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A threshold value for a particular sum of Trial Effective Duration values.
The value MUST be positive.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, this prescribes the sufficient number of trials performed
at a specific Trial Load and Goal Final Trial Duration during the search.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>If the Goal Duration Sum is larger than the Goal Final Trial Duration,
multiple trials may be needed to be performed at the same load.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Refer to Section <xref target="mlrsearch-compliant-with-tst009">MLRsearch Compliant with TST009</xref>
for an example where the possibility of multiple trials
at the same load is intended.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>A Goal Duration Sum value shorter than the Goal Final Trial Duration
(of the same goal) could save some search time, but is NOT RECOMMENDED,
as the time savings come at the cost of decreased repeatability.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In practice, the Search can spend less than Goal Duration Sum measuring
a Load value when the results are particularly one-sided,
but also, the Search can spend more than Goal Duration Sum measuring a Load
when the results are balanced and include
trials shorter than Goal Final Trial Duration.</t>
  </dd>
</dl>

</section>
<section anchor="goal-loss-ratio"><name>Goal Loss Ratio</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A threshold value for Trial Loss Ratio values.
The value MUST be non-negative and smaller than one.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A trial with Trial Loss Ratio larger than this value
signals the SUT may be unable to process this Trial Load well enough.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>See <xref target="throughput-with-non-zero-loss">Throughput with Non-Zero Loss</xref>
for reasons why users may want to set this value above zero.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Since multiple trials may be needed for one Load value,
the Load Classification may be more complicated than mere comparison
of Trial Loss Ratio to Goal Loss Ratio.</t>
  </dd>
</dl>

</section>
<section anchor="goal-exceed-ratio"><name>Goal Exceed Ratio</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A threshold value for a particular ratio of sums
of Trial Effective Duration values.
The value MUST be non-negative and smaller than one.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, up to this proportion of Trial Results
with Trial Loss Ratio above Goal Loss Ratio is tolerated at a Lower Bound.
This is the full impact if every Trial was measured at Goal Final Trial Duration.
The actual full logic is more complicated, as shorter Trials are allowed.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For explainability reasons, the RECOMMENDED value for exceed ratio is 0.5 (50%),
as in practice that value leads to
the smallest variation in overall Search Duration.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Refer to Section <xref target="exceed-ratio-and-multiple-trials">Exceed Ratio and Multiple Trials</xref>
for more details.</t>
  </dd>
</dl>

</section>
<section anchor="goal-width"><name>Goal Width</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A threshold value for deciding whether two Trial Load values are close enough.
This is an OPTIONAL attribute. If present, the value MUST be positive.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, this acts as a stopping condition,
controlling the precision of the search result.
The search stops if every goal has reached its precision.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Implementations without this attribute
MUST provide the Controller with other means to control the search stopping conditions.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Absolute load difference and relative load difference are two popular choices,
but implementations may choose a different way to specify width.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The test report MUST make it clear what specific quantity is used as Goal Width.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It is RECOMMENDED to express Goal Width as a relative difference and
setting it to a value not lower than the Goal Loss Ratio.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Refer to Section 
<xref target="generalized-throughput">Generalized Throughput</xref> for more elaboration on the reasoning.</t>
  </dd>
</dl>

</section>
<section anchor="goal-initial-trial-duration"><name>Goal Initial Trial Duration</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Minimal value for Trial Duration suggested to use for this goal.
If present, this value MUST be positive.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>This is an example of an optional Search Goal.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>A typical default value is equal to the Goal Final Trial Duration value.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, this is the shortest Trial Duration the Controller should select
when focusing on the goal.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Note that shorter Trial Duration values can still be used,
for example, selected while focusing on a different Search Goal.
Such results MUST be still accepted by the Load Classification logic.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Goal Initial Trial Duration is a mechanism for a user to discourage
trials with Trial Duration values deemed as too unreliable
for a particular SUT and a given Search Goal.</t>
  </dd>
</dl>

</section>
<section anchor="search-goal"><name>Search Goal</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Search Goal is a composite quantity consisting of several attributes,
some of them are required.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Required attributes: Goal Final Trial Duration, Goal Duration Sum, Goal
Loss Ratio and Goal Exceed Ratio.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Optional attributes: Goal Initial Trial Duration and Goal Width.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Implementations MAY add their own attributes.
Those additional attributes may be required by an implementation
even if they are not required by MLRsearch Specification.
However, it is RECOMMENDED for those implementations
to support missing attributes by providing typical default values.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For example, implementations with Goal Initial Trial Durations
may also require users to specify &quot;how quickly&quot; should Trial Durations increase.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Refer to Section <xref target="compliance"></xref> for important Search Goal settings.</t>
  </dd>
</dl>

</section>
<section anchor="controller-input"><name>Controller Input</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Controller Input is a composite quantity
required as an input for the Controller.
The only REQUIRED attribute is a list of Search Goal instances.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>MLRsearch implementations MAY use additional attributes.
Those additional attributes may be required by an implementation
even if they are not required by MLRsearch Specification.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Formally, the Manager does not apply any Controller configuration
apart from one Controller Input instance.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For example, Traffic Profile is configured on the Measurer by the Manager,
without explicit assistance of the Controller.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The order of Search Goal instances in a list SHOULD NOT
have a big impact on Controller Output,
but MLRsearch implementations MAY base their behavior on the order
of Search Goal instances in a list.</t>
  </dd>
</dl>

<section anchor="max-load"><name>Max Load</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Max Load is an optional attribute of Controller Input.
It is the maximal value the Controller is allowed to use for Trial Load values.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Max Load is an example of an optional attribute (outside the list of Search Goals)
required by some implementations of MLRsearch.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>If the Max Load value is provided, Controller MUST NOT select
Trial Load values larger than that value.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In theory, each search goal could have its own Max Load value,
but as all Trial Results are possibly affecting all Search Goals,
it makes more sense for a single Max Load value to apply
to all Search Goal instances.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>While Max Load is a frequently used configuration parameter, already governed
(as maximum frame rate) by <xref target="RFC2544"></xref> (Section 20)
and (as maximum offered load) by <xref target="RFC2285"></xref> (Section 3.5.3),
some implementations may detect or discover it
(instead of requiring a user-supplied value).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In MLRsearch Specification, one reason for listing
the <xref target="relevant-upper-bound">Relevant Upper Bound</xref> as a required attribute
is that it makes the search result independent of Max Load value.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Given that Max Load is a quantity based on Load,
Test Report MAY express this quantity using multi-interface values,
as sum of per-interface maximal loads.</t>
  </dd>
</dl>

</section>
<section anchor="min-load"><name>Min Load</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Min Load is an optional attribute of Controller Input.
It is the minimal value the Controller is allowed to use for Trial Load values.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Min Load is another example of an optional attribute
required by some implementations of MLRsearch.
Similarly to Max Load, it makes more sense to prescribe one common value,
as opposed to using a different value for each Search Goal.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>If the Min Load value is provided, Controller MUST NOT select
Trial Load values smaller than that value.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Min Load is mainly useful for saving time by failing early,
arriving at an Irregular Goal Result when Min Load gets classified
as an Upper Bound.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For implementations, it is RECOMMENDED to require Min Load to be non-zero
and large enough to result in at least one frame being forwarded
even at shortest allowed Trial Duration,
so that Trial Loss Ratio is always well-defined,
and the implementation can apply relative Goal Width safely.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Given that Min Load is a quantity based on Load,
Test Report MAY express this quantity using multi-interface values,
as sum of per-interface minimal loads.</t>
  </dd>
</dl>

</section>
</section>
</section>
<section anchor="auxiliary-terms"><name>Auxiliary Terms</name>

<t>While the terms defined in this section are not strictly needed
when formulating MLRsearch requirements, they simplify the language used
in discussion paragraphs and explanation sections.</t>

<section anchor="trial-classification"><name>Trial Classification</name>

<t>When one Trial Result instance is compared to one Search Goal instance,
several relations can be named using short adjectives.</t>

<t>As trial results do not affect each other, this <strong>Trial Classification</strong>
does not change during a Search.</t>

<section anchor="high-loss-trial"><name>High-Loss Trial</name>

<t>A trial with Trial Loss Ratio larger than a Goal Loss Ratio value
is called a <strong>high-loss trial</strong>, with respect to given Search Goal
(or lossy trial, if Goal Loss Ratio is zero).</t>

</section>
<section anchor="low-loss-trial"><name>Low-Loss Trial</name>

<t>If a trial is not high-loss, it is called a <strong>low-loss trial</strong>
(or zero-loss trial, if Goal Loss Ratio is zero).</t>

</section>
<section anchor="short-trial"><name>Short Trial</name>

<t>A trial with Trial Duration shorter than the Goal Final Trial Duration
is called a <strong>short trial</strong> (with respect to the given Search Goal).</t>

</section>
<section anchor="full-length-trial"><name>Full-Length Trial</name>

<t>A trial that is not short is called a <strong>full-length</strong> trial.</t>

<t>Note that this includes Trial Durations larger than Goal Final Trial Duration.</t>

</section>
<section anchor="long-trial"><name>Long Trial</name>

<t>A trial with Trial Duration longer than the Goal Final Trial Duration
is called a <strong>long trial</strong>.</t>

</section>
</section>
<section anchor="load-classification"><name>Load Classification</name>

<t>When a set of all Trial Result instances, performed so far
at one Trial Load, is compared to one Search Goal instance,
their relation can be named using the concept of a bound.</t>

<t>In general, such bounds are a current quantity,
even though cases of a Load changing its classification more than once
during the Search is rare in practice.</t>

<section anchor="upper-bound"><name>Upper Bound</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A Load value is called an Upper Bound if and only if it is classified
as such by <xref target="load-classification-code">Appendix A</xref>
algorithm for the given Search Goal at the current moment of the Search.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>In more detail, the set of all Trial Result instances
performed so far at the Trial Load (and any Trial Duration)
is certain to fail to uphold all the requirements of the given Search Goal,
mainly the Goal Loss Ratio in combination with the Goal Exceed Ratio.
In this context, &quot;certain to fail&quot; relates to any possible results within the time
remaining till Goal Duration Sum.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>One search goal can have multiple different Trial Load values
classified as its Upper Bounds.
While search progresses and more trials are measured,
any load value can become an Upper Bound in principle.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Moreover, a Load can stop being an Upper Bound, but that
can only happen when more than Goal Duration Sum of trials are measured
(e.g., because another Search Goal needs more trials at this load).
Informally, the previous Upper Bound got invalidated.
In practice, the Load frequently becomes a <xref target="lower-bound">Lower Bound</xref> instead.</t>
  </dd>
</dl>

</section>
<section anchor="lower-bound"><name>Lower Bound</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A Load value is called a Lower Bound if and only if it is classified
as such by <xref target="load-classification-code">Appendix A</xref>
algorithm for the given Search Goal at the current moment of the search.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>In more detail, the set of all Trial Result instances
performed so far at the Trial Load (and any Trial Duration)
is certain to uphold all the requirements of the given Search Goal,
mainly the Goal Loss Ratio in combination with the Goal Exceed Ratio.
Here &quot;certain to uphold&quot; relates to any possible results within the time
remaining till Goal Duration Sum.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>One search goal can have multiple different Trial Load values
classified as its Lower Bounds.
As search progresses and more trials are measured,
any load value can become a Lower Bound in principle.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>No load can be both an Upper Bound and a Lower Bound for the same Search goal
at the same time, but it is possible for a larger load to be a Lower Bound
while a smaller load is an Upper Bound.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Moreover, a Load can stop being a Lower Bound, but that
can only happen when more than Goal Duration Sum of trials are measured
(e.g., because another Search Goal needs more trials at this load).
Informally, the previous Lower Bound got invalidated.
In practice, the Load frequently becomes an <xref target="upper-bound">Upper Bound</xref> instead.</t>
  </dd>
</dl>

</section>
<section anchor="undecided"><name>Undecided</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A Load value is called Undecided if it is currently
neither an Upper Bound nor a Lower Bound.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A Load value that has not been measured so far is Undecided.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It is possible for a Load to transition from an Upper Bound to Undecided
by adding Short Trials with Low-Loss results.
That is yet another reason for users to avoid using Search Goal instances
with different Goal Final Trial Duration values.</t>
  </dd>
</dl>

</section>
</section>
</section>
<section anchor="result-terms"><name>Result Terms</name>

<t>Before defining the full structure of a Controller Output,
it is useful to define the composite quantity, called Goal Result.
The following subsections define its attribute first,
before describing the Goal Result quantity.</t>

<t>There is a correspondence between Search Goals and Goal Results.
Most of the following subsections refer to a given Search Goal,
when defining their terms.
Conversely, at the end of the search, each Search Goal instance
has its corresponding Goal Result instance.</t>

<section anchor="relevant-upper-bound"><name>Relevant Upper Bound</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Relevant Upper Bound is the smallest Trial Load value
classified as an Upper Bound for a given Search Goal at the end of the Search.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>If no measured load had enough High-Loss Trials,
the Relevant Upper Bound MAY be non-existent.
For example, when Max Load is classified as a Lower Bound.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Conversely, when Relevant Upper Bound does exist,
it is not affected by Max Load value.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Given that Relevant Upper Bound is a quantity based on Load,
Test Report MAY express this quantity using multi-interface values,
as sum of per-interface loads.</t>
  </dd>
</dl>

</section>
<section anchor="relevant-lower-bound"><name>Relevant Lower Bound</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Relevant Lower Bound is the largest Trial Load value
among those smaller than the Relevant Upper Bound, that got classified
as a Lower Bound for a given Search Goal at the end of the search.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>If no load had enough Low-Loss Trials, the Relevant Lower Bound
MAY be non-existent.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Strictly speaking, if the Relevant Upper Bound does not exist,
the Relevant Lower Bound also does not exist.
In a typical case, Max Load is classified as a Lower Bound,
making it impossible to increase the Load to continue the search
for an Upper Bound.
Thus, it is not clear whether a larger value would be found
for a Relevant Lower Bound if larger Loads were possible.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Given that Relevant Lower Bound is a quantity based on Load,
Test Report MAY express this quantity using multi-interface values,
as sum of per-interface loads.</t>
  </dd>
</dl>

</section>
<section anchor="conditional-throughput"><name>Conditional Throughput</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Conditional Throughput is a value computed at the Relevant Lower Bound
according to algorithm defined in
<xref target="conditional-throughput-code">Appendix B</xref>.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Relevant Lower Bound is defined only at the end of the Search,
and so is the Conditional Throughput.
But the algorithm can be applied at any time on any Lower Bound load,
so the final Conditional Throughput value may appear sooner
than at the end of a Search.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, the Conditional Throughput should be
a typical Trial Forwarding Rate, expected to be seen
at the Relevant Lower Bound of a given Search Goal.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>But frequently it is only a conservative estimate thereof,
as MLRsearch implementations tend to stop measuring more Trials
as soon as they confirm the value cannot get worse than this estimate
within the Goal Duration Sum.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>This value is RECOMMENDED to be used when evaluating repeatability
and comparability of different MLRsearch implementations.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Refer to Section <xref target="generalized-throughput">Generalized Throughput</xref> for more details.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Given that Conditional Throughput is a quantity based on Load,
Test Report MAY express this quantity using multi-interface values,
as sum of per-interface forwarding rates.</t>
  </dd>
</dl>

</section>
<section anchor="goal-results"><name>Goal Results</name>

<t>MLRsearch Specification is based on a set of requirements
for a &quot;regular&quot; result. But in practice, it is not always possible
for such result instance to exist, so also &quot;irregular&quot; results
need to be supported.</t>

<section anchor="regular-goal-result"><name>Regular Goal Result</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Regular Goal Result is a composite quantity consisting of several attributes.
Relevant Upper Bound and Relevant Lower Bound are REQUIRED attributes.
Conditional Throughput is a RECOMMENDED attribute.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Implementations MAY add their own attributes.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Test report MUST display Relevant Lower Bound.
Displaying Relevant Upper Bound is RECOMMENDED,
especially if the implementation does not use Goal Width.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In general, stopping conditions for the corresponding Search Goal MUST
be satisfied to produce a Regular Goal Result.
Specifically, if an implementation offers Goal Width as a Search Goal attribute,
the distance between the Relevant Lower Bound
and the Relevant Upper Bound MUST NOT be larger than the Goal Width.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For stopping conditions refer to Sections <xref target="goal-width">Goal Width</xref> and
<xref target="stopping-conditions-and-precision">Stopping Conditions and Precision</xref>.</t>
  </dd>
</dl>

</section>
<section anchor="irregular-goal-result"><name>Irregular Goal Result</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Irregular Goal Result is a composite quantity. No attributes are required.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>It is RECOMMENDED to report any useful quantity even if it does not
satisfy all the requirements. For example, if Max Load is classified
as a Lower Bound, it is fine to report it as an &quot;effective&quot; Relevant Lower Bound
(although not a real one, as that requires
Relevant Upper Bound which does not exist in this case),
and compute Conditional Throughput for it. In this case,
only the missing Relevant Upper Bound signals this result instance is irregular.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Similarly, if both relevant bounds exist, it is RECOMMENDED
to include them as Irregular Goal Result attributes,
and let the Manager decide if their distance is too far for Test Report purposes.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>If Test Report displays some Irregular Goal Result attribute values,
they MUST be clearly marked as coming from irregular results.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The implementation MAY define additional attributes,
for example explicit flags for expected situations, so the Manager logic can be simpler.</t>
  </dd>
</dl>

</section>
<section anchor="goal-result"><name>Goal Result</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Goal Result is a composite quantity.
Each instance is either a Regular Goal Result or an Irregular Goal Result.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Manager MUST be able of distinguishing whether the instance is regular or not.</t>
  </dd>
</dl>

</section>
</section>
<section anchor="search-result"><name>Search Result</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Search Result is a single composite object
that maps each Search Goal instance to a corresponding Goal Result instance.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>As an alternative to mapping, the Search Result may be represented
as an ordered list of Goal Result instances that appears in the exact
sequence of their corresponding Search Goal instances.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>When the Search Result is expressed as a mapping, it MUST contain an
entry for every Search Goal instance supplied in the Controller Input.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Identical Goal Result instances MAY be listed for different Search Goals,
but their status as regular or irregular may be different.
For example, if two goals differ only in Goal Width value,
and the relevant bound values are close enough according to only one of them.</t>
  </dd>
</dl>

</section>
<section anchor="controller-output"><name>Controller Output</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Controller Output is a composite quantity returned from the Controller
to the Manager at the end of the search.
The Search Result instance is its only required attribute.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>MLRsearch implementation MAY return additional data in the Controller Output,
e.g., number of trials performed and the total Search Duration.</t>
  </dd>
</dl>

</section>
</section>
<section anchor="architecture-terms"><name>Architecture Terms</name>

<t>MLRsearch architecture consists of three main system components: 
the Manager, the Controller, and the Measurer.
The components were introduced in <xref target="architecture-overview">Architecture Overview</xref>,
and the following subsections finalize their definitions
using terms from previous sections.</t>

<t>Note that the architecture also implies the presence of other components,
such as the SUT and the tester (as a sub-component of the Measurer).</t>

<t>Communication protocols and interfaces between components are left
unspecified. For example, when MLRsearch Specification mentions
&quot;Controller calls Measurer&quot;,
it is possible that the Controller notifies the Manager
to call the Measurer indirectly instead. In doing so, the Measurer implementations
can be fully independent from the Controller implementations,
e.g., developed in different programming languages.</t>

<section anchor="measurer"><name>Measurer</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Measurer is a functional element that when called
with a <xref target="trial-input">Trial Input</xref> instance, performs one <xref target="trial">Trial </xref>
and returns a <xref target="trial-output">Trial Output</xref> instance.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>This definition assumes the Measurer is already initialized.
In practice, there may be additional steps before the Search,
e.g., when the Manager configures the traffic profile
(either on the Measurer or on its tester sub-component directly)
and performs a warm-up (if the tester or the test procedure requires one).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It is the responsibility of the Measurer implementation to uphold
any requirements and assumptions present in MLRsearch Specification,
e.g., Trial Forwarding Ratio not being larger than one.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Implementers have some freedom.
For example, Section 10 of <xref target="RFC2544"></xref>
gives some suggestions (but not requirements) related to
duplicated or reordered frames.
Implementations are RECOMMENDED to document their behavior
related to such freedoms in as detailed a way as possible.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It is RECOMMENDED to benchmark the test equipment first,
e.g., connect sender and receiver directly (without any SUT in the path),
find a load value that guarantees the Offered Load is not too far
from the Intended Load and use that value as the Max Load value.
When testing the real SUT, it is RECOMMENDED to turn any severe deviation
between the Intended Load and the Offered Load into increased Trial Loss Ratio.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Neither of the two recommendations are made into mandatory requirements,
because it is not easy to provide guidance about when the difference is severe enough,
in a way that would be disentangled from other Measurer freedoms.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For a sample situation where the Offered Load cannot keep up
with the Intended Load, and the consequences on MLRsearch result,
refer to Section <xref target="hard-performance-limit">Hard Performance Limit</xref>.</t>
  </dd>
</dl>

</section>
<section anchor="controller"><name>Controller</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Controller is a functional element that, upon receiving a Controller
Input instance, repeatedly generates Trial Input instances for the
Measurer and collects the corresponding Trial Output instances. This
cycle continues until the stopping conditions are met, at which point
the Controller produces a final Controller Output instance and
terminates.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, the Controller has big freedom in selection of Trial Inputs,
and the implementations want to achieve all the Search Goals
in the shortest average time.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The Controller&#39;s role in optimizing the overall Search Duration
distinguishes MLRsearch algorithms from simpler search procedures.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, each implementation can have different stopping conditions.
Goal Width is only one example.
In practice, implementation details do not matter,
as long as Goal Result instances are regular.</t>
  </dd>
</dl>

</section>
<section anchor="manager"><name>Manager</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Manager is a functional element that is responsible for
provisioning other components, calling a Controller component once,
and for creating the test report following the reporting format as
defined in Section 26 of <xref target="RFC2544"></xref>.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Manager initializes the SUT, the Measurer
(and the tester if independent from Measurer)
with their intended configurations before calling the Controller.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Note that Section 7 of <xref target="RFC2544"></xref> already puts requirements on SUT setups:</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>&quot;It is expected that all of the tests will be run without changing the
configuration or setup of the DUT in any way other than that required
to do the specific test. For example, it is not acceptable to change
the size of frame handling buffers between tests of frame handling
rates or to disable all but one transport protocol when testing the
throughput of that protocol.&quot;</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It is REQUIRED for the test report to encompass all the SUT configuration
details, including description of a &quot;default&quot; configuration common for most tests
and configuration changes if required by a specific test.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For example, Section 5.1.1 of <xref target="RFC5180"></xref> recommends testing jumbo frames
if SUT can forward them, even though they are outside the scope
of the 802.3 IEEE standard. In this case, it is acceptable
for the SUT default configuration to not support jumbo frames,
and only enable this support when testing jumbo traffic profiles,
as the handling of jumbo frames typically has different packet buffer
requirements and potentially higher processing overhead.
Non-jumbo frame sizes should also be tested on the jumbo-enabled setup.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The Manager does not need to be able to tweak any Search Goal attributes,
but it MUST report all applied attribute values even if not tweaked.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>A &quot;user&quot; - human or automated - invokes the Manager once to launch a
single Search and receive its report. Every new invocation is treated
as a fresh, independent Search; how the system behaves across multiple
calls (for example, combining or comparing their results) is explicitly
out of scope for this document.</t>
  </dd>
</dl>

</section>
</section>
<section anchor="compliance"><name>Compliance</name>

<t>This section discusses compliance relations between MLRsearch
and other test procedures.</t>

<section anchor="test-procedure-compliant-with-mlrsearch"><name>Test Procedure Compliant with MLRsearch</name>

<t>Any networking measurement setup that could be understood as consisting of
functional elements satisfying requirements
for the Measurer, the Controller and the Manager,
is compliant with MLRsearch Specification.</t>

<t>These components can be seen as abstractions present in any testing procedure.
For example, there can be a single component acting both
as the Manager and the Controller, but if values of required attributes
of Search Goals and Goal Results are visible in the test report,
the Controller Input instance and Controller Output instance are implied.</t>

<t>For example, any setup for conditionally (or unconditionally)
compliant <xref target="RFC2544"></xref> throughput testing
can be understood as a MLRsearch architecture,
if there is enough data to reconstruct the Relevant Upper Bound.</t>

<t>Refer to section 
<xref target="mlrsearch-compliant-with-rfc-2544">MLRsearch Compliant with RFC 2544</xref>
for an equivalent Search Goal.</t>

<t>Any test procedure that can be understood as one call to the Manager of
MLRsearch architecture is said to be compliant with MLRsearch Specification.</t>

</section>
<section anchor="mlrsearch-compliant-with-rfc-2544"><name>MLRsearch Compliant with RFC 2544</name>

<t>The following Search Goal instance makes the corresponding Search Result
unconditionally compliant with Section 24 of <xref target="RFC2544"></xref>.</t>

<t><list style="symbols">
  <t>Goal Final Trial Duration = 60 seconds</t>
  <t>Goal Duration Sum = 60 seconds</t>
  <t>Goal Loss Ratio = 0%</t>
  <t>Goal Exceed Ratio = 0%</t>
</list></t>

<t>Goal Loss Ratio and Goal Exceed Ratio attributes,
are enough to make the Search Goal conditionally compliant.
Adding Goal Final Trial Duration
makes the Search Goal unconditionally compliant.</t>

<t>Goal Duration Sum prevents MLRsearch
from repeating zero-loss Full-Length Trials.</t>

<t>The presence of other Search Goals does not affect the compliance
of this Goal Result.
The Relevant Lower Bound and the Conditional Throughput are in this case
equal to each other, and the value is the <xref target="RFC2544"></xref> throughput.</t>

<t>Non-zero exceed ratio is not strictly disallowed, but it could
needlessly prolong the search when Low-Loss short trials are present.</t>

</section>
<section anchor="mlrsearch-compliant-with-tst009"><name>MLRsearch Compliant with TST009</name>

<t>One of the alternatives to <xref target="RFC2544"></xref> is Binary search with loss verification
as described in Section 12.3.3 of <xref target="TST009"></xref>.</t>

<t>The rationale of such search is to repeat high-loss trials, hoping for zero loss on second try,
so the results are closer to the noiseless end of performance spectrum,
thus more repeatable and comparable.</t>

<t>Only the variant with &quot;z = infinity&quot; is achievable with MLRsearch.</t>

<t>For example, for &quot;max(r) = 2&quot; variant, the following Search Goal instance
should be used to get compatible Search Result:</t>

<t><list style="symbols">
  <t>Goal Final Trial Duration = 60 seconds</t>
  <t>Goal Duration Sum = 120 seconds</t>
  <t>Goal Loss Ratio = 0%</t>
  <t>Goal Exceed Ratio = 50%</t>
</list></t>

<t>If the first 60 seconds trial has zero loss, it is enough for MLRsearch to stop
measuring at that load, as even a second high-loss trial
would still fit within the exceed ratio.</t>

<t>But if the first trial is high-loss, MLRsearch needs to perform also
the second trial to classify that load.
Goal Duration Sum is twice as long as Goal Final Trial Duration,
so third full-length trial is never needed.</t>

</section>
</section>
</section>
<section anchor="methodology-rationale-and-design-considerations"><name>Methodology Rationale and Design Considerations</name>

<t>This section explains the Why behind MLRsearch. Building on the
normative specification in Section
<xref target="mlrsearch-specification">MLRsearch Specification</xref>,
it contrasts MLRsearch with the classic
<xref target="RFC2544"></xref> single-ratio binary-search procedure and walks through the
key design choices: binary-search mechanics, stopping-rule precision,
loss-inversion for multiple goals, exceed-ratio handling, short-trial
strategies, and the generalised throughput concept. Together, these
considerations show how the methodology reduces test time, supports
multiple loss ratios, and improves repeatability.</t>

<section anchor="binary-search"><name>Binary Search</name>

<t>A typical binary search implementation for <xref target="RFC2544"></xref>
tracks only the two tightest bounds.
To start, the search needs both Max Load and Min Load values.
Then, one trial is used to confirm Max Load is an Upper Bound,
and one trial to confirm Min Load is a Lower Bound.</t>

<t>Then, next Trial Load is chosen as the mean of the current tightest upper bound
and the current tightest lower bound, and becomes a new tightest bound
depending on the Trial Loss Ratio.</t>

<t>After some number of trials, the tightest lower bound becomes the throughput,
but <xref target="RFC2544"></xref> does not specify when, if ever, the search should stop.
In practice, the search stops either at some distance
between the tightest upper bound and the tightest lower bound,
or after some number of Trials.</t>

<t>For a given pair of Max Load and Min Load values,
there is one-to-one correspondence between number of Trials
and final distance between the tightest bounds.
Thus, the search always takes the same time,
assuming initial bounds are confirmed.</t>

</section>
<section anchor="stopping-conditions-and-precision"><name>Stopping Conditions and Precision</name>

<t>MLRsearch Specification requires listing both Relevant Bounds for each
Search Goal, and the difference between the bounds implies
whether the result precision is achieved.
Therefore, it is not necessary to report the specific stopping condition used.</t>

<t>MLRsearch implementations may use Goal Width
to allow direct control of result precision
and indirect control of the Search Duration.</t>

<t>Other MLRsearch implementations may use different stopping conditions:
for example based on the Search Duration, trading off precision control
for duration control.</t>

<t>Due to various possible time optimizations, there is no strict
correspondence between the Search Duration and Goal Width values.
In practice, noisy SUT performance increases both average search time
and its variance.</t>

</section>
<section anchor="loss-ratios-and-loss-inversion"><name>Loss Ratios and Loss Inversion</name>

<t>The biggest difference between MLRsearch and <xref target="RFC2544"></xref> binary search
is in the goals of the search.
<xref target="RFC2544"></xref> has a single goal, based on classifying a single full-length trial
as either zero-loss or non-zero-loss.
MLRsearch supports searching for multiple Search Goals at once,
usually differing in their Goal Loss Ratio values.</t>

<section anchor="single-goal-and-hard-bounds"><name>Single Goal and Hard Bounds</name>

<t>Each bound in <xref target="RFC2544"></xref> simple binary search is &quot;hard&quot;,
in the sense that all further Trial Load values
are smaller than any current upper bound and larger than any current lower bound.</t>

<t>This is also possible for MLRsearch implementations,
when the search is started with only one Search Goal instance.</t>

</section>
<section anchor="multiple-goals-and-loss-inversion"><name>Multiple Goals and Loss Inversion</name>

<t>MLRsearch Specification supports multiple Search Goals, making the search procedure
more complicated compared to binary search with single goal,
but most of the complications do not affect the final results much.
Except for one phenomenon: Loss Inversion.</t>

<t>Depending on Search Goal attributes, Load Classification results may be resistant
to small amounts of Section <xref target="inconsistent-trial-results">Inconsistent Trial Results</xref>.
However, for larger amounts, a Load that is classified
as an Upper Bound for one Search Goal
may still be a Lower Bound for another Search Goal.
Due to this other goal, MLRsearch will probably perform subsequent Trials
at Trial Loads even larger than the original value.</t>

<t>This introduces questions any many-goals search algorithm has to address.
For example: What to do when all such larger load trials happen to have zero loss?
Does it mean the earlier upper bound was not real?
Does it mean the later Low-Loss trials are not considered a lower bound?</t>

<t>The situation where a smaller Load is classified as an Upper Bound,
while a larger Load is classified as a Lower Bound (for the same search goal),
is called Loss Inversion.</t>

<t>Conversely, only single-goal search algorithms can have hard bounds
that shield them from Loss Inversion.</t>

</section>
<section anchor="conservativeness-and-relevant-bounds"><name>Conservativeness and Relevant Bounds</name>

<t>MLRsearch is conservative when dealing with Loss Inversion:
the Upper Bound is considered real, and the Lower Bound
is considered to be a fluke, at least when computing the final result.</t>

<t>This is formalized using definitions of
<xref target="relevant-upper-bound">Relevant Upper Bound</xref> and
<xref target="relevant-lower-bound">Relevant Lower Bound</xref>.</t>

<t>The Relevant Upper Bound (for specific goal) is the smallest Load classified
as an Upper Bound. But the Relevant Lower Bound is not simply
the largest among Lower Bounds. It is the largest Load among Loads
that are Lower Bounds while also being smaller than the Relevant Upper Bound.</t>

<t>With these definitions, the Relevant Lower Bound is always smaller
than the Relevant Upper Bound (if both exist), and the two relevant bounds
are used analogously as the two tightest bounds in the binary search.
When they meet the stopping conditions, the Relevant Bounds are used in the output.</t>

</section>
<section anchor="consequences"><name>Consequences</name>

<t>The consequence of the way the Relevant Bounds are defined is that
every Trial Result can have an impact
on any current Relevant Bound larger than that Trial Load,
namely by becoming a new Upper Bound.</t>

<t>This also applies when that Load is measured
before another Load gets enough measurements to become a current Relevant Bound.</t>

<t>This also implies that if the SUT tested (or the Traffic Generator used)
needs a warm-up, it should be warmed up before starting the Search,
otherwise the first few measurements could become unjustly limiting.</t>

<t>For MLRsearch implementations, it means it is better to measure
at smaller Loads first, so bounds found earlier are less likely
to get invalidated later.</t>

</section>
</section>
<section anchor="exceed-ratio-and-multiple-trials"><name>Exceed Ratio and Multiple Trials</name>

<t>The idea of performing multiple Trials at the same Trial Load comes from
a model where some Trial Results (those with high Trial Loss Ratio) are affected
by infrequent effects, causing unsatisfactory repeatability</t>

<t>of <xref target="RFC2544"></xref> Throughput results. Refer to Section <xref target="dut-in-sut">DUT in SUT</xref>
for a discussion about noiseful and noiseless ends
of the SUT performance spectrum.
Stable results are closer to the noiseless end of the SUT performance spectrum,
so MLRsearch may need to allow some frequency of high-loss trials
to ignore the rare but big effects near the noiseful end.</t>

<t>For MLRsearch to perform such Trial Result filtering, it needs
a configuration option to tell how frequent the &quot;infrequent&quot; big loss can be.
This option is called the <xref target="goal-exceed-ratio">Goal Exceed Ratio</xref>.
It tells MLRsearch what ratio of trials (more specifically,
what ratio of Trial Effective Duration seconds)
can have a <xref target="trial-loss-ratio">Trial Loss Ratio</xref>
larger than the <xref target="goal-loss-ratio">Goal Loss Ratio</xref>
and still be classified as a <xref target="lower-bound">Lower Bound</xref>.</t>

<t>Zero exceed ratio means all Trials must have a Trial Loss Ratio
equal to or lower than the Goal Loss Ratio.</t>

<t>When more than one Trial is intended to classify a Load,
MLRsearch also needs something that controls the number of trials needed.
Therefore, each goal also has an attribute called Goal Duration Sum.</t>

<t>The meaning of a <xref target="goal-duration-sum">Goal Duration Sum</xref> is that
when a Load has (Full-Length) Trials
whose Trial Effective Durations when summed up give a value at least as big
as the Goal Duration Sum value,
the Load is guaranteed to be classified either as an Upper Bound
or a Lower Bound for that Search Goal instance.</t>

</section>
<section anchor="short-trials-and-duration-selection"><name>Short Trials and Duration Selection</name>

<t>MLRsearch requires each Search Goal to specify its Goal Final Trial Duration.</t>

<t>Section 24 of <xref target="RFC2544"></xref> already anticipates possible time savings
when Short Trials are used.</t>

<t>An MLRsearch implementation MAY expose configuration parameters that
decide whether, when, and how short trial durations are used. The exact
heuristics and controls are left to the discretion of the implementer.</t>

<t>While MLRsearch implementations are free to use any logic to select
Trial Input values, comparability between MLRsearch implementations
is only assured when the Load Classification logic
handles any possible set of Trial Results in the same way.</t>

<t>The presence of Short Trial Results complicates
the Load Classification logic, see more details in Section
<xref target="load-classification-logic">Load Classification Logic</xref>.</t>

<t>While the Load Classification algorithm is designed to avoid any unneeded Trials,
for explainability reasons it is recommended for users to use
such Controller Input instances that lead to all Trial Duration values
selected by Controller to be the same,
e.g., by setting any Goal Initial Trial Duration to be a single value
also used in all Goal Final Trial Duration attributes.</t>

</section>
<section anchor="generalized-throughput"><name>Generalized Throughput</name>

<t>Because testing equipment takes the Intended Load
as an input parameter for a Trial measurement,
any load search algorithm needs to deal with Intended Load values internally.</t>

<t>But in the presence of Search Goals with a non-zero
<xref target="goal-loss-ratio">Goal Loss Ratio</xref>, the Load usually does not match
the user&#39;s intuition of what a throughput is.
The forwarding rate as defined in Section Section 3.6.1 of <xref target="RFC2285"></xref> is better,
but it is not obvious how to generalize it
for Loads with multiple Trials and a non-zero Goal Loss Ratio.</t>

<t>The clearest illustration - and the chief reason for adopting a
generalized throughput definition - is the presence of a hard
performance limit.</t>

<section anchor="hard-performance-limit"><name>Hard Performance Limit</name>

<t>Even if bandwidth of a medium allows higher traffic forwarding performance,
the SUT interfaces may have their additional own limitations,
e.g., a specific frames-per-second limit on the NIC (a common occurrence).</t>

<t>Those limitations should be known and provided as Max Load, Section
<xref target="max-load">Max Load</xref>.</t>

<t>But if Max Load is set larger than what the interface can receive or transmit,
there will be a &quot;hard limit&quot; behavior observed in Trial Results.</t>

<t>Consider that the hard limit is at hundred million frames per second (100 Mfps),
Max Load is larger, and the Goal Loss Ratio is 0.5%.
If DUT has no additional losses, 0.5% Trial Loss Ratio will be achieved
at Relevant Lower Bound of 100.5025 Mfps.</t>

<t>Reporting a throughput that exceeds the SUT&#39;s verified hard limit is
counter-intuitive. Accordingly, the <xref target="RFC2544"></xref> Throughput metric should
be generalized - rather than relying solely on the Relevant Lower
Bound - to reflect realistic, limit-aware performance.</t>

<t>MLRsearch defines one such generalization,
the <xref target="conditional-throughput">Conditional Throughput</xref>.
It is the Trial Forwarding Rate from one of the Full-Length Trials
performed at the Relevant Lower Bound.
The algorithm to determine which trial exactly is in
<xref target="conditional-throughput-code">Appendix B</xref>.</t>

<t>In the hard limit example, 100.5025 Mfps Load will still have
only 100.0 Mfps forwarding rate, nicely confirming the known limitation.</t>

</section>
<section anchor="performance-variability"><name>Performance Variability</name>

<t>With non-zero Goal Loss Ratio, and without hard performance limits,
Low-Loss trials at the same Load may achieve different Trial Forwarding Rate
values just due to DUT performance variability.</t>

<t>By comparing the best case (all Relevant Lower Bound trials have zero loss)
and the worst case (all Trial Loss Ratios at Relevant Lower Bound
are equal to the Goal Loss Ratio),
one can prove that Conditional Throughput
values may have up to the Goal Loss Ratio relative difference.</t>

<t>Setting the Goal Width below the Goal Loss Ratio
may cause the Conditional Throughput for a larger Goal Loss Ratio to become smaller
than a Conditional Throughput for a goal with a lower Goal Loss Ratio,
which is counter-intuitive, considering they come from the same Search.
Therefore, it is RECOMMENDED to set the Goal Width to a value no lower
than the Goal Loss Ratio of the higher-loss Search Goal.</t>

<t>Although Conditional Throughput can fluctuate from one run to the next,
it still offers a more discriminating basis for comparison than the
Relevant Lower Bound - particularly when deterministic load selection
yields the same Lower Bound value across multiple runs.</t>

</section>
</section>
</section>
<section anchor="mlrsearch-logic-and-example"><name>MLRsearch Logic and Example</name>

<t>This section uses informal language to describe two aspects of MLRsearch logic:
Load Classification and Conditional Throughput,
reflecting formal pseudocode representation provided in
<xref target="load-classification-code">Appendix A</xref>
and <xref target="conditional-throughput-code">Appendix B</xref>.
This is followed by example search.</t>

<t>The logic is equivalent but not identical to the pseudocode
on appendices. The pseudocode is designed to be short and frequently
combines multiple operations into one expression.
The logic as described in this section lists each operation separately
and uses more intuitive names for the intermediate values.</t>

<section anchor="load-classification-logic"><name>Load Classification Logic</name>

<t>Note: For clarity of explanation, variables are tagged as (I)nput,
(T)emporary, (O)utput.</t>

<t><list style="symbols">
  <t>Collect Trial Results:  <list style="symbols">
      <t>Take all Trial Result instances (I) measured at a given load.</t>
    </list></t>
  <t>Aggregate Trial Durations:  <list style="symbols">
      <t>Full-length high-loss sum (T) is the sum of Trial Effective Duration
values of all full-length high-loss trials (I).</t>
      <t>Full-length low-loss sum (T) is the sum of Trial Effective Duration
values of all full-length low-loss trials (I).</t>
      <t>Short high-loss sum is the sum (T)  of Trial Effective Duration values
of all short high-loss trials (I).</t>
      <t>Short low-loss sum is the sum (T) of Trial Effective Duration values
of all short low-loss trials (I).</t>
    </list></t>
  <t>Derive goal-based ratios:  <list style="symbols">
      <t>Subceed ratio (T) is One minus the Goal Exceed Ratio (I).</t>
      <t>Exceed coefficient (T) is the Goal Exceed Ratio divided by the subceed
ratio.</t>
    </list></t>
  <t>Balance short-trial effects:  <list style="symbols">
      <t>Balancing sum (T) is the short low-loss sum
multiplied by the exceed coefficient.</t>
      <t>Excess sum (T) is the short high-loss sum minus the balancing sum.</t>
      <t>Positive excess sum (T) is the maximum of zero and excess sum.</t>
    </list></t>
  <t>Compute effective duration totals  <list style="symbols">
      <t>Effective high-loss sum (T) is the full-length high-loss sum
plus the positive excess sum.</t>
      <t>Effective full sum (T) is the effective high-loss sum
plus the full-length low-loss sum.</t>
      <t>Effective whole sum (T) is the larger of the effective full sum
and the Goal Duration Sum.</t>
      <t>Missing sum (T) is the effective whole sum minus the effective full sum.</t>
    </list></t>
  <t>Estimate exceed ratios:  <list style="symbols">
      <t>Pessimistic high-loss sum (T) is the effective high-loss sum
plus the missing sum.</t>
      <t>Optimistic exceed ratio (T) is the effective high-loss sum
divided by the effective whole sum.</t>
      <t>Pessimistic exceed ratio (T) is the pessimistic high-loss sum
divided by the effective whole sum.</t>
    </list></t>
  <t>Classify the Load:  <list style="symbols">
      <t>The load is classified as an Upper Bound (O) if the optimistic exceed
ratio is larger than the Goal Exceed Ratio.</t>
      <t>The load is classified as a Lower Bound (O) if the pessimistic exceed
ratio is not larger than the Goal Exceed Ratio.</t>
      <t>The load is classified as undecided (O) otherwise.</t>
    </list></t>
</list></t>

</section>
<section anchor="conditional-throughput-logic"><name>Conditional Throughput Logic</name>

<t><list style="symbols">
  <t>Collect Trial Results  <list style="symbols">
      <t>Take all Trial Result instances (I) measured at a given Load.</t>
    </list></t>
  <t>Sum Full-Length Durations:  <list style="symbols">
      <t>Full-length high-loss sum (T) is the sum of Trial Effective Duration
values of all full-length high-loss trials (I).</t>
      <t>Full-length low-loss sum (T) is the sum of Trial Effective Duration
values of all full-length low-loss trials (I).</t>
      <t>Full-length sum (T) is the full-length high-loss sum (I) plus the
full-length low-loss sum (I).</t>
    </list></t>
  <t>Derive initial thresholds:  <list style="symbols">
      <t>Subceed ratio (T) is One minus the Goal Exceed Ratio (I) is called.</t>
      <t>Remaining sum (T) initially is full-lengths sum multiplied by subceed
ratio.</t>
      <t>Current loss ratio (T) initially is 100%.</t>
    </list></t>
  <t>Iterate through ordered trials  <list style="symbols">
      <t>For each full-length trial result, sorted in increasing order by Trial
Loss Ratio:      <list style="symbols">
          <t>If remaining sum is not larger than zero, exit the loop.</t>
          <t>Set current loss ratio to this trial&#39;s Trial Loss Ratio (I).</t>
          <t>Decrease the remaining sum by this trial&#39;s Trial Effective Duration (I).</t>
        </list></t>
    </list></t>
  <t>Compute Conditional Throughput  <list style="symbols">
      <t>Current forwarding ratio (T) is One minus the current loss ratio.</t>
      <t>Conditional Throughput (T) is the current forwarding ratio multiplied
by the Load value.</t>
    </list></t>
</list></t>

<section anchor="conditional-throughput-and-load-classification"><name>Conditional Throughput and Load Classification</name>

<t>Conditional Throughput and results of Load Classification overlap but
are not identical.</t>

<t><list style="symbols">
  <t>When a load is marked as a Relevant Lower Bound, its Conditional
Throughput is taken from a trial whose loss ratio never exceeds the
Goal Loss Ratio.</t>
  <t>The reverse is not guaranteed: if the Goal Width is narrower than the
Goal Loss Ratio, Conditional Throughput can still end up higher than
the Relevant Upper Bound.</t>
</list></t>

</section>
</section>
<section anchor="sut-behaviors"><name>SUT Behaviors</name>

<t>In Section <xref target="dut-in-sut">DUT in SUT</xref>, the notion of noise has been introduced.
This section uses new terms
to describe possible SUT behaviors more precisely.</t>

<t>From measurement point of view, noise is visible as inconsistent trial results.
See <xref target="inconsistent-trial-results">Inconsistent Trial Results</xref> for general points
and <xref target="loss-ratios-and-loss-inversion">Loss Ratios and Loss Inversion</xref>
for specifics when comparing different Load values.</t>

<t>Load Classification and Conditional Throughput apply to a single Load value,
but even the set of Trial Results measured at that Trial Load value
may appear inconsistent.</t>

<t>As MLRsearch aims to save time, it executes only a small number of Trials,
getting only a limited amount of information about SUT behavior.
It is useful to introduce an &quot;SUT expert&quot; point of view to contrast
with that limited information.</t>

<section anchor="expert-predictions"><name>Expert Predictions</name>

<t>Imagine that before the Search starts, a human expert had unlimited time
to measure SUT and obtain all reliable information about it.
The information is not perfect, as there is still random noise influencing SUT.
But the expert is familiar with possible noise events, even the rare ones,
and thus the expert can do probabilistic predictions about future Trial Outputs.</t>

<t>When several outcomes are possible,
the expert can assess probability of each outcome.</t>

</section>
<section anchor="exceed-probability"><name>Exceed Probability</name>

<t>When the Controller selects new Trial Duration and Trial Load,
and just before the Measurer starts performing the Trial,
the SUT expert can envision possible Trial Results.</t>

<t>With respect to a particular Search Goal instance, the possibilities
can be summarized into a single number: Exceed Probability.
It is the probability (according to the expert) that the measured
Trial Loss Ratio will be higher than the Goal Loss Ratio.</t>

</section>
<section anchor="trial-duration-dependence"><name>Trial Duration Dependence</name>

<t>When comparing Exceed Probability values for the same Trial Load value
but different Trial Duration values,
there are several patterns that commonly occur in practice.</t>

<section anchor="strong-increase"><name>Strong Increase</name>

<t>Exceed Probability is very low at short durations but very high at full-length.
This SUT behavior is undesirable, and may hint at faulty SUT,
e.g., SUT leaks resources and is unable to sustain the desired performance.</t>

<t>But this behavior is also seen when SUT uses large amount of buffers.
This is the main reasons users may want to set large Goal Final Trial Duration.</t>

</section>
<section anchor="mild-increase"><name>Mild Increase</name>

<t>Short trials are slightly less likely to exceed the loss-ratio limit,
but the improvement is modest. This mild benefit is typical when noise
is dominated by rare, large loss spikes: during a full-length trial,
the good-performing periods cannot fully offset the heavy frame loss
that occurs in the brief low-performing bursts.</t>

</section>
<section anchor="independence"><name>Independence</name>

<t>Short trials have basically the same Exceed Probability as full-length trials.
This is possible only if loss spikes are small (so other parts can compensate)
and if Goal Loss Ratio is more than zero (otherwise, other parts
cannot compensate at all).</t>

</section>
<section anchor="decrease"><name>Decrease</name>

<t>Short trials have larger Exceed Probability than full-length trials.
This can be possible only for non-zero Goal Loss Ratio,
for example if SUT needs to &quot;warm up&quot; to best performance within each trial.
Not commonly seen in practice.</t>

</section>
</section>
</section>
</section>
<section anchor="iana-considerations"><name>IANA Considerations</name>

<t>This document does not make any request to IANA.</t>

</section>
<section anchor="security-considerations"><name>Security Considerations</name>

<t>Benchmarking activities as described in this memo are limited to
technology characterization of a DUT/SUT using controlled stimuli in a
laboratory environment, with dedicated address space and the constraints
specified in the sections above.</t>

<t>The benchmarking network topology will be an independent test setup and
MUST NOT be connected to devices that may forward the test traffic into
a production network or misroute traffic to the test management network.</t>

<t>Further, benchmarking is performed on an &quot;opaque&quot; basis, relying
solely on measurements observable external to the DUT/SUT.</t>

<t>The DUT/SUT SHOULD NOT include features that serve only to boost
benchmark scores - such as a dedicated &quot;fast-track&quot; test mode that is
never used in normal operation.</t>

<t>Any implications for network security arising from the DUT/SUT SHOULD be
identical in the lab and in production networks.</t>

</section>
<section anchor="acknowledgements"><name>Acknowledgements</name>

<t>Special wholehearted gratitude and thanks to the late Al Morton for his
thorough reviews filled with very specific feedback and constructive
guidelines. Thank You Al for the close collaboration over the years, Your Mentorship,
Your continuous unwavering encouragement full of empathy and energizing
positive attitude. Al, You are dearly missed.</t>

<t>Thanks to Gabor Lencse, Giuseppe Fioccola, Carsten Rossenhoevel and BMWG
contributors for good discussions and thorough reviews, guiding and
helping us to improve the clarity and formality of this document.</t>

<t>Many thanks to Alec Hothan of the OPNFV NFVbench project for a thorough
review and numerous useful comments and suggestions in the earlier
versions of this document.</t>

<t>We are equally indebted to Mohamed Boucadair for a very thorough and
detailed AD review and providing many good comments and suggestions,
helping us make this document complete.</t>

<t>Our appreciation is also extended to Shawn Emery, Yoshifumi Nishida,
David Dong, Nabeel Cocker and Lars Eggert for their reviews and valueable comments.</t>

</section>


  </middle>

  <back>


<references title='References' anchor="sec-combined-references">

    <references title='Normative References' anchor="sec-normative-references">

&RFC1242;
&RFC2119;
&RFC2285;
&RFC2544;
&RFC8174;


    </references>

    <references title='Informative References' anchor="sec-informative-references">

&RFC5180;
&RFC6349;
&RFC6985;
&RFC8219;
<reference anchor="TST009" target="https://www.etsi.org/deliver/etsi_gs/NFV-TST/001_099/009/03.04.01_60/gs_NFV-TST009v030401p.pdf">
  <front>
    <title>TST 009</title>
    <author >
      <organization></organization>
    </author>
    <date year="n.d."/>
  </front>
</reference>
<reference anchor="Y.1564" target="https://www.itu.int/rec/dologin_pub.asp?lang=e&amp;id=T-REC-Y.1564-201602-I!!PDF-E&amp;type=items">
  <front>
    <title>Y.1564</title>
    <author >
      <organization></organization>
    </author>
    <date year="n.d."/>
  </front>
</reference>
<reference anchor="FDio-CSIT-MLRsearch" target="https://csit.fd.io/cdocs/methodology/measurements/data_plane_throughput/mlr_search/">
  <front>
    <title>FD.io CSIT Test Methodology - MLRsearch</title>
    <author >
      <organization></organization>
    </author>
    <date year="2023" month="October"/>
  </front>
</reference>
<reference anchor="PyPI-MLRsearch" target="https://pypi.org/project/MLRsearch/1.2.1/">
  <front>
    <title>MLRsearch 1.2.1, Python Package Index</title>
    <author >
      <organization></organization>
    </author>
    <date year="2023" month="October"/>
  </front>
</reference>
<reference anchor="Lencze-Shima" target="https://datatracker.ietf.org/doc/html/draft-lencse-bmwg-rfc2544-bis-00">
  <front>
    <title>An Upgrade to Benchmarking Methodology for Network Interconnect Devices - expired</title>
    <author >
      <organization></organization>
    </author>
    <date year="n.d."/>
  </front>
</reference>
<reference anchor="Lencze-Kovacs-Shima" target="http://dx.doi.org/10.11601/ijates.v9i2.288">
  <front>
    <title>Gaming with the Throughput and the Latency Benchmarking Measurement Procedures of RFC 2544</title>
    <author >
      <organization></organization>
    </author>
    <date year="n.d."/>
  </front>
</reference>
<reference anchor="Ott-Mathis-Semke-Mahdavi" target="https://www.cs.cornell.edu/people/egs/cornellonly/syslunch/fall02/ott.pdf">
  <front>
    <title>The Macroscopic Behavior of the TCP Congestion Avoidance Algorithm</title>
    <author >
      <organization></organization>
    </author>
    <date year="n.d."/>
  </front>
</reference>
<reference anchor="Vassilev" target="https://datatracker.ietf.org/doc/draft-ietf-bmwg-network-tester-cfg/06">
  <front>
    <title>A YANG Data Model for Network Tester Management</title>
    <author >
      <organization></organization>
    </author>
    <date year="n.d."/>
  </front>
</reference>


    </references>

</references>


<?line 2709?>

<section anchor="load-classification-code"><name>Load Classification Code</name>

<t>This appendix specifies how to perform the Load Classification.</t>

<t>Any Trial Load value can be classified,
according to a given <xref target="search-goal">Search Goal</xref> instance.</t>

<t>The algorithm uses (some subsets of) the set of all available Trial Results
from Trials measured at a given Load at the end of the Search.</t>

<t>The block at the end of this appendix holds pseudocode
which computes two values, stored in variables named
<spanx style="verb">optimistic_is_lower</spanx> and <spanx style="verb">pessimistic_is_lower</spanx>.</t>

<t>Although presented as pseudocode, the listing is syntactically valid
Python and can be executed without modification.</t>

<t>If values of both variables are computed to be true, the Load in question
is classified as a Lower Bound according to the given Search Goal instance.
If values of both variables are false, the Load is classified as an Upper Bound.
Otherwise, the load is classified as Undecided.</t>

<t>Some variable names are shortened to fit expressions in one line.
Namely, variables holding sum quantities end in <spanx style="verb">_s</spanx> instead of <spanx style="verb">_sum</spanx>,
and variables holding effective quantities start in <spanx style="verb">effect_</spanx>
instead of <spanx style="verb">effective_</spanx>.</t>

<t>The pseudocode expects the following variables to hold the following values:</t>

<t><list style="symbols">
  <t><spanx style="verb">goal_duration_s</spanx>: The Goal Duration Sum value of the given Search Goal.</t>
  <t><spanx style="verb">goal_exceed_ratio</spanx>: The Goal Exceed Ratio value of the given Search Goal.</t>
  <t><spanx style="verb">full_length_low_loss_s</spanx>: Sum of Trial Effective Durations across Trials
with Trial Duration at least equal to the Goal Final Trial Duration
and with Trial Loss Ratio not higher than the Goal Loss Ratio
(across Full-Length Low-Loss Trials).</t>
  <t><spanx style="verb">full_length_high_loss_s</spanx>: Sum of Trial Effective Durations across Trials
with Trial Duration at least equal to the Goal Final Trial Duration
and with Trial Loss Ratio higher than the Goal Loss Ratio
(across Full-Length High-Loss Trials).</t>
  <t><spanx style="verb">short_low_loss_s</spanx>: Sum of Trial Effective Durations across Trials
with Trial Duration shorter than the Goal Final Trial Duration
and with Trial Loss Ratio not higher than the Goal Loss Ratio
(across Short Low-Loss Trials).</t>
  <t><spanx style="verb">short_high_loss_s</spanx>: Sum of Trial Effective Durations across Trials
with Trial Duration shorter than the Goal Final Trial Duration
and with Trial Loss Ratio higher than the Goal Loss Ratio
(across Short High-Loss Trials).</t>
</list></t>

<t>The code works correctly also when there are no Trial Results at a given Load.</t>

<figure><sourcecode type="python"><![CDATA[
<CODE BEGINS>
exceed_coefficient = goal_exceed_ratio / (1.0 - goal_exceed_ratio)
balancing_s = short_low_loss_s * exceed_coefficient
positive_excess_s = max(0.0, short_high_loss_s - balancing_s)
effect_high_loss_s = full_length_high_loss_s + positive_excess_s
effect_full_length_s = full_length_low_loss_s + effect_high_loss_s
effect_whole_s = max(effect_full_length_s, goal_duration_s)
quantile_duration_s = effect_whole_s * goal_exceed_ratio
pessimistic_high_loss_s = effect_whole_s - full_length_low_loss_s
pessimistic_is_lower = pessimistic_high_loss_s <= quantile_duration_s
optimistic_is_lower = effect_high_loss_s <= quantile_duration_s
<CODE ENDS>
]]></sourcecode></figure>

</section>
<section anchor="conditional-throughput-code"><name>Conditional Throughput Code</name>

<t>This section specifies an example of how to compute Conditional Throughput,
as referred to in Section <xref target="conditional-throughput">Conditional Throughput</xref>.</t>

<t>Any Load value can be used as the basis for the following computation,
but only the Relevant Lower Bound (at the end of the Search)
leads to the value called the Conditional Throughput for a given Search Goal.</t>

<t>The algorithm uses (some subsets of) the set of all available Trial Results
from Trials measured at a given Load at the end of the Search.</t>

<t>The block at the end of this appendix holds pseudocode
which computes a value stored as variable <spanx style="verb">conditional_throughput</spanx>.</t>

<t>Although presented as pseudocode, the listing is syntactically valid
Python and can be executed without modification.</t>

<t>Some variable names are shortened in order to fit expressions in one line.
Namely, variables holding sum quantities end in <spanx style="verb">_s</spanx> instead of <spanx style="verb">_sum</spanx>,
and variables holding effective quantities start in <spanx style="verb">effect_</spanx>
instead of <spanx style="verb">effective_</spanx>.</t>

<t>The pseudocode expects the following variables to hold the following values:</t>

<t><list style="symbols">
  <t><spanx style="verb">goal_duration_s</spanx>: The Goal Duration Sum value of the given Search Goal.</t>
  <t><spanx style="verb">goal_exceed_ratio</spanx>: The Goal Exceed Ratio value of the given Search Goal.</t>
  <t><spanx style="verb">full_length_low_loss_s</spanx>: Sum of Trial Effective Durations across Trials
with Trial Duration at least equal to the Goal Final Trial Duration
and with Trial Loss Ratio not higher than the Goal Loss Ratio
(across Full-Length Low-Loss Trials).</t>
  <t><spanx style="verb">full_length_high_loss_s</spanx>: Sum of Trial Effective Durations across Trials
with Trial Duration at least equal to the Goal Final Trial Duration
and with Trial Loss Ratio higher than the Goal Loss Ratio
(across Full-Length High-Loss Trials).</t>
  <t><spanx style="verb">full_length_trials</spanx>: An iterable of all Trial Results from Trials
with Trial Duration at least equal to the Goal Final Trial Duration
(all Full-Length Trials), sorted by increasing Trial Loss Ratio.
One item <spanx style="verb">trial</spanx> is a composite with the following two attributes available:  <list style="symbols">
      <t><spanx style="verb">trial.loss_ratio</spanx>: The Trial Loss Ratio as measured for this Trial.</t>
      <t><spanx style="verb">trial.effect_duration</spanx>: The Trial Effective Duration of this Trial.</t>
    </list></t>
</list></t>

<t>The code works correctly only when there is at least one
Trial Result measured at a given Load.</t>

<figure><sourcecode type="python"><![CDATA[
<CODE BEGINS>
full_length_s = full_length_low_loss_s + full_length_high_loss_s
whole_s = max(goal_duration_s, full_length_s)
remaining = whole_s * (1.0 - goal_exceed_ratio)
quantile_loss_ratio = None
for trial in full_length_trials:
    if quantile_loss_ratio is None or remaining > 0.0:
        quantile_loss_ratio = trial.loss_ratio
        remaining -= trial.effect_duration
    else:
        break
else:
    if remaining > 0.0:
        quantile_loss_ratio = 1.0
conditional_throughput = intended_load * (1.0 - quantile_loss_ratio)
<CODE ENDS>
]]></sourcecode></figure>

</section>
<section anchor="example-search"><name>Example Search</name>

<t>The following example Search is related to
one hypothetical run of a Search test procedure
that has been started with multiple Search Goals.
Several points in time are chosen, to show how the logic works,
with specific sets of Trial Result available.
The trial results themselves are not very realistic, as
the intention is to show several corner cases of the logic.</t>

<t>In all Trials, the Effective Trial Duration is equal to Trial Duration.</t>

<t>Only one Trial Load is in focus, its value is one million frames per second.
Trial Results at other Trial Loads are not mentioned,
as the parts of logic present here do not depend on those.
In practice, Trial Results at other Load values would be present,
e.g., MLRsearch will look for a Lower Bound smaller than any Upper Bound found.</t>

<t>At any given moment, exactly one Search Goal is designated as in focus.
This designation affects only the Trial Duration chosen for new trials;
it does not alter the rest of the decision logic.</t>

<t>An MLRsearch implementation is free to evaluate several goals
simultaneously - the &quot;focus&quot; mechanism is optional and appears here only
to show that a load can still be classified against goals that are not
currently in focus.</t>

<section anchor="example-goals"><name>Example Goals</name>

<t>The following four Search Goal instances are selected for the example Search.
Each goal has a readable name and dense code,
the code is useful to show Search Goal attribute values.</t>

<t>As the variable &quot;exceed coefficient&quot; does not depend on trial results,
it is also precomputed here.</t>

<t>Goal 1:</t>

<figure><artwork><![CDATA[
name: RFC2544
Goal Final Trial Duration: 60s
Goal Duration Sum: 60s
Goal Loss Ratio: 0%
Goal Exceed Ratio: 0%
exceed coefficient: 0% / (100% / 0%) = 0.0
code: 60f60d0l0e
]]></artwork></figure>

<t>Goal 2:</t>

<figure><artwork><![CDATA[
name: TST009
Goal Final Trial Duration: 60s
Goal Duration Sum: 120s
Goal Loss Ratio: 0%
Goal Exceed Ratio: 50%
exceed coefficient: 50% / (100% - 50%) = 1.0
code: 60f120d0l50e
]]></artwork></figure>

<t>Goal 3:</t>

<figure><artwork><![CDATA[
name: 1s final
Goal Final Trial Duration: 1s
Goal Duration Sum: 120s
Goal Loss Ratio: 0.5%
Goal Exceed Ratio: 50%
exceed coefficient: 50% / (100% - 50%) = 1.0
code: 1f120d.5l50e
]]></artwork></figure>

<t>Goal 4:</t>

<figure><artwork><![CDATA[
name: 20% exceed
Goal Final Trial Duration: 60s
Goal Duration Sum: 60s
Goal Loss Ratio: 0.5%
Goal Exceed Ratio: 20%
exceed coefficient: 20% / (100% - 20%) = 0.25
code: 60f60d0.5l20e
]]></artwork></figure>

<t>The first two goals are important for compliance reasons,
the other two cover less frequent cases.</t>

</section>
<section anchor="example-trial-results"><name>Example Trial Results</name>

<t>The following six sets of trial results are selected for the example Search.
The sets are defined as points in time, describing which Trial Results
were added since the previous point.</t>

<t>Each point has a readable name and dense code,
the code is useful to show Trial Output attribute values
and number of times identical results were added.</t>

<t>Point 1:</t>

<figure><artwork><![CDATA[
name: first short good
goal in focus: 1s final (1f120d.5l50e)
added Trial Results: 59 trials, each 1 second and 0% loss
code: 59x1s0l
]]></artwork></figure>

<t>Point 2:</t>

<figure><artwork><![CDATA[
name: first short bad
goal in focus: 1s final (1f120d.5l50e)
added Trial Result: one trial, 1 second, 1% loss
code: 59x1s0l+1x1s1l
]]></artwork></figure>

<t>Point 3:</t>

<figure><artwork><![CDATA[
name: last short bad
goal in focus: 1s final (1f120d.5l50e)
added Trial Results: 59 trials, 1 second each, 1% loss each
code: 59x1s0l+60x1s1l
]]></artwork></figure>

<t>Point 4:</t>

<figure><artwork><![CDATA[
name: last short good
goal in focus: 1s final (1f120d.5l50e)
added Trial Results: one trial 1 second, 0% loss
code: 60x1s0l+60x1s1l
]]></artwork></figure>

<t>Point 5:</t>

<figure><artwork><![CDATA[
name: first long bad
goal in focus: TST009 (60f120d0l50e)
added Trial Results: one trial, 60 seconds, 0.1% loss
code: 60x1s0l+60x1s1l+1x60s.1l
]]></artwork></figure>

<t>Point 6:</t>

<figure><artwork><![CDATA[
name: first long good
goal in focus: TST009 (60f120d0l50e)
added Trial Results: one trial, 60 seconds, 0% loss
code: 60x1s0l+60x1s1l+1x60s.1l+1x60s0l
]]></artwork></figure>

<t>Comments on point in time naming:</t>

<t><list style="symbols">
  <t>When a name contains &quot;short&quot;, it means the added trial
had Trial Duration of 1 second, which is Short Trial for 3 of the Search Goals,
but it is a Full-Length Trial for the &quot;1s final&quot; goal.</t>
  <t>Similarly, &quot;long&quot; in name means the added trial
had Trial Duration of 60 seconds, which is Full-Length Trial for 3 goals
but Long Trial for the &quot;1s final&quot; goal.</t>
  <t>When a name contains &quot;good&quot; it means the added trial is Low-Loss Trial
for all the goals.</t>
  <t>When a name contains &quot;short bad&quot; it means the added trial is High-Loss Trial
for all the goals.</t>
  <t>When a name contains &quot;long bad&quot;, it means the added trial
is a High-Loss Trial for goals &quot;RFC2544&quot; and &quot;TST009&quot;,
but it is a Low-Loss Trial for the two other goals.</t>
</list></t>

</section>
<section anchor="load-classification-computations"><name>Load Classification Computations</name>

<t>This section shows how Load Classification logic is applied
by listing all temporary values at the specific time point.</t>

<section anchor="point-1"><name>Point 1</name>

<t>This is the &quot;first short good&quot; point.
Code for available results is: 59x1s0l</t>

<texttable>
      <ttcol align='left'>Goal name</ttcol>
      <ttcol align='left'>RFC2544</ttcol>
      <ttcol align='left'>TST009</ttcol>
      <ttcol align='left'>1s final</ttcol>
      <ttcol align='left'>20% exceed</ttcol>
      <c>Goal code</c>
      <c>60f60d0l0e</c>
      <c>60f120d0l50e</c>
      <c>1f120d.5l50e</c>
      <c>60f60d0.5l20e</c>
      <c>Full-length high-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Full-length low-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>Short high-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Short low-loss sum</c>
      <c>59s</c>
      <c>59s</c>
      <c>0s</c>
      <c>59s</c>
      <c>Balancing sum</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>14.75s</c>
      <c>Excess sum</c>
      <c>0s</c>
      <c>-59s</c>
      <c>0s</c>
      <c>-14.75s</c>
      <c>Positive excess sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Effective high-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Effective full sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>Effective whole sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>120s</c>
      <c>60s</c>
      <c>Missing sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>61s</c>
      <c>60s</c>
      <c>Pessimistic high-loss sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>61s</c>
      <c>60s</c>
      <c>Optimistic exceed ratio</c>
      <c>0%</c>
      <c>0%</c>
      <c>0%</c>
      <c>0%</c>
      <c>Pessimistic exceed ratio</c>
      <c>100%</c>
      <c>100%</c>
      <c>50.833%</c>
      <c>100%</c>
      <c>Classification Result</c>
      <c>Undecided</c>
      <c>Undecided</c>
      <c>Undecided</c>
      <c>Undecided</c>
</texttable>

<t>This is the last point in time where all goals have this load as Undecided.</t>

</section>
<section anchor="point-2"><name>Point 2</name>

<t>This is the &quot;first short bad&quot; point.
Code for available results is: 59x1s0l+1x1s1l</t>

<texttable>
      <ttcol align='left'>Goal name</ttcol>
      <ttcol align='left'>RFC2544</ttcol>
      <ttcol align='left'>TST009</ttcol>
      <ttcol align='left'>1s final</ttcol>
      <ttcol align='left'>20% exceed</ttcol>
      <c>Goal code</c>
      <c>60f60d0l0e</c>
      <c>60f120d0l50e</c>
      <c>1f120d.5l50e</c>
      <c>60f60d0.5l20e</c>
      <c>Full-length high-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>1s</c>
      <c>0s</c>
      <c>Full-length low-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>Short high-loss sum</c>
      <c>1s</c>
      <c>1s</c>
      <c>0s</c>
      <c>1s</c>
      <c>Short low-loss sum</c>
      <c>59s</c>
      <c>59s</c>
      <c>0s</c>
      <c>59s</c>
      <c>Balancing sum</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>14.75s</c>
      <c>Excess sum</c>
      <c>1s</c>
      <c>-58s</c>
      <c>0s</c>
      <c>-13.75s</c>
      <c>Positive excess sum</c>
      <c>1s</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Effective high-loss sum</c>
      <c>1s</c>
      <c>0s</c>
      <c>1s</c>
      <c>0s</c>
      <c>Effective full sum</c>
      <c>1s</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>Effective whole sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>120s</c>
      <c>60s</c>
      <c>Missing sum</c>
      <c>59s</c>
      <c>120s</c>
      <c>60s</c>
      <c>60s</c>
      <c>Pessimistic high-loss sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>61s</c>
      <c>60s</c>
      <c>Optimistic exceed ratio</c>
      <c>1.667%</c>
      <c>0%</c>
      <c>0.833%</c>
      <c>0%</c>
      <c>Pessimistic exceed ratio</c>
      <c>100%</c>
      <c>100%</c>
      <c>50.833%</c>
      <c>100%</c>
      <c>Classification Result</c>
      <c>Upper Bound</c>
      <c>Undecided</c>
      <c>Undecided</c>
      <c>Undecided</c>
</texttable>

<t>Due to zero Goal Loss Ratio, RFC2544 goal must have mild or strong increase
of exceed probability, so the one lossy trial would be lossy even if measured
at 60 second duration.
Due to zero exceed ratio, one High-Loss Trial is enough to preclude this Load
from becoming a Lower Bound for RFC2544. That is why this Load
is classified as an Upper Bound for RFC2544 this early.</t>

<t>This is an example how significant time can be saved, compared to 60-second trials.</t>

</section>
<section anchor="point-3"><name>Point 3</name>

<t>This is the &quot;last short bad&quot; point.
Code for available trial results is: 59x1s0l+60x1s1l</t>

<texttable>
      <ttcol align='left'>Goal name</ttcol>
      <ttcol align='left'>RFC2544</ttcol>
      <ttcol align='left'>TST009</ttcol>
      <ttcol align='left'>1s final</ttcol>
      <ttcol align='left'>20% exceed</ttcol>
      <c>Goal code</c>
      <c>60f60d0l0e</c>
      <c>60f120d0l50e</c>
      <c>1f120d.5l50e</c>
      <c>60f60d0.5l20e</c>
      <c>Full-length high-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>Full-length low-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>Short high-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Short low-loss sum</c>
      <c>59s</c>
      <c>59s</c>
      <c>0s</c>
      <c>59s</c>
      <c>Balancing sum</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>14.75s</c>
      <c>Excess sum</c>
      <c>60s</c>
      <c>1s</c>
      <c>0s</c>
      <c>45.25s</c>
      <c>Positive excess sum</c>
      <c>60s</c>
      <c>1s</c>
      <c>0s</c>
      <c>45.25s</c>
      <c>Effective high-loss sum</c>
      <c>60s</c>
      <c>1s</c>
      <c>60s</c>
      <c>45.25s</c>
      <c>Effective full sum</c>
      <c>60s</c>
      <c>1s</c>
      <c>119s</c>
      <c>45.25s</c>
      <c>Effective whole sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>120s</c>
      <c>60s</c>
      <c>Missing sum</c>
      <c>0s</c>
      <c>119s</c>
      <c>1s</c>
      <c>14.75s</c>
      <c>Pessimistic high-loss sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>61s</c>
      <c>60s</c>
      <c>Optimistic exceed ratio</c>
      <c>100%</c>
      <c>0.833%</c>
      <c>50%</c>
      <c>75.417%</c>
      <c>Pessimistic exceed ratio</c>
      <c>100%</c>
      <c>100%</c>
      <c>50.833%</c>
      <c>100%</c>
      <c>Classification Result</c>
      <c>Upper Bound</c>
      <c>Undecided</c>
      <c>Undecided</c>
      <c>Upper Bound</c>
</texttable>

<t>This is the last point for &quot;1s final&quot; goal to have this Load still Undecided.
Only one 1-second trial is missing within the 120-second Goal Duration Sum,
but its result will decide the classification result.</t>

<t>The &quot;20% exceed&quot; started to classify this load as an Upper Bound
somewhere between points 2 and 3.</t>

</section>
<section anchor="point-4"><name>Point 4</name>

<t>This is the &quot;last short good&quot; point.
Code for available trial results is: 60x1s0l+60x1s1l</t>

<texttable>
      <ttcol align='left'>Goal name</ttcol>
      <ttcol align='left'>RFC2544</ttcol>
      <ttcol align='left'>TST009</ttcol>
      <ttcol align='left'>1s final</ttcol>
      <ttcol align='left'>20% exceed</ttcol>
      <c>Goal code</c>
      <c>60f60d0l0e</c>
      <c>60f120d0l50e</c>
      <c>1f120d.5l50e</c>
      <c>60f60d0.5l20e</c>
      <c>Full-length high-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>Full-length low-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>Short high-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Short low-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Balancing sum</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>15s</c>
      <c>Excess sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>45s</c>
      <c>Positive excess sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>45s</c>
      <c>Effective high-loss sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>45s</c>
      <c>Effective full sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>120s</c>
      <c>45s</c>
      <c>Effective whole sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>120s</c>
      <c>60s</c>
      <c>Missing sum</c>
      <c>0s</c>
      <c>120s</c>
      <c>0s</c>
      <c>15s</c>
      <c>Pessimistic high-loss sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>60s</c>
      <c>60s</c>
      <c>Optimistic exceed ratio</c>
      <c>100%</c>
      <c>0%</c>
      <c>50%</c>
      <c>75%</c>
      <c>Pessimistic exceed ratio</c>
      <c>100%</c>
      <c>100%</c>
      <c>50%</c>
      <c>100%</c>
      <c>Classification Result</c>
      <c>Upper Bound</c>
      <c>Undecided</c>
      <c>Lower Bound</c>
      <c>Upper Bound</c>
</texttable>

<t>The one missing trial for &quot;1s final&quot; was Low-Loss,
half of trial results are Low-Loss which exactly matches 50% exceed ratio.
This shows time savings are not guaranteed.</t>

</section>
<section anchor="point-5"><name>Point 5</name>

<t>This is the &quot;first long bad&quot; point.
Code for available trial results is: 60x1s0l+60x1s1l+1x60s.1l</t>

<texttable>
      <ttcol align='left'>Goal name</ttcol>
      <ttcol align='left'>RFC2544</ttcol>
      <ttcol align='left'>TST009</ttcol>
      <ttcol align='left'>1s final</ttcol>
      <ttcol align='left'>20% exceed</ttcol>
      <c>Goal code</c>
      <c>60f60d0l0e</c>
      <c>60f120d0l50e</c>
      <c>1f120d.5l50e</c>
      <c>60f60d0.5l20e</c>
      <c>Full-length high-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>Full-length low-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>120s</c>
      <c>60s</c>
      <c>Short high-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Short low-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Balancing sum</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>15s</c>
      <c>Excess sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>45s</c>
      <c>Positive excess sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>45s</c>
      <c>Effective high-loss sum</c>
      <c>120s</c>
      <c>60s</c>
      <c>60s</c>
      <c>45s</c>
      <c>Effective full sum</c>
      <c>120s</c>
      <c>60s</c>
      <c>180s</c>
      <c>105s</c>
      <c>Effective whole sum</c>
      <c>120s</c>
      <c>120s</c>
      <c>180s</c>
      <c>105s</c>
      <c>Missing sum</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Pessimistic high-loss sum</c>
      <c>120s</c>
      <c>120s</c>
      <c>60s</c>
      <c>45s</c>
      <c>Optimistic exceed ratio</c>
      <c>100%</c>
      <c>50%</c>
      <c>33.333%</c>
      <c>42.857%</c>
      <c>Pessimistic exceed ratio</c>
      <c>100%</c>
      <c>100%</c>
      <c>33.333%</c>
      <c>42.857%</c>
      <c>Classification Result</c>
      <c>Upper Bound</c>
      <c>Undecided</c>
      <c>Lower Bound</c>
      <c>Lower Bound</c>
</texttable>

<t>As designed for TST009 goal, one Full-Length High-Loss Trial can be tolerated.
120s worth of 1-second trials is not useful, as this is allowed when
Exceed Probability does not depend on Trial Duration.
As Goal Loss Ratio is zero, it is not possible for 60-second trials
to compensate for losses seen in 1-second results.
But Load Classification logic does not have that knowledge hardcoded,
so optimistic exceed ratio is still only 50%.</t>

<t>But the 0.1% Trial Loss Ratio is lower than &quot;20% exceed&quot; Goal Loss Ratio,
so this unexpected Full-Length Low-Loss trial changed the classification result
of this Load to Lower Bound.</t>

</section>
<section anchor="point-6"><name>Point 6</name>

<t>This is the &quot;first long good&quot; point.
Code for available trial results is: 60x1s0l+60x1s1l+1x60s.1l+1x60s0l</t>

<texttable>
      <ttcol align='left'>Goal name</ttcol>
      <ttcol align='left'>RFC2544</ttcol>
      <ttcol align='left'>TST009</ttcol>
      <ttcol align='left'>1s final</ttcol>
      <ttcol align='left'>20% exceed</ttcol>
      <c>Goal code</c>
      <c>60f60d0l0e</c>
      <c>60f120d0l50e</c>
      <c>1f120d.5l50e</c>
      <c>60f60d0.5l20e</c>
      <c>Full-length high-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>Full-length low-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>180s</c>
      <c>120s</c>
      <c>Short high-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Short low-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Balancing sum</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>15s</c>
      <c>Excess sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>45s</c>
      <c>Positive excess sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>45s</c>
      <c>Effective high-loss sum</c>
      <c>120s</c>
      <c>60s</c>
      <c>60s</c>
      <c>45s</c>
      <c>Effective full sum</c>
      <c>180s</c>
      <c>120s</c>
      <c>240s</c>
      <c>165s</c>
      <c>Effective whole sum</c>
      <c>180s</c>
      <c>120s</c>
      <c>240s</c>
      <c>165s</c>
      <c>Missing sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Pessimistic high-loss sum</c>
      <c>120s</c>
      <c>60s</c>
      <c>60s</c>
      <c>45s</c>
      <c>Optimistic exceed ratio</c>
      <c>66.667%</c>
      <c>50%</c>
      <c>25%</c>
      <c>27.273%</c>
      <c>Pessimistic exceed ratio</c>
      <c>66.667%</c>
      <c>50%</c>
      <c>25%</c>
      <c>27.273%</c>
      <c>Classification Result</c>
      <c>Upper Bound</c>
      <c>Lower Bound</c>
      <c>Lower Bound</c>
      <c>Lower Bound</c>
</texttable>

<t>This is the Low-Loss Trial the &quot;TST009&quot; goal was waiting for.
This Load is now classified for all goals; the search may end.
Or, more realistically, it can focus on larger load only,
as the three goals will want an Upper Bound (unless this Load is Max Load).</t>

</section>
</section>
<section anchor="conditional-throughput-computations"><name>Conditional Throughput Computations</name>

<t>At the end of this hypothetical search, the &quot;RFC2544&quot; goal labels the
load as an Upper Bound, making it ineligible for Conditional-Throughput
calculations. By contrast, the other three goals treat the same load as
a Lower Bound; if it is also accepted as their Relevant Lower Bound, we
can compute Conditional-Throughput values for each of them.</t>

<t>(The load under discussion is 1 000 000 frames per second.)</t>

<section anchor="goal-2"><name>Goal 2</name>

<t>The Conditional Throughput is computed from sorted list
of Full-Length Trial results. As TST009 Goal Final Trial Duration is 60 seconds,
only two of 122 Trials are considered Full-Length Trials.
One has Trial Loss Ratio of 0%, the other of 0.1%.</t>

<t><list style="symbols">
  <t>Full-length high-loss sum is 60 seconds.</t>
  <t>Full-length low-loss sum is 60 seconds.</t>
  <t>Full-length is 120 seconds.</t>
  <t>Subceed ratio is 50%.</t>
  <t>Remaining sum initially is 0.5x12s = 60 seconds.</t>
  <t>Current loss ratio initially is 100%.</t>
  <t>For first result (duration 60s, loss 0%):
  <list style="symbols">
      <t>Remaining sum is larger than zero, not exiting the loop.</t>
      <t>Set current loss ratio to this trial&#39;s Trial Loss Ratio which is 0%.</t>
      <t>Decrease the remaining sum by this trial&#39;s Trial Effective Duration.</t>
      <t>New remaining sum is 60s - 60s = 0s.</t>
    </list></t>
  <t>For second result (duration 60s, loss 0.1%):</t>
  <t>Remaining sum is not larger than zero, exiting the loop.</t>
  <t>Current loss ratio was most recently set to 0%.</t>
  <t>Current forwarding ratio is one minus the current loss ratio, so 100%.</t>
  <t>Conditional Throughput is the current forwarding ratio multiplied by the Load value.</t>
  <t>Conditional Throughput is one million frames per second.</t>
</list></t>

</section>
<section anchor="goal-3"><name>Goal 3</name>

<t>The &quot;1s final&quot; has Goal Final Trial Duration of 1 second,
so all 122 Trial Results are considered Full-Length Trials.
They are ordered like this:</t>

<figure><artwork><![CDATA[
60 1-second 0% loss trials,
1 60-second 0% loss trial,
1 60-second 0.1% loss trial,
60 1-second 1% loss trials.
]]></artwork></figure>

<t>The result does not depend on the order of 0% loss trials.</t>

<t><list style="symbols">
  <t>Full-length high-loss sum is 60 seconds.</t>
  <t>Full-length low-loss sum is 180 seconds.</t>
  <t>Full-length is 240 seconds.</t>
  <t>Subceed ratio is 50%.</t>
  <t>Remaining sum initially is 0.5x240s = 120 seconds.</t>
  <t>Current loss ratio initially is 100%.</t>
  <t>For first 61 results (duration varies, loss 0%):
  <list style="symbols">
      <t>Remaining sum is larger than zero, not exiting the loop.</t>
      <t>Set current loss ratio to this trial&#39;s Trial Loss Ratio which is 0%.</t>
      <t>Decrease the remaining sum by this trial&#39;s Trial Effective Duration.</t>
      <t>New remaining sum varies.</t>
    </list></t>
  <t>After 61 trials, duration of 60x1s + 1x60s has been subtracted from 120s, leaving 0s.</t>
  <t>For 62-th result (duration 60s, loss 0.1%):
  <list style="symbols">
      <t>Remaining sum is not larger than zero, exiting the loop.</t>
    </list></t>
  <t>Current loss ratio was most recently set to 0%.</t>
  <t>Current forwarding ratio is one minus the current loss ratio, so 100%.</t>
  <t>Conditional Throughput is the current forwarding ratio multiplied by the Load value.</t>
  <t>Conditional Throughput is one million frames per second.</t>
</list></t>

</section>
<section anchor="goal-4"><name>Goal 4</name>

<t>The Conditional Throughput is computed from sorted list
of Full-Length Trial results. As &quot;20% exceed&quot; Goal Final Trial Duration
is 60 seconds, only two of 122 Trials are considered Full-Length Trials.
One has Trial Loss Ratio of 0%, the other of 0.1%.</t>

<t><list style="symbols">
  <t>Full-length high-loss sum is 60 seconds.</t>
  <t>Full-length low-loss sum is 60 seconds.</t>
  <t>Full-length is 120 seconds.</t>
  <t>Subceed ratio is 80%.</t>
  <t>Remaining sum initially is 0.8x120s = 96 seconds.</t>
  <t>Current loss ratio initially is 100%.</t>
  <t>For first result (duration 60s, loss 0%):
  <list style="symbols">
      <t>Remaining sum is larger than zero, not exiting the loop.</t>
      <t>Set current loss ratio to this trial&#39;s Trial Loss Ratio which is 0%.</t>
      <t>Decrease the remaining sum by this trial&#39;s Trial Effective Duration.</t>
      <t>New remaining sum is 96s - 60s = 36s.</t>
    </list></t>
  <t>For second result (duration 60s, loss 0.1%):
  <list style="symbols">
      <t>Remaining sum is larger than zero, not exiting the loop.</t>
      <t>Set current loss ratio to this trial&#39;s Trial Loss Ratio which is 0.1%.</t>
      <t>Decrease the remaining sum by this trial&#39;s Trial Effective Duration.</t>
      <t>New remaining sum is 36s - 60s = -24s.</t>
    </list></t>
  <t>No more trials (and remaining sum is not larger than zero), exiting loop.</t>
  <t>Current loss ratio was most recently set to 0.1%.</t>
  <t>Current forwarding ratio is one minus the current loss ratio, so 99.9%.</t>
  <t>Conditional Throughput is the current forwarding ratio multiplied by the Load value.</t>
  <t>Conditional Throughput is 999 thousand frames per second.</t>
</list></t>

<t>Due to stricter Goal Exceed Ratio, this Conditional Throughput
is smaller than Conditional Throughput of the other two goals.</t>

</section>
</section>
</section>


  </back>

<!-- ##markdown-source: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-->

</rfc>


<?xml version="1.0" encoding="us-ascii"?>
  <?xml-stylesheet type="text/xsl" href="rfc2629.xslt" ?>
  <!-- generated by https://github.com/cabo/kramdown-rfc version 1.7.29 (Ruby 3.1.2) -->


<!DOCTYPE rfc  [
  <!ENTITY nbsp    "&#160;">
  <!ENTITY zwsp   "&#8203;">
  <!ENTITY nbhy   "&#8209;">
  <!ENTITY wj     "&#8288;">

<!ENTITY RFC1242 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.1242.xml">
<!ENTITY RFC2119 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.2119.xml">
<!ENTITY RFC2285 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.2285.xml">
<!ENTITY RFC2544 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.2544.xml">
<!ENTITY RFC8174 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.8174.xml">
<!ENTITY RFC5180 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.5180.xml">
<!ENTITY RFC6349 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.6349.xml">
<!ENTITY RFC6985 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.6985.xml">
<!ENTITY RFC8219 SYSTEM "https://bib.ietf.org/public/rfc/bibxml/reference.RFC.8219.xml">
]>


<rfc ipr="trust200902" docName="draft-ietf-bmwg-mlrsearch-12" category="info" submissionType="IETF" tocInclude="true" sortRefs="true" symRefs="true">
  <front>
    <title abbrev="MLRsearch">Multiple Loss Ratio Search</title>

    <author initials="M." surname="Konstantynowicz" fullname="Maciek Konstantynowicz">
      <organization>Cisco Systems</organization>
      <address>
        <email>mkonstan@cisco.com</email>
      </address>
    </author>
    <author initials="V." surname="Polak" fullname="Vratko Polak">
      <organization>Cisco Systems</organization>
      <address>
        <email>vrpolak@cisco.com</email>
      </address>
    </author>

    <date year="2025" month="September" day="02"/>

    <area>ops</area>
    <workgroup>Benchmarking Working Group</workgroup>
    <keyword>Internet-Draft</keyword>

    <abstract>


<?line 72?>

<t>This document specifies extensions to &quot;Benchmarking Methodology for
Network Interconnect Devices&quot; (RFC 2544) throughput search by
defining a new methodology called Multiple Loss Ratio search
(MLRsearch). MLRsearch aims to minimize search duration,
support multiple loss ratio searches, and improve result repeatability
and comparability.</t>

<t>MLRsearch is motivated by the pressing need to address the challenges of
evaluating and testing the various data plane solutions, especially in
software- based networking systems based on Commercial Off-the-Shelf
(COTS) CPU hardware vs purpose-built ASIC / NPU / FPGA hardware.</t>



    </abstract>



  </front>

  <middle>


<?line 86?>


<section anchor="introduction"><name>Introduction</name>

<t>This document describes the Multiple Loss Ratio search
(MLRsearch) methodology, optimized for determining data plane
throughput in software-based networking functions running on commodity systems with
x86/ARM CPUs (vs purpose-built ASIC / NPU / FPGA). Such network
functions can be deployed on dedicated physical appliance (e.g., a
standalone hardware device) or as virtual appliance (e.g., Virtual
Network Function running on shared servers in the compute cloud).</t>

<section anchor="purpose"><name>Purpose</name>

<t>The purpose of this document is to describe the Multiple Loss Ratio search
(MLRsearch) methodology, optimized for determining
data plane throughput in software-based networking devices and functions.</t>

<t>Applying the vanilla throughput binary search,
as specified for example in <xref target="TST009"></xref> and <xref target="RFC2544"></xref>
to software devices under test (DUTs) results in several problems:</t>

<t><list style="symbols">
  <t>Binary search takes long as most trials are done far from the
eventually found throughput.</t>
  <t>The required final trial duration and pauses between trials
prolong the overall search duration.</t>
  <t>Software DUTs show noisy trial results,
leading to a big spread of possible discovered throughput values.</t>
  <t>Throughput requires a loss of exactly zero frames, but the industry best practices
frequently allow for low but non-zero losses tolerance (<xref target="Y.1564"></xref>, test-equipment manuals).</t>
  <t>The definition of throughput is not clear when trial results are inconsistent.
(e.g., when successive trials at the same - or even a higher - offered
load yield different loss ratios, the classical <xref target="RFC1242"></xref> / <xref target="RFC2544"></xref>
throughput metric can no longer be pinned to a single, unambiguous
value.)</t>
</list></t>

<t>To address these problems,
early MLRsearch implementations employed the following enhancements:</t>

<t><list style="numbers" type="1">
  <t>Allow multiple short trials instead of one big trial per load.
  <list style="symbols">
      <t>Optionally, tolerate a percentage of trial results with higher loss.</t>
    </list></t>
  <t>Allow searching for multiple Search Goals, with differing loss ratios.
  <list style="symbols">
      <t>Any trial result can affect each Search Goal in principle.</t>
    </list></t>
  <t>Insert multiple coarse targets for each Search Goal, earlier ones need
to spend less time on trials.
  <list style="symbols">
      <t>Earlier targets also aim for lesser precision.</t>
      <t>Use Forwarding Rate (FR) at Maximum Offered Load (FRMOL), as defined
in Section 3.6.2 of <xref target="RFC2285"></xref>, to initialize bounds.</t>
    </list></t>
  <t>Be careful when dealing with inconsistent trial results.
  <list style="symbols">
      <t>Reported throughput is smaller than the smallest load with high loss.</t>
      <t>Smaller load candidates are measured first.</t>
    </list></t>
  <t>Apply several time-saving load selection heuristics that deliberately
prevent the bounds from narrowing unnecessarily.</t>
</list></t>

<t>Enhacements 1, 2 and partly 4 are formalized as MLRsearch Specification
within this document, other implementation details are out the scope.</t>

<t>The remaining enhancements are treated as implementation details,
thus achieving high comparability without limiting future improvements.</t>

<t>MLRsearch configuration
supports both conservative settings and aggressive settings.
Conservative enough settings lead to results
unconditionally compliant with <xref target="RFC2544"></xref>,
but without much improvement on search duration and repeatability - see
<xref target="mlrsearch-compliant-with-rfc-2544">MLRsearch Compliant with RFC 2544</xref>.
Conversely, aggressive settings lead to shorter search durations
and better repeatability, but the results are not compliant with <xref target="RFC2544"></xref>.
Exact settings are not specified, but see the discussion in
<xref target="overview-of-rfc-2544-problems">Overview of RFC 2544 Problems</xref>
for the impact of different settings on result quality.</t>

<t>This document does not change or obsolete any part of <xref target="RFC2544"></xref>.</t>

</section>
<section anchor="positioning-within-bmwg-methodologies"><name>Positioning within BMWG Methodologies</name>

<t>The Benchmarking Methodology Working Group (BMWG) produces recommendations (RFCs)
that describe various benchmarking methodologies for use in a controlled laboratory environment.
A large number of these benchmarks are based on the terminology from <xref target="RFC1242"></xref>
and the foundational methodology from <xref target="RFC2544"></xref>.
A common pattern has emerged where BMWG documents reference the methodology of <xref target="RFC2544"></xref>
and augment it with specific requirements for testing particular network systems or protocols,
without modifying the core benchmark definitions.</t>

<t>While BMWG documents are formally recommendations,
they are widely treated as industry norms to ensure the comparability of results between different labs.
The set of benchmarks defined in <xref target="RFC2544"></xref>, in particular,
became a de facto standard for performance testing.
In this context, the MLRsearch Specification formally defines a new
class of benchmarks that fits within the wider <xref target="RFC2544"></xref> framework
(see <xref target="scope">Scope </xref>).</t>

<t>A primary consideration in the design of MLRsearch is the trade-off
between configurability and comparability. The methodology&#39;s flexibility,
especially the ability to define various sets of Search Goals,
supporting both single-goal and multiple-goal benchmarks in an unified way
is powerful for detailed characterization and internal testing.
However, this same flexibility is detrimental to inter-lab comparability
unless a specific, common set of Search Goals is agreed upon.</t>

<t>Therefore, MLRsearch should not be seen as a direct extension
nor a replacement for the <xref target="RFC2544"></xref> Throughput benchmark.
Instead, this document provides a foundational methodology
that future BMWG documents can use to define new, specific, and comparable benchmarks
by mandating particular Search Goal configurations.
For operators of existing test procedures, it is worth noting
that many test setups measuring <xref target="RFC2544"></xref> Throughput
can be adapted to produce results compliant with the MLRsearch Specification,
often without affecting Trials,
merely by augmenting the content of the final test report.</t>

</section>
</section>
<section anchor="overview-of-rfc-2544-problems"><name>Overview of RFC 2544 Problems</name>

<t>This section describes the problems affecting usability
of various performance testing methodologies,
mainly a binary search for <xref target="RFC2544"></xref> unconditionally compliant throughput.</t>

<section anchor="long-search-duration"><name>Long Search Duration</name>

<t>The proliferation of software DUTs, with frequent software updates and a</t>

<t>number of different frame processing modes and configurations,
has increased both the number of performance tests
required to verify the DUT update and the frequency of running those tests.
This makes the overall test execution time even more important than before.</t>

<t>The throughput definition per <xref target="RFC2544"></xref> restricts the potential
for time-efficiency improvements.
The bisection method, when used in a manner unconditionally compliant
with <xref target="RFC2544"></xref>, is excessively slow due to two main factors.</t>

<t>Firstly, a significant amount of time is spent on trials
with loads that, in retrospect, are far from the final determined throughput.</t>

<t>Secondly, <xref target="RFC2544"></xref> does not specify any stopping condition for
throughput search, so users of testing equipment implementing the
procedure already have access to a limited trade-off
between search duration and achieved precision.
However, each of the full 60-second trials doubles the precision.</t>

<t>As such, not many trials can be removed without a substantial loss of precision.</t>

<t>For reference, here is a brief <xref target="RFC2544"></xref> throughput binary
(bisection) reminder, based on Sections 24 and 26 of [RFC2544:</t>

<t><list style="symbols">
  <t>Set Max = line-rate and Min = a proven loss-free load.</t>
  <t>Run a single 60-s trial at the midpoint.</t>
  <t>Zero-loss -&gt; midpoint becomes new Min; any loss-&gt; new Max.</t>
  <t>Repeat until the Max-Min gap meets the desired precision, then report
the highest zero-loss rate for every mandatory frame size.</t>
</list></t>

</section>
<section anchor="dut-in-sut"><name>DUT in SUT</name>

<t><xref target="RFC2285"></xref> defines:</t>

<t>DUT as:</t>

<t><list style="symbols">
  <t>The network frame forwarding device to which stimulus is offered and
response measured Section 3.1.1 of <xref target="RFC2285"></xref>.</t>
</list></t>

<t>SUT as:</t>

<t><list style="symbols">
  <t>The collective set of network devices as a single entity to which
stimulus is offered and response measured Section 3.1.2 of <xref target="RFC2285"></xref>.</t>
</list></t>

<t>Section 19 of <xref target="RFC2544"></xref> specifies a test setup with an external tester
stimulating the networking system, treating it either as a single
Device Under Test (DUT), or as a system of devices, a System Under
Test (SUT).</t>

<t>For software-based data-plane forwarding running on commodity x86/ARM
CPUs, the SUT comprises not only the forwarding application itself, the
DUT, but the entire execution environment: host hardware, firmware and
kernel/hypervisor services, as well as any other software workloads
that share the same CPUs, memory and I/O resources.</t>

<t>Given that a SUT is a shared multi-tenant environment,
the DUT might inadvertently
experience interference from the operating system
or other software operating on the same server.</t>

<t>Some of this interference can be mitigated.
For instance, in multi-core CPU systems, pinning DUT program threads to
specific CPU cores
and isolating those cores can prevent context switching.</t>

<t>Despite taking all feasible precautions, some adverse effects may still impact
the DUT&#39;s network performance.
In this document, these effects are collectively
referred to as SUT noise, even if the effects are not as unpredictable
as what other engineering disciplines call noise.</t>

<t>A DUT can also exhibit fluctuating performance itself,
for reasons not related to the rest of SUT. For example, this can be
due to pauses in execution as needed for internal stateful processing.
In many cases this may be an expected per-design behavior,
as it would be observable even in a hypothetical scenario
where all sources of SUT noise are eliminated.
Such behavior affects trial results in a way similar to SUT noise.
As the two phenomena are hard to distinguish,
in this document the term &#39;noise&#39; is used to encompass
both the internal performance fluctuations of the DUT
and the genuine noise of the SUT.</t>

<t>A simple model of SUT performance consists of an idealized noiseless performance,
and additional noise effects.
For a specific SUT, the noiseless performance is assumed to be constant,
with all observed performance variations being attributed to noise.
The impact of the noise can vary in time, sometimes wildly,
even within a single trial.
The noise can sometimes be negligible, but frequently
it lowers the observed SUT performance as observed in trial results.</t>

<t>In this simple model, a SUT does not have a single performance value, it has a spectrum.
One end of the spectrum is the idealized noiseless performance value,
the other end can be called a noiseful performance.
In practice, trial results close to the noiseful end of the spectrum
happen only rarely.
The worse a possible performance value is, the more rarely it is seen in a trial.
Therefore, the extreme noiseful end of the SUT spectrum is not observable
among trial results.</t>

<t>Furthermore, the extreme noiseless end of the SUT spectrum is unlikely
to be observable, this time because minor noise events almost always
occur during each trial, nudging the measured performance slightly
below the theoretical maximum.</t>

<t>Unless specified otherwise, this document&#39;s focus is
on the potentially observable ends of the SUT performance spectrum,
as opposed to the extreme ones.</t>

<t>When focusing on the DUT, the benchmarking effort should ideally aim
to eliminate only the SUT noise from SUT measurements.
However, this is currently not feasible in practice,
as there are no realistic enough models that would be capable
to distinguish SUT noise from DUT fluctuations
(based on the available literature at the time of writing).</t>

<t>Provided SUT execution environment and any co-resident workloads place
only negligible demands on SUT shared resources, so that
the DUT remains the principal performance limiter,
the DUT&#39;s ideal noiseless performance is defined
as the noiseless end of the SUT performance spectrum.</t>

<t>Note that by this definition, DUT noiseless performance
also minimizes the impact of DUT fluctuations, as much as realistically possible
for a given trial duration.</t>

<t>The MLRsearch methodology aims to solve the DUT in SUT problem
by estimating the noiseless end of the SUT performance spectrum
using a limited number of trial results.</t>

<t>Improvements to the throughput search algorithm, aimed at better dealing
with software networking SUT and DUT setups, should adopt methods that
explicitly model SUT-generated noise, enabling to derive surrogate
metrics that approximate the (proxies for) DUT noiseless performance
across a range of SUT noise-tolerance levels.</t>

</section>
<section anchor="repeatability-and-comparability"><name>Repeatability and Comparability</name>

<t><xref target="RFC2544"></xref> does not suggest repeating throughput search. Also, note that
from simply one discovered throughput value,
it cannot be determined how repeatable that value is.
Unsatisfactory repeatability then leads to unacceptable comparability,
as different benchmarking teams may obtain varying throughput values
for the same SUT, exceeding the expected differences from search precision.
Repeatability is important also when the test procedure is kept the same,
but SUT is varied in small ways. For example, during development
of software-based DUTs, repeatability is needed to detect small regressions.</t>

<t><xref target="RFC2544"></xref> throughput requirements (60 seconds trial and
no tolerance of a single frame loss) affect the throughput result as follows:</t>

<t>The SUT behavior close to the noiseful end of its performance spectrum
consists of rare occasions of significantly low performance,
but the long trial duration makes those occasions not so rare on the trial level.
Therefore, the binary search results tend to wander away from the noiseless end
of SUT performance spectrum, more frequently and more widely than shorter
trials would, thus causing unacceptable throughput repeatability.</t>

<t>The repeatability problem can be better addressed by defining a search procedure
that identifies a consistent level of performance,
even if it does not meet the strict definition of throughput in <xref target="RFC2544"></xref>.</t>

<t>According to the SUT performance spectrum model, better repeatability
will be at the noiseless end of the spectrum.
Therefore, solutions to the DUT in SUT problem
will help also with the repeatability problem.</t>

<t>Conversely, any alteration to <xref target="RFC2544"></xref> throughput search
that improves repeatability should be considered
as less dependent on the SUT noise.</t>

<t>An alternative option is to simply run a search multiple times, and
report some statistics (e.g., average and standard deviation, and/or
percentiles like p95).</t>

<t>This can be used for a subset of tests deemed more important,
but it makes the search duration problem even more pronounced.</t>

</section>
<section anchor="throughput-with-non-zero-loss"><name>Throughput with Non-Zero Loss</name>

<dl>
  <dt>Section 3.17 of <xref target="RFC1242"></xref> defines throughput as:</dt>
  <dd>
    <t>The maximum rate at which none of the offered frames
are dropped by the device.</t>
  </dd>
  <dt>Then, it says:</dt>
  <dd>
    <t>Since even the loss of one frame in a
data stream can cause significant delays while
waiting for the higher-level protocols to time out,
it is useful to know the actual maximum data
rate that the device can support.</t>
  </dd>
</dl>

<t>However, many benchmarking teams accept a low,
non-zero loss ratio as the goal for their load search.</t>

<t>Motivations are many:</t>

<t><list style="symbols">
  <t>Networking protocols tolerate frame loss better,
compared to the time when <xref target="RFC1242"></xref> and <xref target="RFC2544"></xref> were specified.</t>
  <t>Increased link speeds require trials sending way more frames within the same duration,
increasing the chance of a small SUT performance fluctuation
being enough to cause frame loss.</t>
  <t>Because noise-related drops usually arrive in small bursts, their
impact on the trial&#39;s overall frame loss ratio is diluted by the
longer intervals in which the SUT operates close to its noiseless
performance; consequently, the averaged Trial Loss Ratio can still
end up below the specified Goal Loss Ratio value.</t>
  <t>If an approximation of the SUT noise impact on the Trial Loss Ratio is known,
it can be set as the Goal Loss Ratio (see definitions of
Trial and Goal terms in <xref target="trial-terms">Trial Terms</xref> and <xref target="goal-terms">Goal Terms</xref>).</t>
  <t>For more information, see an earlier draft <xref target="Lencze-Shima"></xref> (Section 5)
and references there.</t>
</list></t>

<t>Regardless of the validity of all similar motivations,
support for non-zero loss goals makes a
search algorithm more user-friendly.
<xref target="RFC2544"></xref> throughput is not user-friendly in this regard.</t>

<t>Furthermore, allowing users to specify multiple loss ratio values,
and enabling a single search to find all relevant bounds,
significantly enhances the usefulness of the search algorithm.</t>

<t>Searching for multiple Search Goals also helps to describe the SUT performance
spectrum better than the result of a single Search Goal.
For example, the repeated wide gap between zero and non-zero loss loads
indicates the noise has a large impact on the observed performance,
which is not evident from a single goal load search procedure result.</t>

<t>It is easy to modify the vanilla bisection to find a lower bound
for the load that satisfies a non-zero Goal Loss Ratio.
But it is not that obvious how to search for multiple goals at once,
hence the support for multiple Search Goals remains a problem.</t>

<t>At the time of writing there does not seem to be a consensus in the industry
on which ratio value is the best.
For users, performance of higher protocol layers is important, for
example, goodput of TCP connection (TCP throughput, <xref target="RFC6349"></xref>), but relationship
between goodput and loss ratio is not simple. Refer to
<xref target="Lencze-Kovacs-Shima"></xref> for examples of various corner cases,
Section 3 of <xref target="RFC6349"></xref> for loss ratios acceptable for an accurate
measurement of TCP throughput, and <xref target="Ott-Mathis-Semke-Mahdavi"></xref> for
models and calculations of TCP performance in presence of packet loss.</t>

</section>
<section anchor="inconsistent-trial-results"><name>Inconsistent Trial Results</name>

<t>While performing throughput search by executing a sequence of
measurement trials, there is a risk of encountering inconsistencies
between trial results.</t>

<t>Examples include, but are not limited to:</t>

<t><list style="symbols">
  <t>A trial at the same load (same or different trial duration) results
in a different Trial Loss Ratio.</t>
  <t>A trial at a larger load (same or different trial duration) results
in a lower Trial Loss Ratio.</t>
</list></t>

<t>The plain bisection never encounters inconsistent trials.
But <xref target="RFC2544"></xref> hints about the possibility of inconsistent trial results,
in two places in its text.
The first place is Section 24 of <xref target="RFC2544"></xref>,
where full trial durations are required,
presumably because they can be inconsistent with the results
from short trial durations.
The second place is Section 26.3 of <xref target="RFC2544"></xref>,
where two successive zero-loss trials
are recommended, presumably because after one zero-loss trial
there can be a subsequent inconsistent non-zero-loss trial.</t>

<t>A robust throughput search algorithm needs to decide how to continue
the search in the presence of such inconsistencies.
Definitions of throughput in <xref target="RFC1242"></xref> and <xref target="RFC2544"></xref> are not specific enough
to imply a unique way of handling such inconsistencies.</t>

<t>Ideally, there will be a definition of a new quantity which both generalizes
throughput for non-zero Goal Loss Ratio values
(and other possible repeatability enhancements), while being precise enough
to force a specific way to resolve trial result inconsistencies.
But until such a definition is agreed upon, the correct way to handle
inconsistent trial results remains an open problem.</t>

<t>Relevant Lower Bound is the MLRsearch term that addresses this problem.</t>

</section>
</section>
<section anchor="requirements-language"><name>Requirements Language</name>

<t>The key words &quot;MUST&quot;, &quot;MUST NOT&quot;, &quot;REQUIRED&quot;, &quot;SHALL&quot;, &quot;SHALL NOT&quot;, &quot;SHOULD&quot;,
&quot;SHOULD NOT&quot;, &quot;RECOMMENDED&quot;, &quot;NOT RECOMMENDED&quot;, &quot;MAY&quot;, and &quot;OPTIONAL&quot;
in this document are to be interpreted as described in BCP 14, <xref target="RFC2119"></xref>
and <xref target="RFC8174"></xref> when, and only when, they appear in all capitals, as shown here.</t>

<t>This document is categorized as an Informational RFC.
While it does not mandate the adoption of the MLRsearch methodology,
it uses the normative language of BCP 14 to provide an unambiguous specification.
This ensures that if a test procedure or test report claims compliance with the MLRsearch Specification,
it MUST adhere to all the absolute requirements defined herein.
The use of normative language is intended to promote repeatable and comparable results
among those who choose to implement this methodology.</t>

</section>
<section anchor="mlrsearch-specification"><name>MLRsearch Specification</name>

<t>This chapter provides all technical definitions
needed for evaluating whether a particular test procedure
complies with MLRsearch Specification.</t>

<t>Some terms used in the specification are capitalized.
It is just a stylistic choice for this document,
reminding the reader this term is introduced, defined or explained
elsewhere in the document. Lowercase variants are equally valid.</t>

<t>This document does not separate terminology from methodology. Terms are
fully specified and discussed in their own subsections, under sections
titled &quot;Terms&quot;. This way, the list of terms is visible in table of
contents.</t>

<t>Each per term subsection contains a short <em>Definition</em> paragraph
containing a minimal definition and all strict requirements, followed
by <em>Discussion</em> paragraphs focusing on important consequences and
recommendations. Requirements about how other components can use the
defined quantity are also included in the discussion.</t>

<section anchor="scope"><name>Scope</name>

<t>This document specifies the Multiple Loss Ratio search (MLRsearch) methodology.
The MLRsearch Specification details a new class of benchmarks
by listing all terminology definitions and methodology requirements.
The definitions support &quot;multi-goal&quot; benchmarks, with &quot;single-goal&quot; as a subset.</t>

<t>The normative scope of this specification includes:</t>

<t><list style="symbols">
  <t>The terminology for all required quantities and their attributes.</t>
  <t>An abstract architecture consisting of functional components
(Manager, Controller, Measurer) and the requirements for their inputs and outputs.</t>
  <t>The required structure and attributes of the Controller Input,
including one or more Search Goal instances.</t>
  <t>The required logic for Load Classification, which determines whether a given Trial Load
qualifies as a Lower Bound or an Upper Bound for a Search Goal.</t>
  <t>The required structure and attributes of the Controller Output,
including a Goal Result for each Search Goal.</t>
</list></t>

<section anchor="relationship-to-rfc-2544"><name>Relationship to RFC 2544</name>

<t>MLRsearch Specification is an independent methodology
and does not change or obsolete any part of <xref target="RFC2544"></xref>.</t>

<t>This specification permits deviations from the Trial procedure
as described in <xref target="RFC2544"></xref>. Any deviation from the <xref target="RFC2544"></xref> procedure
must be documented explicitly in the Test Report,
and such variations remain outside the scope of the original <xref target="RFC2544"></xref> benchmarks.</t>

<t>A specific single-goal MLRsearch benchmark can be configured
to be compliant with <xref target="RFC2544"></xref> Throughput,
and most procedures reporting <xref target="RFC2544"></xref> Throughput
can be adapted to satisfy also MLRsearch requirements for specific search goal.</t>

</section>
<section anchor="applicability-of-other-specifications"><name>Applicability of Other Specifications</name>

<t>Methodology extensions from other BMWG documents that specify details
for testing particular DUTs, configurations, or protocols
(e.g., by defining a particular Traffic Profile) are considered orthogonal
to MLRsearch and are applicable to a benchmark conducted using MLRsearch methodology.</t>

</section>
<section anchor="out-of-scope"><name>Out of Scope</name>

<t>The following aspects are explicitly out of the normative scope of this document:</t>

<t><list style="symbols">
  <t>This specification does not mandate or recommend any single,
universal Search Goal configuration for all use cases.
The selection of Search Goal parameters is left
to the operator of the test procedure or may be defined by future specifications.</t>
  <t>The internal heuristics or algorithms used by the Controller to select Trial Input values
(e.g., the load selection strategy) are considered implementation details.</t>
  <t>The potential for, and the effects of, interference between different Search Goal instances
within a multiple-goal search are considered outside the normative scope of this specification.</t>
</list></t>

</section>
</section>
<section anchor="architecture-overview"><name>Architecture Overview</name>

<t>Although the normative text references only terminology that has already
been introduced, explanatory passages beside it sometimes profit from
terms that are defined later in the document. To keep the initial
read-through clear, this informative section offers a concise, top-down
sketch of the complete MLRsearch architecture.</t>

<t>The architecture is modelled as a set of abstract, interacting
components. Information exchange between components is expressed in an
imperative-programming style: one component &quot;calls&quot; another, supplying
inputs (arguments) and receiving outputs (return values). This notation
is purely conceptual; actual implementations need not exchange explicit
messages. When the text contrasts alternative behaviours, it refers to
the different implementations of the same component.</t>

<t>A test procedure is considered compliant with the MLRsearch
Specification if it can be conceptually decomposed into the abstract
components defined herein, and each component satisfies the
requirements defined for its corresponding MLRsearch element.</t>

<t>The Measurer component is tasked to perform Trials,
the Controller component is tasked to select Trial Durations and Loads,
the Manager component is tasked to pre-configure involved entities
and to produce the Test Report.
The Test Report explicitly states Search Goals (as Controller Input)
and corresponding Goal Results (Controller Output).</t>

<t>This constitutes one benchmark (single-goal or multi-goal).
Repeated or slightly differing benchmarks are realized
by calling Controller once for each benchmark.</t>

<t>The Manager calls a Controller once,
and the Controller then invokes the Measurer repeatedly
until Controler decides it has enough information to return outputs.</t>

<t>The part during which the Controller invokes the Measurer is termed the
Search. Any work the Manager performs either before invoking the
Controller or after Controller returns, falls outside the scope of the
Search.</t>

<t>MLRsearch Specification prescribes Regular Search Results and recommends
corresponding search completion conditions.</t>

<t>Irregular Search Results are also allowed,
they have different requirements and their corresponding stopping conditions are out of scope.</t>

<t>Search Results are based on Load Classification. When measured enough,
a chosen Load can either achieve or fail each Search Goal
(separately), thus becoming a Lower Bound or an Upper Bound for that
Search Goal.</t>

<t>When the Relevant Lower Bound is close enough to Relevant Upper Bound
according to Goal Width, the Regular Goal Result is found.
Search stops when all Regular Goal Results are found,
or when some Search Goals are proven to have only Irregular Goal Results.</t>

<section anchor="test-report"><name>Test Report</name>

<t>A primary responsibility of the Manager is to produce a Test Report,
which serves as the final and formal output of the test procedure.</t>

<t>This document does not provide a single, complete, normative definition
for the structure of the Test Report. For example, Test Report may contain
results for a single benchmark, or it could aggregate results of many benchmarks.</t>

<t>Instead, normative requirements for the content of the Test Report
are specified throughout this document in conjunction
with the definitions of the quantities and procedures to which they apply.
Readers should note that any clause requiring a value to be &quot;reported&quot;
or &quot;stated in the test report&quot; constitutes a normative requirement
on the content of this final artifact.</t>

<t>Even where not stated explicitly, the &quot;Reporting format&quot;
paragraphs in <xref target="RFC2544"></xref> sections are still requirements on Test Report
if they apply to a MLRsearch benchmark.</t>

</section>
<section anchor="behavior-correctness"><name>Behavior Correctness</name>

<t>MLRsearch Specification by itself does not guarantee that
the Search ends in finite time, as the freedom the Controller has
for Load selection also allows for clearly deficient choices.</t>

<t>For deeper insights on these matters, refer to <xref target="FDio-CSIT-MLRsearch"></xref>.</t>

<t>The primary MLRsearch implementation, used as the prototype
for this specification, is <xref target="PyPI-MLRsearch"></xref>.</t>

</section>
</section>
<section anchor="quantities"><name>Quantities</name>

<t>MLRsearch Specification
uses a number of specific quantities,
some of them can be expressed in several different units.</t>

<t>In general, MLRsearch Specification does not require particular units to be used,
but it is REQUIRED for the test report to state all the units.
For example, ratio quantities can be dimensionless numbers between zero and one,
but may be expressed as percentages instead.</t>

<t>For convenience, a group of quantities can be treated as a composite quantity.
One constituent of a composite quantity is called an attribute.
A group of attribute values is called an instance of that composite quantity.</t>

<t>Some attributes may depend on others and can be calculated from other
attributes. Such quantities are called derived quantities.</t>

<section anchor="current-and-final-values"><name>Current and Final Values</name>

<t>Some quantities are defined in a way that makes it possible to compute their
values in the middle of a Search. Other quantities are specified so
that their values can be computed only after a Search ends. Some
quantities are important only after a Search ended, but their values
are computable also before a Search ends.</t>

<t>For a quantity that is computable before a Search ends,
the adjective <strong>current</strong> is used to mark a value of that quantity
available before the Search ends.
When such value is relevant for the search result, the adjective <strong>final</strong>
is used to denote the value of that quantity at the end of the Search.</t>

<t>If a time evolution of such a dynamic quantity is guided by
configuration quantities, those adjectives can be used to distinguish
quantities. For example, if the current value of &quot;duration&quot;
(dynamic quantity) increases from &quot;initial duration&quot; to &quot;final
duration&quot; (configuration quantities), all the quoted names denote
separate but related quantities. As the naming suggests, the final
value of &quot;duration&quot; is expected to be equal to &quot;final duration&quot; value.</t>

</section>
</section>
<section anchor="existing-terms"><name>Existing Terms</name>

<t>This specification relies on the following three documents that should
be consulted before attempting to make use of this document:</t>

<t><list style="symbols">
  <t>&quot;Benchmarking Terminology for Network Interconnect Devices&quot; <xref target="RFC1242"></xref>
contains basic term definitions.</t>
  <t>&quot;Benchmarking Terminology for LAN Switching Devices&quot; <xref target="RFC2285"></xref> adds
more terms and discussions, describing some known network
benchmarking situations in a more precise way.</t>
  <t>&quot;Benchmarking Methodology for Network Interconnect Devices&quot;
 <xref target="RFC2544"></xref> contains discussions about terms and additional
 methodology requirements.</t>
</list></t>

<t>Definitions of some central terms from above documents are copied and
discussed in the following subsections.</t>

<section anchor="sut"><name>SUT</name>

<t>Defined in Section 3.1.2 of <xref target="RFC2285"></xref> as follows.</t>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The collective set of network devices to which stimulus is offered
as a single entity and response measured.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>An SUT consisting of a single network device is allowed by this definition.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In software-based networking SUT may comprise multitude of
networking applications and the entire host hardware and software
execution environment.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>SUT is the only entity that can be benchmarked directly,
even though only the performance of some sub-components are of interest.</t>
  </dd>
</dl>

</section>
<section anchor="dut"><name>DUT</name>

<t>Defined in Section 3.1.1 of <xref target="RFC2285"></xref> as follows.</t>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The network forwarding device
to which stimulus is offered and response measured.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Contrary to SUT, the DUT stimulus and response are frequently
initiated and observed only indirectly, on different parts of SUT.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>DUT, as a sub-component of SUT, is only indirectly mentioned in
MLRsearch Specification, but is of key relevance for its motivation.
The device can represent a software-based networking functions running
on commodity x86/ARM CPUs (vs purpose-built ASIC / NPU / FPGA).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>A well-designed SUTs should have the primary DUT as their performance bottleneck.
The ways to achieve that are outside of MLRsearch Specification scope.</t>
  </dd>
</dl>

</section>
<section anchor="trial"><name>Trial</name>

<t>A trial is the part of the test described in Section 23 of <xref target="RFC2544"></xref>.</t>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A particular test consists of multiple trials.  Each trial returns
one piece of information, for example the loss rate at a particular
input frame rate.  Each trial consists of a number of phases:</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>a) If the DUT is a router, send the routing update to the &quot;input&quot;
port and pause two seconds to be sure that the routing has settled.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>b)  Send the &quot;learning frames&quot; to the &quot;output&quot; port and wait 2
seconds to be sure that the learning has settled.  Bridge learning
frames are frames with source addresses that are the same as the
destination addresses used by the test frames.  Learning frames for
other protocols are used to prime the address resolution tables in
the DUT.  The formats of the learning frame that should be used are
shown in the Test Frame Formats document.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>c) Run the test trial.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>d) Wait for two seconds for any residual frames to be received.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>e) Wait for at least five seconds for the DUT to restabilize.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The traffic is sent only in phase c) and received in phases c) and d).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Trials are the only stimuli the SUT is expected to experience during the Search.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In some discussion paragraphs, it is useful to consider the traffic
as sent and received by a tester, as implicitly defined
in Section 6 of <xref target="RFC2544"></xref>.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The definition describes some traits, not using capitalized verbs
to signify strength of the requirements.
For the purposes of the MLRsearch Specification,
the test procedure MAY deviate from the <xref target="RFC2544"></xref> description,
but any such deviation MUST be described explicitly in the Test Report.
It is still RECOMMENDED to not deviate from the description,
as any deviation weakens comparability.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>An example of deviation from <xref target="RFC2544"></xref> is using shorter wait times,
compared to those described in phases a), b), d) and e).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The <xref target="RFC2544"></xref> document itself seems to be treating phase b)
as any type of configuration that cannot be configured only once (by Manager,
before Search starts), as some crucial SUT state could time-out during the Search.
It is RECOMMENDED to interpret the &quot;learning frames&quot; to be
any such time-sensitive per-trial configuration method,
with bridge MAC learning being only one possible examples.
Appendix C.2.4.1 of <xref target="RFC2544"></xref> lists another example: ARP with wait time of 5 seconds.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Some methodologies describe recurring tests.
If those are based on Trials, they are treated as multiple independent Trials.</t>
  </dd>
</dl>

</section>
</section>
<section anchor="trial-terms"><name>Trial Terms</name>

<t>This section defines new and redefine existing terms for quantities
relevant as inputs or outputs of a Trial, as used by the Measurer component.
This includes also any derived quantities related to results of one Trial.</t>

<section anchor="trial-duration"><name>Trial Duration</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Duration is the intended duration of the phase c) of a Trial.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The value MUST be positive.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>While any positive real value may be provided, some Measurer
implementations MAY limit possible values, e.g., by rounding down to
nearest integer in seconds. In that case, it is RECOMMENDED to give
such inputs to the Controller so that the Controller
only uses the accepted values.</t>
  </dd>
</dl>

</section>
<section anchor="trial-load"><name>Trial Load</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Load is the per-interface Intended Load for a Trial.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Load is equivalent to the quantities defined
as constant load (Section 3.4 of <xref target="RFC1242"></xref>),
data rate (Section 14 of <xref target="RFC2544"></xref>),
and Intended Load (Section 3.5.1 of <xref target="RFC2285"></xref>),
in the sense that all three definitions specify that this value
applies to one (input or output) interface.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For specification purposes, it is assumed that this is a constant load by default,
as specified in Section 3.4 of <xref target="RFC1242"></xref>).
Informally, Traffic Load is a single number that can &quot;scale&quot; any traffic pattern
as long as the intuition of load intended against a single interface can be applied.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It MAY be possible to use a Trial Load value to describe a non-constant traffic
(using average load when the traffic consists of repeated bursts of frames
e.g., as suggested in Section 21 of <xref target="RFC2544"></xref>).
In the case of a non-constant load, the Test Report
MUST explicitly mention how exactly non-constant the traffic is
and how it reacts to Traffic Load value.
But the rest of the MLRsearch Specification assumes that is not the case,
to avoid discussing corner cases (e.g., which values are possible within medium limitations).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Similarly, traffic patterns where different interfaces are subject to different loads
MAY be described by a single Trial Load value (e.g. using largest load among interfaces),
but again the Test Report MUST explicitly describe how the traffic pattern
reacts to Traffic Load value,
and this specification does not discuss all the implications of that approach.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In the common case of bidirectional traffic, as described in
Section 14. Bidirectional Traffic of <xref target="RFC2544"></xref>,
Trial Load is the data rate per direction, half of aggregate data rate.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Traffic patterns where a single Trial Load does not describe their scaling
cannot be used for MLRsearch benchmarks.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Similarly to Trial Duration, some Measurers MAY limit the possible values
of Trial Load. Contrary to Trial Duration,
documenting such behavior in the test report is OPTIONAL.
This is because the load differences are negligible (and frequently
undocumented) in practice.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The Controller MAY select Trial Load and Trial Duration values in a way
that would not be possible to achieve using any integer number of data frames.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>If a particular Trial Load value is not tied to a single Trial,
e.g., if there are no Trials yet or if there are multiple Trials,
this document uses a shorthand <strong>Load</strong>.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The test report MAY present the aggregate load across multiple
interfaces, treating it as the same quantity expressed using different
units. Each reported Trial Load value MUST state unambiguously whether
it refers to (i) a single interface, (ii) a specified subset of
interfaces (e.g., such as all logical interfaces mapped to one physical
port), or (iii) the total across every interface. For any aggregate
load value, the report MUST also give the fixed conversion factor that
links the per-interface and multi-interface load values.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The per-interface value remains the primary unit, consistent
with prevailing practice in <xref target="RFC1242"></xref>, <xref target="RFC2544"></xref>, and <xref target="RFC2285"></xref>.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The last paragraph also applies to other terms related to Load.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For example, tests with symmetric bidirectional traffic
can report load-related values as &quot;bidirectional load&quot;
(double of &quot;unidirectional load&quot;).</t>
  </dd>
</dl>

</section>
<section anchor="trial-input"><name>Trial Input</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Input is a composite quantity, consisting of two attributes:
Trial Duration and Trial Load.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>When talking about multiple Trials, it is common to say &quot;Trial Inputs&quot;
to denote all corresponding Trial Input instances.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>A Trial Input instance acts as the input for one call of the Measurer component.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Contrary to other composite quantities, MLRsearch implementations
MUST NOT add optional attributes into Trial Input.
This improves interoperability between various implementations of
a Controller and a Measurer.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Note that both attributes are <strong>intended</strong> quantities,
as only those can be fully controlled by the Controller.
The actual offered quantities, as realized by the Measurer, can be different
(and must be different if not multiplying into integer number of frames),
but questions around those offered quantities are generally
outside of the scope of this document.</t>
  </dd>
</dl>

</section>
<section anchor="traffic-profile"><name>Traffic Profile</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Traffic Profile is a composite quantity containing
all attributes other than Trial Load and Trial Duration,
that are needed for unique determination of the Trial to be performed.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>All the attributes are assumed to be constant during the Search,
and the composite is configured on the Measurer by the Manager
before the Search starts.
This is why the traffic profile is not part of the Trial Input.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Specification of traffic properties included in the Traffic Profile is
the responsibility of the Manager, but the specific configuration mechanisms
are outside of the scope of this docunment.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, implementations of the Manager and the Measurer
must be aware of their common set of capabilities,
so that Traffic Profile instance uniquely defines the traffic during the Search.
Typically, Manager and Measurer implementations are tightly integrated.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Integration efforts between independent Manager and Measurer implementations
are outside of the scope of this document.
An example standardization effort is <xref target="Vassilev"></xref>,
a draft at the time of writing.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Examples of traffic properties include:
- Data link frame size
- Fixed sizes as listed in Section 3.5 of <xref target="RFC1242"></xref> and in Section
  9 of <xref target="RFC2544"></xref>
- IMIX mixed sizes as defined in <xref target="RFC6985"></xref>
- Frame formats and protocol addresses
- Section 8, 12 and Appendix C of <xref target="RFC2544"></xref>
- Symmetric bidirectional traffic
- Section 14 of <xref target="RFC2544"></xref>.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Other traffic properties that need to be somehow specified
in Traffic Profile, and MUST be mentioned in Test Report
if they apply to the benchmark, include:</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t><list style="symbols">
      <t>bidirectional traffic from Section 14 of <xref target="RFC2544"></xref>,</t>
      <t>fully meshed traffic from Section 3.3.3 of <xref target="RFC2285"></xref>,</t>
      <t>modifiers from Section 11 of <xref target="RFC2544"></xref>.</t>
      <t>IP version mixing from Section 5.3 of <xref target="RFC8219"></xref>.</t>
    </list></t>
  </dd>
</dl>

</section>
<section anchor="trial-forwarding-ratio"><name>Trial Forwarding Ratio</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Trial Forwarding Ratio is a dimensionless floating point value.
It MUST range between 0.0 and 1.0, both inclusive.
It is calculated by dividing the number of frames
successfully forwarded by the SUT
by the total number of frames expected to be forwarded during the trial.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>For most Traffic Profiles, &quot;expected to be forwarded&quot; means
&quot;intended to get received by SUT from tester&quot;.
This SHOULD be the default interpretation.
Only if this is not the case, the test report MUST describe the Traffic Profile
in a detail sufficient to imply how Trial Forwarding Ratio should be calculated.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Forwarding Ratio MAY be expressed in other units
(e.g., as a percentage) in the test report.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Note that, contrary to Load terms, frame counts used to compute
Trial Forwarding Ratio are generally aggregates over all SUT output interfaces,
as most test procedures verify all outgoing frames.
The procedure for <xref target="RFC2544"></xref> Throughput counts received frames,
so implicitly it implies bidirectional counts for bidirectional traffic,
even though the final value is &quot;rate&quot; that is still per-interface.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For example, in a test with symmetric bidirectional traffic,
if one direction is forwarded without losses, but the opposite direction
does not forward at all, the Trial Forwarding Ratio would be 0.5 (50%).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In future extensions, more general ways to compute Trial Forwarding Ratio
may be allowed, but the current MLRsearch Specification relies on this specific
averaged counters approach.</t>
  </dd>
</dl>

</section>
<section anchor="trial-loss-ratio"><name>Trial Loss Ratio</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Trial Loss Ratio is equal to one minus the Trial Forwarding Ratio.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>100% minus the Trial Forwarding Ratio, when expressed as a percentage.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>This is almost identical to Frame Loss Rate of Section 3.6 of <xref target="RFC1242"></xref>.
The only minor differences are that Trial Loss Ratio does not need to
be expressed as a percentage, and Trial Loss Ratio is explicitly
based on averaged frame counts when more than one data stream is present.</t>
  </dd>
</dl>

</section>
<section anchor="trial-forwarding-rate"><name>Trial Forwarding Rate</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Trial Forwarding Rate is a derived quantity, calculated by
multiplying the Trial Load by the Trial Forwarding Ratio.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>This quantity differs from the Forwarding Rate described in Section
3.6.1 of <xref target="RFC2285"></xref>. Under the RFC 2285 method, each output interface is
measured separately, so every interface may report a distinct rate. The
Trial Forwarding Rate, by contrast, uses a single set of frame counts
and therefore yields one value that represents the whole system,
while still preserving the direct link to the per-interface load.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>When the Traffic Profile is symmetric and bidirectional, as defined in
Section 14 of <xref target="RFC2544"></xref>, the Trial Forwarding Rate is numerically equal
to the arithmetic average of the individual per-interface forwarding rates
that would be produced by the RFC 2285 procedure.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For more complex traffic patterns, such as many-to-one as mentioned
in Section 3.3.2 Partially Meshed Traffic of <xref target="RFC2285"></xref>,
the meaning of Trial Forwarding Rate is less straightforward.
For example, if two input interfaces receive one million frames per second each,
and a single interface outputs 1.4 million frames per second (fps),
Trial Load is 1 million fps, Trial Loss Ratio is 30%,
and Trial Forwarding Rate is 0.7 million fps.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Because this rate is anchored to the Load defined for one interface,
a test report MAY show it either as the single averaged figure just described,
or as the sum of the separate per-interface forwarding rates.
For the example above, the aggregate trial forwarding rate is 1.4 million fps.</t>
  </dd>
</dl>

</section>
<section anchor="trial-effective-duration"><name>Trial Effective Duration</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Effective Duration is a time quantity related to a Trial,
by default equal to the Trial Duration.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>This is an optional feature.
If the Measurer does not return any Trial Effective Duration value,
the Controller MUST use the Trial Duration value instead.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Effective Duration may be any positive time quantity
chosen by the Measurer to be used for time-based decisions in the Controller.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The test report MUST explain how the Measurer computes the returned
Trial Effective Duration values, if they are not always
equal to the Trial Duration.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>This feature can be beneficial for time-critical benchmarks
designed to manage the overall search duration,
rather than solely the traffic portion of it.
An approach is to measure the duration of the whole trial (including all wait times)
and use that as the Trial Effective Duration.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>This is also a way for the Measurer to inform the Controller about
its surprising behavior, for example, when rounding the Trial Duration value.</t>
  </dd>
</dl>

</section>
<section anchor="trial-output"><name>Trial Output</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Output is a composite quantity consisting of several attributes.
Required attributes are: Trial Loss Ratio, Trial Effective Duration and
Trial Forwarding Rate.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>When referring to more than one trial, plural term &quot;Trial Outputs&quot; is
used to collectively describe multiple Trial Output instances.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Measurer implementations may provide additional optional attributes.
The Controller implementations SHOULD
ignore values of any optional attribute
they are not familiar with,
except when passing Trial Output instances to the Manager.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Example of an optional attribute:
The aggregate number of frames expected to be forwarded during the trial,
especially if it is not (a rounded-down value)
implied by Trial Load and Trial Duration.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>While Section 3.5.2 of <xref target="RFC2285"></xref> requires the Offered Load value
to be reported for forwarding rate measurements,
it is not required in MLRsearch Specification,
as search results do not depend on it.</t>
  </dd>
</dl>

</section>
<section anchor="trial-result"><name>Trial Result</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Trial Result is a composite quantity,
consisting of the Trial Input and the Trial Output.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>When referring to more than one trial, plural term &quot;Trial Results&quot; is
used to collectively describe multiple Trial Result instances.</t>
  </dd>
</dl>

</section>
</section>
<section anchor="goal-terms"><name>Goal Terms</name>

<t>This section defines new terms for quantities relevant (directly or indirectly)
for inputs and outputs of the Controller component.</t>

<t>Several goal attributes are defined before introducing
the main composite quantity: the Search Goal.</t>

<t>Contrary to other sections, definitions in subsections of this section
are necessarily vague, as their fundamental meaning is to act as
coefficients in formulas for Controller Output, which are not defined yet.</t>

<t>The discussions in this section relate the attributes to concepts mentioned in Section
<xref target="overview-of-rfc-2544-problems">Overview of RFC 2544 Problems</xref>, but even these discussion
paragraphs are short, informal, and mostly referencing later sections,
where the impact on search results is discussed after introducing
the complete set of auxiliary terms.</t>

<section anchor="goal-final-trial-duration"><name>Goal Final Trial Duration</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Minimal value for Trial Duration that must be reached.
The value MUST be positive.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Certain trials must reach this minimum duration before a load can be
classified as a lower bound.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The Controller may choose shorter durations,
results of those may be enough for classification as an Upper Bound.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It is RECOMMENDED for all search goals to share the same
Goal Final Trial Duration value. Otherwise, Trial Duration values larger than
the Goal Final Trial Duration may occur, weakening the assumptions
the <xref target="load-classification-logic">Load Classification Logic</xref> is based on.</t>
  </dd>
</dl>

</section>
<section anchor="goal-duration-sum"><name>Goal Duration Sum</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A threshold value for a particular sum of Trial Effective Duration values.
The value MUST be positive.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, this prescribes the sufficient number of trials performed
at a specific Trial Load and Goal Final Trial Duration during the search.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>If the Goal Duration Sum is larger than the Goal Final Trial Duration,
multiple trials may be needed to be performed at the same load.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Refer to Section <xref target="mlrsearch-compliant-with-tst009">MLRsearch Compliant with TST009</xref>
for an example where the possibility of multiple trials
at the same load is intended.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>A Goal Duration Sum value shorter than the Goal Final Trial Duration
(of the same goal) could save some search time, but is NOT RECOMMENDED,
as the time savings come at the cost of decreased repeatability.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In practice, the Search can spend less than Goal Duration Sum measuring
a Load value when the results are particularly one-sided,
but also, the Search can spend more than Goal Duration Sum measuring a Load
when the results are balanced and include
trials shorter than Goal Final Trial Duration.</t>
  </dd>
</dl>

</section>
<section anchor="goal-loss-ratio"><name>Goal Loss Ratio</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A threshold value for Trial Loss Ratio values.
The value MUST be non-negative and smaller than one.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A trial with Trial Loss Ratio larger than this value
signals the SUT may be unable to process this Trial Load well enough.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>See <xref target="throughput-with-non-zero-loss">Throughput with Non-Zero Loss</xref>
for reasons why users may want to set this value above zero.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Since multiple trials may be needed for one Load value,
the Load Classification may be more complicated than mere comparison
of Trial Loss Ratio to Goal Loss Ratio.</t>
  </dd>
</dl>

</section>
<section anchor="goal-exceed-ratio"><name>Goal Exceed Ratio</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A threshold value for a particular ratio of sums
of Trial Effective Duration values.
The value MUST be non-negative and smaller than one.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, up to this proportion of Trial Results
with Trial Loss Ratio above Goal Loss Ratio is tolerated at a Lower Bound.
This is the full impact if every Trial was measured at Goal Final Trial Duration.
The actual full logic is more complicated, as shorter Trials are allowed.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For explainability reasons, the RECOMMENDED value for exceed ratio is 0.5 (50%),
as in practice that value leads to
the smallest variation in overall Search Duration.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Refer to Section <xref target="exceed-ratio-and-multiple-trials">Exceed Ratio and Multiple Trials</xref>
for more details.</t>
  </dd>
</dl>

</section>
<section anchor="goal-width"><name>Goal Width</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A threshold value for deciding whether two Trial Load values are close enough.
This is an OPTIONAL attribute. If present, the value MUST be positive.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, this acts as a stopping condition,
controlling the precision of the search result.
The search stops if every goal has reached its precision.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Implementations without this attribute
MUST provide the Controller with other means to control the search stopping conditions.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Absolute load difference and relative load difference are two popular choices,
but implementations may choose a different way to specify width.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The test report MUST make it clear what specific quantity is used as Goal Width.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It is RECOMMENDED to express Goal Width as a relative difference and
setting it to a value not lower than the Goal Loss Ratio.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Refer to Section 
<xref target="generalized-throughput">Generalized Throughput</xref> for more elaboration on the reasoning.</t>
  </dd>
</dl>

</section>
<section anchor="goal-initial-trial-duration"><name>Goal Initial Trial Duration</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Minimal value for Trial Duration suggested to use for this goal.
If present, this value MUST be positive.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>This is an example of an optional Search Goal.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>A typical default value is equal to the Goal Final Trial Duration value.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, this is the shortest Trial Duration the Controller should select
when focusing on the goal.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Note that shorter Trial Duration values can still be used,
for example, selected while focusing on a different Search Goal.
Such results MUST be still accepted by the Load Classification logic.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Goal Initial Trial Duration is a mechanism for a user to discourage
trials with Trial Duration values deemed as too unreliable
for a particular SUT and a given Search Goal.</t>
  </dd>
</dl>

</section>
<section anchor="search-goal"><name>Search Goal</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Search Goal is a composite quantity consisting of several attributes,
some of them are required.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Required attributes: Goal Final Trial Duration, Goal Duration Sum, Goal
Loss Ratio and Goal Exceed Ratio.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Optional attributes: Goal Initial Trial Duration and Goal Width.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Implementations MAY add their own attributes.
Those additional attributes may be required by an implementation
even if they are not required by MLRsearch Specification.
However, it is RECOMMENDED for those implementations
to support missing attributes by providing typical default values.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For example, implementations with Goal Initial Trial Durations
may also require users to specify &quot;how quickly&quot; should Trial Durations increase.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Refer to Section <xref target="compliance"></xref> for important Search Goal settings.</t>
  </dd>
</dl>

</section>
<section anchor="controller-input"><name>Controller Input</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Controller Input is a composite quantity
required as an input for the Controller.
The only REQUIRED attribute is a list of Search Goal instances.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>MLRsearch implementations MAY use additional attributes.
Those additional attributes may be required by an implementation
even if they are not required by MLRsearch Specification.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Formally, the Manager does not apply any Controller configuration
apart from one Controller Input instance.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For example, Traffic Profile is configured on the Measurer by the Manager,
without explicit assistance of the Controller.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The order of Search Goal instances in a list SHOULD NOT
have a big impact on Controller Output,
but MLRsearch implementations MAY base their behavior on the order
of Search Goal instances in a list.</t>
  </dd>
</dl>

<section anchor="max-load"><name>Max Load</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Max Load is an optional attribute of Controller Input.
It is the maximal value the Controller is allowed to use for Trial Load values.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Max Load is an example of an optional attribute (outside the list of Search Goals)
required by some implementations of MLRsearch.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>If the Max Load value is provided, Controller MUST NOT select
Trial Load values larger than that value.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In theory, each search goal could have its own Max Load value,
but as all Trial Results are possibly affecting all Search Goals,
it makes more sense for a single Max Load value to apply
to all Search Goal instances.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>While Max Load is a frequently used configuration parameter, already governed
(as maximum frame rate) by <xref target="RFC2544"></xref> (Section 20)
and (as maximum offered load) by <xref target="RFC2285"></xref> (Section 3.5.3),
some implementations may detect or discover it
(instead of requiring a user-supplied value).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In MLRsearch Specification, one reason for listing
the <xref target="relevant-upper-bound">Relevant Upper Bound</xref> as a required attribute
is that it makes the search result independent of Max Load value.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Given that Max Load is a quantity based on Load,
Test Report MAY express this quantity using multi-interface values,
as sum of per-interface maximal loads.</t>
  </dd>
</dl>

</section>
<section anchor="min-load"><name>Min Load</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Min Load is an optional attribute of Controller Input.
It is the minimal value the Controller is allowed to use for Trial Load values.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Min Load is another example of an optional attribute
required by some implementations of MLRsearch.
Similarly to Max Load, it makes more sense to prescribe one common value,
as opposed to using a different value for each Search Goal.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>If the Min Load value is provided, Controller MUST NOT select
Trial Load values smaller than that value.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Min Load is mainly useful for saving time by failing early,
arriving at an Irregular Goal Result when Min Load gets classified
as an Upper Bound.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For implementations, it is RECOMMENDED to require Min Load to be non-zero
and large enough to result in at least one frame being forwarded
even at shortest allowed Trial Duration,
so that Trial Loss Ratio is always well-defined,
and the implementation can apply relative Goal Width safely.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Given that Min Load is a quantity based on Load,
Test Report MAY express this quantity using multi-interface values,
as sum of per-interface minimal loads.</t>
  </dd>
</dl>

</section>
</section>
</section>
<section anchor="auxiliary-terms"><name>Auxiliary Terms</name>

<t>While the terms defined in this section are not strictly needed
when formulating MLRsearch requirements, they simplify the language used
in discussion paragraphs and explanation sections.</t>

<section anchor="trial-classification"><name>Trial Classification</name>

<t>When one Trial Result instance is compared to one Search Goal instance,
several relations can be named using short adjectives.</t>

<t>As trial results do not affect each other, this <strong>Trial Classification</strong>
does not change during a Search.</t>

<section anchor="high-loss-trial"><name>High-Loss Trial</name>

<t>A trial with Trial Loss Ratio larger than a Goal Loss Ratio value
is called a <strong>high-loss trial</strong>, with respect to given Search Goal
(or lossy trial, if Goal Loss Ratio is zero).</t>

</section>
<section anchor="low-loss-trial"><name>Low-Loss Trial</name>

<t>If a trial is not high-loss, it is called a <strong>low-loss trial</strong>
(or zero-loss trial, if Goal Loss Ratio is zero).</t>

</section>
<section anchor="short-trial"><name>Short Trial</name>

<t>A trial with Trial Duration shorter than the Goal Final Trial Duration
is called a <strong>short trial</strong> (with respect to the given Search Goal).</t>

</section>
<section anchor="full-length-trial"><name>Full-Length Trial</name>

<t>A trial that is not short is called a <strong>full-length</strong> trial.</t>

<t>Note that this includes Trial Durations larger than Goal Final Trial Duration.</t>

</section>
<section anchor="long-trial"><name>Long Trial</name>

<t>A trial with Trial Duration longer than the Goal Final Trial Duration
is called a <strong>long trial</strong>.</t>

</section>
</section>
<section anchor="load-classification"><name>Load Classification</name>

<t>When a set of all Trial Result instances, performed so far
at one Trial Load, is compared to one Search Goal instance,
their relation can be named using the concept of a bound.</t>

<t>In general, such bounds are a current quantity,
even though cases of a Load changing its classification more than once
during the Search is rare in practice.</t>

<section anchor="upper-bound"><name>Upper Bound</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A Load value is called an Upper Bound if and only if it is classified
as such by <xref target="load-classification-code">Appendix A</xref>
algorithm for the given Search Goal at the current moment of the Search.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>In more detail, the set of all Trial Result instances
performed so far at the Trial Load (and any Trial Duration)
is certain to fail to uphold all the requirements of the given Search Goal,
mainly the Goal Loss Ratio in combination with the Goal Exceed Ratio.
In this context, &quot;certain to fail&quot; relates to any possible results within the time
remaining till Goal Duration Sum.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>One search goal can have multiple different Trial Load values
classified as its Upper Bounds.
While search progresses and more trials are measured,
any load value can become an Upper Bound in principle.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Moreover, a Load can stop being an Upper Bound, but that
can only happen when more than Goal Duration Sum of trials are measured
(e.g., because another Search Goal needs more trials at this load).
Informally, the previous Upper Bound got invalidated.
In practice, the Load frequently becomes a <xref target="lower-bound">Lower Bound</xref> instead.</t>
  </dd>
</dl>

</section>
<section anchor="lower-bound"><name>Lower Bound</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A Load value is called a Lower Bound if and only if it is classified
as such by <xref target="load-classification-code">Appendix A</xref>
algorithm for the given Search Goal at the current moment of the search.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>In more detail, the set of all Trial Result instances
performed so far at the Trial Load (and any Trial Duration)
is certain to uphold all the requirements of the given Search Goal,
mainly the Goal Loss Ratio in combination with the Goal Exceed Ratio.
Here &quot;certain to uphold&quot; relates to any possible results within the time
remaining till Goal Duration Sum.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>One search goal can have multiple different Trial Load values
classified as its Lower Bounds.
As search progresses and more trials are measured,
any load value can become a Lower Bound in principle.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>No load can be both an Upper Bound and a Lower Bound for the same Search goal
at the same time, but it is possible for a larger load to be a Lower Bound
while a smaller load is an Upper Bound.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Moreover, a Load can stop being a Lower Bound, but that
can only happen when more than Goal Duration Sum of trials are measured
(e.g., because another Search Goal needs more trials at this load).
Informally, the previous Lower Bound got invalidated.
In practice, the Load frequently becomes an <xref target="upper-bound">Upper Bound</xref> instead.</t>
  </dd>
</dl>

</section>
<section anchor="undecided"><name>Undecided</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A Load value is called Undecided if it is currently
neither an Upper Bound nor a Lower Bound.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>A Load value that has not been measured so far is Undecided.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It is possible for a Load to transition from an Upper Bound to Undecided
by adding Short Trials with Low-Loss results.
That is yet another reason for users to avoid using Search Goal instances
with different Goal Final Trial Duration values.</t>
  </dd>
</dl>

</section>
</section>
</section>
<section anchor="result-terms"><name>Result Terms</name>

<t>Before defining the full structure of a Controller Output,
it is useful to define the composite quantity, called Goal Result.
The following subsections define its attribute first,
before describing the Goal Result quantity.</t>

<t>There is a correspondence between Search Goals and Goal Results.
Most of the following subsections refer to a given Search Goal,
when defining their terms.
Conversely, at the end of the search, each Search Goal instance
has its corresponding Goal Result instance.</t>

<section anchor="relevant-upper-bound"><name>Relevant Upper Bound</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Relevant Upper Bound is the smallest Trial Load value
classified as an Upper Bound for a given Search Goal at the end of the Search.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>If no measured load had enough High-Loss Trials,
the Relevant Upper Bound MAY be non-existent.
For example, when Max Load is classified as a Lower Bound.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Conversely, when Relevant Upper Bound does exist,
it is not affected by Max Load value.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Given that Relevant Upper Bound is a quantity based on Load,
Test Report MAY express this quantity using multi-interface values,
as sum of per-interface loads.</t>
  </dd>
</dl>

</section>
<section anchor="relevant-lower-bound"><name>Relevant Lower Bound</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Relevant Lower Bound is the largest Trial Load value
among those smaller than the Relevant Upper Bound, that got classified
as a Lower Bound for a given Search Goal at the end of the search.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>If no load had enough Low-Loss Trials, the Relevant Lower Bound
MAY be non-existent.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Strictly speaking, if the Relevant Upper Bound does not exist,
the Relevant Lower Bound also does not exist.
In a typical case, Max Load is classified as a Lower Bound,
making it impossible to increase the Load to continue the search
for an Upper Bound.
Thus, it is not clear whether a larger value would be found
for a Relevant Lower Bound if larger Loads were possible.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Given that Relevant Lower Bound is a quantity based on Load,
Test Report MAY express this quantity using multi-interface values,
as sum of per-interface loads.</t>
  </dd>
</dl>

</section>
<section anchor="conditional-throughput"><name>Conditional Throughput</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Conditional Throughput is a value computed at the Relevant Lower Bound
according to algorithm defined in
<xref target="conditional-throughput-code">Appendix B</xref>.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Relevant Lower Bound is defined only at the end of the Search,
and so is the Conditional Throughput.
But the algorithm can be applied at any time on any Lower Bound load,
so the final Conditional Throughput value may appear sooner
than at the end of a Search.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, the Conditional Throughput should be
a typical Trial Forwarding Rate, expected to be seen
at the Relevant Lower Bound of a given Search Goal.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>But frequently it is only a conservative estimate thereof,
as MLRsearch implementations tend to stop measuring more Trials
as soon as they confirm the value cannot get worse than this estimate
within the Goal Duration Sum.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>This value is RECOMMENDED to be used when evaluating repeatability
and comparability of different MLRsearch implementations.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Refer to Section <xref target="generalized-throughput">Generalized Throughput</xref> for more details.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Given that Conditional Throughput is a quantity based on Load,
Test Report MAY express this quantity using multi-interface values,
as sum of per-interface forwarding rates.</t>
  </dd>
</dl>

</section>
<section anchor="goal-results"><name>Goal Results</name>

<t>MLRsearch Specification is based on a set of requirements
for a &quot;regular&quot; result. But in practice, it is not always possible
for such result instance to exist, so also &quot;irregular&quot; results
need to be supported.</t>

<section anchor="regular-goal-result"><name>Regular Goal Result</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Regular Goal Result is a composite quantity consisting of several attributes.
Relevant Upper Bound and Relevant Lower Bound are REQUIRED attributes.
Conditional Throughput is a RECOMMENDED attribute.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Implementations MAY add their own attributes.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Test report MUST display Relevant Lower Bound.
Displaying Relevant Upper Bound is RECOMMENDED,
especially if the implementation does not use Goal Width.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>In general, stopping conditions for the corresponding Search Goal MUST
be satisfied to produce a Regular Goal Result.
Specifically, if an implementation offers Goal Width as a Search Goal attribute,
the distance between the Relevant Lower Bound
and the Relevant Upper Bound MUST NOT be larger than the Goal Width.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For stopping conditions refer to Sections <xref target="goal-width">Goal Width</xref> and
<xref target="stopping-conditions-and-precision">Stopping Conditions and Precision</xref>.</t>
  </dd>
</dl>

</section>
<section anchor="irregular-goal-result"><name>Irregular Goal Result</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Irregular Goal Result is a composite quantity. No attributes are required.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>It is RECOMMENDED to report any useful quantity even if it does not
satisfy all the requirements. For example, if Max Load is classified
as a Lower Bound, it is fine to report it as an &quot;effective&quot; Relevant Lower Bound
(although not a real one, as that requires
Relevant Upper Bound which does not exist in this case),
and compute Conditional Throughput for it. In this case,
only the missing Relevant Upper Bound signals this result instance is irregular.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Similarly, if both relevant bounds exist, it is RECOMMENDED
to include them as Irregular Goal Result attributes,
and let the Manager decide if their distance is too far for Test Report purposes.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>If Test Report displays some Irregular Goal Result attribute values,
they MUST be clearly marked as coming from irregular results.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The implementation MAY define additional attributes,
for example explicit flags for expected situations, so the Manager logic can be simpler.</t>
  </dd>
</dl>

</section>
<section anchor="goal-result"><name>Goal Result</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Goal Result is a composite quantity.
Each instance is either a Regular Goal Result or an Irregular Goal Result.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Manager MUST be able to distinguish whether the instance is regular or not.</t>
  </dd>
</dl>

</section>
</section>
<section anchor="search-result"><name>Search Result</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Search Result is a single composite object
that maps each Search Goal instance to a corresponding Goal Result instance.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>As an alternative to mapping, the Search Result may be represented
as an ordered list of Goal Result instances that appears in the exact
sequence of their corresponding Search Goal instances.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>When the Search Result is expressed as a mapping, it MUST contain an
entry for every Search Goal instance supplied in the Controller Input.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Identical Goal Result instances MAY be listed for different Search Goals,
but their status as regular or irregular may be different.
For example, if two goals differ only in Goal Width value,
and the relevant bound values are close enough according to only one of them.</t>
  </dd>
</dl>

</section>
<section anchor="controller-output"><name>Controller Output</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Controller Output is a composite quantity returned from the Controller
to the Manager at the end of the search.
The Search Result instance is its only required attribute.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>MLRsearch implementation MAY return additional data in the Controller Output,
e.g., number of trials performed and the total Search Duration.</t>
  </dd>
</dl>

</section>
</section>
<section anchor="architecture-terms"><name>Architecture Terms</name>

<t>MLRsearch architecture consists of three main system components: 
the Manager, the Controller, and the Measurer.
The components were introduced in <xref target="architecture-overview">Architecture Overview</xref>,
and the following subsections finalize their definitions
using terms from previous sections.</t>

<t>Note that the architecture also implies the presence of other components,
such as the SUT and the tester (as a sub-component of the Measurer).</t>

<t>Communication protocols and interfaces between components are left
unspecified. For example, when MLRsearch Specification mentions
&quot;Controller calls Measurer&quot;,
it is possible that the Controller notifies the Manager
to call the Measurer indirectly instead. In doing so, the Measurer implementations
can be fully independent from the Controller implementations,
e.g., developed in different programming languages.</t>

<section anchor="measurer"><name>Measurer</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Measurer is a functional element that when called
with a <xref target="trial-input">Trial Input</xref> instance, performs one <xref target="trial">Trial </xref>
and returns a <xref target="trial-output">Trial Output</xref> instance.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>This definition assumes the Measurer is already initialized.
In practice, there may be additional steps before the Search,
e.g., when the Manager configures the traffic profile
(either on the Measurer or on its tester sub-component directly)
and performs a warm-up (if the tester or the test procedure requires one).</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It is the responsibility of the Measurer implementation to uphold
any requirements and assumptions present in MLRsearch Specification,
e.g., Trial Forwarding Ratio not being larger than one.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Implementers have some freedom.
For example, Section 10 of <xref target="RFC2544"></xref>
gives some suggestions (but not requirements) related to
duplicated or reordered frames.
Implementations are RECOMMENDED to document their behavior
related to such freedoms in as detailed a way as possible.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It is RECOMMENDED to benchmark the test equipment first,
e.g., connect sender and receiver directly (without any SUT in the path),
find a load value that guarantees the Offered Load is not too far
from the Intended Load and use that value as the Max Load value.
When testing the real SUT, it is RECOMMENDED to turn any severe deviation
between the Intended Load and the Offered Load into increased Trial Loss Ratio.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Neither of the two recommendations are made into mandatory requirements,
because it is not easy to provide guidance about when the difference is severe enough,
in a way that would be disentangled from other Measurer freedoms.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For a sample situation where the Offered Load cannot keep up
with the Intended Load, and the consequences on MLRsearch result,
refer to Section <xref target="hard-performance-limit">Hard Performance Limit</xref>.</t>
  </dd>
</dl>

</section>
<section anchor="controller"><name>Controller</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Controller is a functional element that, upon receiving a Controller
Input instance, repeatedly generates Trial Input instances for the
Measurer and collects the corresponding Trial Output instances. This
cycle continues until the stopping conditions are met, at which point
the Controller produces a final Controller Output instance and
terminates.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, the Controller has big freedom in selection of Trial Inputs,
and the implementations want to achieve all the Search Goals
in the shortest average time.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The Controller&#39;s role in optimizing the overall Search Duration
distinguishes MLRsearch algorithms from simpler search procedures.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Informally, each implementation can have different stopping conditions.
Goal Width is only one example.
In practice, implementation details do not matter,
as long as Goal Result instances are regular.</t>
  </dd>
</dl>

</section>
<section anchor="manager"><name>Manager</name>

<t>Definition:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Manager is a functional element that is reponsible for
provisioning other components, calling a Controller component once,
and for creating the test report following the reporting format as
defined in Section 26 of <xref target="RFC2544"></xref>.</t>
  </dd>
</dl>

<t>Discussion:</t>

<dl>
  <dt>&#160;</dt>
  <dd>
    <t>The Manager initializes the SUT, the Measurer
(and the tester if independent from Measurer)
with their intended configurations before calling the Controller.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>Note that Section 7 of <xref target="RFC2544"></xref> already puts requirements on SUT setups:</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>&quot;It is expected that all of the tests will be run without changing the
configuration or setup of the DUT in any way other than that required
to do the specific test. For example, it is not acceptable to change
the size of frame handling buffers between tests of frame handling
rates or to disable all but one transport protocol when testing the
throughput of that protocol.&quot;</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>It is REQUIRED for the test report to encompass all the SUT configuration
details, including description of a &quot;default&quot; configuration common for most tests
and configuration changes if required by a specific test.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>For example, Section 5.1.1 of <xref target="RFC5180"></xref> recommends testing jumbo frames
if SUT can forward them, even though they are outside the scope
of the 802.3 IEEE standard. In this case, it is acceptable
for the SUT default configuration to not support jumbo frames,
and only enable this support when testing jumbo traffic profiles,
as the handling of jumbo frames typically has different packet buffer
requirements and potentially higher processing overhead.
Non-jumbo frame sizes should also be tested on the jumbo-enabled setup.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>The Manager does not need to be able to tweak any Search Goal attributes,
but it MUST report all applied attribute values even if not tweaked.</t>
  </dd>
  <dt>&#160;</dt>
  <dd>
    <t>A &quot;user&quot; - human or automated - invokes the Manager once to launch a
single Search and receive its report. Every new invocation is treated
as a fresh, independent Search; how the system behaves across multiple
calls (for example, combining or comparing their results) is explicitly
out of scope for this document.</t>
  </dd>
</dl>

</section>
</section>
<section anchor="compliance"><name>Compliance</name>

<t>This section discusses compliance relations between MLRsearch
and other test procedures.</t>

<section anchor="test-procedure-compliant-with-mlrsearch"><name>Test Procedure Compliant with MLRsearch</name>

<t>Any networking measurement setup that could be understood as consisting of
functional elements satisfying requirements
for the Measurer, the Controller and the Manager,
is compliant with MLRsearch Specification.</t>

<t>These components can be seen as abstractions present in any testing procedure.
For example, there can be a single component acting both
as the Manager and the Controller, but if values of required attributes
of Search Goals and Goal Results are visible in the test report,
the Controller Input instance and Controller Output instance are implied.</t>

<t>For example, any setup for conditionally (or unconditionally)
compliant <xref target="RFC2544"></xref> throughput testing
can be understood as a MLRsearch architecture,
if there is enough data to reconstruct the Relevant Upper Bound.</t>

<t>Refer to section 
<xref target="mlrsearch-compliant-with-rfc-2544">MLRsearch Compliant with RFC 2544</xref>
for an equivalent Search Goal.</t>

<t>Any test procedure that can be understood as one call to the Manager of
MLRsearch architecture is said to be compliant with MLRsearch Specification.</t>

</section>
<section anchor="mlrsearch-compliant-with-rfc-2544"><name>MLRsearch Compliant with RFC 2544</name>

<t>The following Search Goal instance makes the corresponding Search Result
unconditionally compliant with Section 24 of <xref target="RFC2544"></xref>.</t>

<t><list style="symbols">
  <t>Goal Final Trial Duration = 60 seconds</t>
  <t>Goal Duration Sum = 60 seconds</t>
  <t>Goal Loss Ratio = 0%</t>
  <t>Goal Exceed Ratio = 0%</t>
</list></t>

<t>Goal Loss Ratio and Goal Exceed Ratio attributes,
are enough to make the Search Goal conditionally compliant.
Adding Goal Final Trial Duration
makes the Search Goal unconditionally compliant.</t>

<t>Goal Duration Sum prevents MLRsearch
from repeating zero-loss Full-Length Trials.</t>

<t>The presence of other Search Goals does not affect the compliance
of this Goal Result.
The Relevant Lower Bound and the Conditional Throughput are in this case
equal to each other, and the value is the <xref target="RFC2544"></xref> throughput.</t>

<t>Non-zero exceed ratio is not strictly disallowed, but it could
needlessly prolong the search when Low-Loss short trials are present.</t>

</section>
<section anchor="mlrsearch-compliant-with-tst009"><name>MLRsearch Compliant with TST009</name>

<t>One of the alternatives to <xref target="RFC2544"></xref> is Binary search with loss verification
as described in Section 12.3.3 of <xref target="TST009"></xref>.</t>

<t>The rationale of such search is to repeat high-loss trials, hoping for zero loss on second try,
so the results are closer to the noiseless end of performance spectrum,
thus more repeatable and comparable.</t>

<t>Only the variant with &quot;z = infinity&quot; is achievable with MLRsearch.</t>

<t>For example, for &quot;max(r) = 2&quot; variant, the following Search Goal instance
should be used to get compatible Search Result:</t>

<t><list style="symbols">
  <t>Goal Final Trial Duration = 60 seconds</t>
  <t>Goal Duration Sum = 120 seconds</t>
  <t>Goal Loss Ratio = 0%</t>
  <t>Goal Exceed Ratio = 50%</t>
</list></t>

<t>If the first 60 seconds trial has zero loss, it is enough for MLRsearch to stop
measuring at that load, as even a second high-loss trial
would still fit within the exceed ratio.</t>

<t>But if the first trial is high-loss, MLRsearch needs to perform also
the second trial to classify that load.
Goal Duration Sum is twice as long as Goal Final Trial Duration,
so third full-length trial is never needed.</t>

</section>
</section>
</section>
<section anchor="methodology-rationale-and-design-considerations"><name>Methodology Rationale and Design Considerations</name>

<t>This section explains the Why behind MLRsearch. Building on the
normative specification in Section
<xref target="mlrsearch-specification">MLRsearch Specification</xref>,
it contrasts MLRsearch with the classic
<xref target="RFC2544"></xref> single-ratio binary-search procedure and walks through the
key design choices: binary-search mechanics, stopping-rule precision,
loss-inversion for multiple goals, exceed-ratio handling, short-trial
strategies, and the generalised throughput concept. Together, these
considerations show how the methodology reduces test time, supports
multiple loss ratios, and improves repeatability.</t>

<section anchor="binary-search"><name>Binary Search</name>

<t>A typical binary search implementation for <xref target="RFC2544"></xref>
tracks only the two tightest bounds.
To start, the search needs both Max Load and Min Load values.
Then, one trial is used to confirm Max Load is an Upper Bound,
and one trial to confirm Min Load is a Lower Bound.</t>

<t>Then, next Trial Load is chosen as the mean of the current tightest upper bound
and the current tightest lower bound, and becomes a new tightest bound
depending on the Trial Loss Ratio.</t>

<t>After some number of trials, the tightest lower bound becomes the throughput,
but <xref target="RFC2544"></xref> does not specify when, if ever, the search should stop.
In practice, the search stops either at some distance
between the tightest upper bound and the tightest lower bound,
or after some number of Trials.</t>

<t>For a given pair of Max Load and Min Load values,
there is one-to-one correspondence between number of Trials
and final distance between the tightest bounds.
Thus, the search always takes the same time,
assuming initial bounds are confirmed.</t>

</section>
<section anchor="stopping-conditions-and-precision"><name>Stopping Conditions and Precision</name>

<t>MLRsearch Specification requires listing both Relevant Bounds for each
Search Goal, and the difference between the bounds implies
whether the result precision is achieved.
Therefore, it is not necessary to report the specific stopping condition used.</t>

<t>MLRsearch implementations may use Goal Width
to allow direct control of result precision
and indirect control of the Search Duration.</t>

<t>Other MLRsearch implementations may use different stopping conditions:
for example based on the Search Duration, trading off precision control
for duration control.</t>

<t>Due to various possible time optimizations, there is no strict
correspondence between the Search Duration and Goal Width values.
In practice, noisy SUT performance increases both average search time
and its variance.</t>

</section>
<section anchor="loss-ratios-and-loss-inversion"><name>Loss Ratios and Loss Inversion</name>

<t>The biggest</t>

<t>difference between MLRsearch and <xref target="RFC2544"></xref> binary search
is in the goals of the search.
<xref target="RFC2544"></xref> has a single goal, based on classifying a single full-length trial
as either zero-loss or non-zero-loss.
MLRsearch supports searching for multiple Search Goals at once,
usually differing in their Goal Loss Ratio values.</t>

<section anchor="single-goal-and-hard-bounds"><name>Single Goal and Hard Bounds</name>

<t>Each bound in <xref target="RFC2544"></xref> simple binary search is &quot;hard&quot;,
in the sense that all further Trial Load values
are smaller than any current upper bound and larger than any current lower bound.</t>

<t>This is also possible for MLRsearch implementations,
when the search is started with only one Search Goal instance.</t>

</section>
<section anchor="multiple-goals-and-loss-inversion"><name>Multiple Goals and Loss Inversion</name>

<t>MLRsearch Specification</t>

<t>supports multiple Search Goals, making the search procedure
more complicated compared to binary search with single goal,
but most of the complications do not affect the final results much.
Except for one phenomenon: Loss Inversion.</t>

<t>Depending on Search Goal attributes, Load Classification results may be resistant
to small amounts of Section <xref target="inconsistent-trial-results">Inconsistent Trial Results</xref>.
However, for larger amounts, a Load that is classified
as an Upper Bound for one Search Goal
may still be a Lower Bound for another Search Goal.
Due to this other goal, MLRsearch will probably perform subsequent Trials
at Trial Loads even larger than the original value.</t>

<t>This introduces questions any many-goals search algorithm has to address.
For example: What to do when all such larger load trials happen to have zero loss?
Does it mean the earlier upper bound was not real?
Does it mean the later Low-Loss trials are not considered a lower bound?</t>

<t>The situation where a smaller Load is classified as an Upper Bound,
while a larger Load is classified as a Lower Bound (for the same search goal),
is called Loss Inversion.</t>

<t>Conversely, only single-goal search algorithms can have hard bounds
that shield them from Loss Inversion.</t>

</section>
<section anchor="conservativeness-and-relevant-bounds"><name>Conservativeness and Relevant Bounds</name>

<t>MLRsearch is conservative when dealing with Loss Inversion:
the Upper Bound is considered real, and the Lower Bound
is considered to be a fluke, at least when computing the final result.</t>

<t>This is formalized using definitions of
<xref target="relevant-upper-bound">Relevant Upper Bound</xref> and
<xref target="relevant-lower-bound">Relevant Lower Bound</xref>.</t>

<t>The Relevant Upper Bound (for specific goal) is the smallest Load classified
as an Upper Bound. But the Relevant Lower Bound is not simply
the largest among Lower Bounds. It is the largest Load among Loads
that are Lower Bounds while also being smaller than the Relevant Upper Bound.</t>

<t>With these definitions, the Relevant Lower Bound is always smaller
than the Relevant Upper Bound (if both exist), and the two relevant bounds
are used analogously as the two tightest bounds in the binary search.
When they meet the stopping conditions, the Relevant Bounds are used in the output.</t>

</section>
<section anchor="consequences"><name>Consequences</name>

<t>The consequence of the way the Relevant Bounds are defined is that
every Trial Result can have an impact
on any current Relevant Bound larger than that Trial Load,
namely by becoming a new Upper Bound.</t>

<t>This also applies when that Load is measured
before another Load gets enough measurements to become a current Relevant Bound.</t>

<t>This also implies that if the SUT tested (or the Traffic Generator used)
needs a warm-up, it should be warmed up before starting the Search,
otherwise the first few measurements could become unjustly limiting.</t>

<t>For MLRsearch implementations, it means it is better to measure
at smaller Loads first, so bounds found earlier are less likely
to get invalidated later.</t>

</section>
</section>
<section anchor="exceed-ratio-and-multiple-trials"><name>Exceed Ratio and Multiple Trials</name>

<t>The idea of performing multiple Trials at the same Trial Load comes from
a model where some Trial Results (those with high Trial Loss Ratio) are affected
by infrequent effects, causing unsatisfactory repeatability</t>

<t>of <xref target="RFC2544"></xref> Throughput results. Refer to Section <xref target="dut-in-sut">DUT in SUT</xref>
for a discussion about noiseful and noiseless ends
of the SUT performance spectrum.
Stable results are closer to the noiseless end of the SUT performance spectrum,
so MLRsearch may need to allow some frequency of high-loss trials
to ignore the rare but big effects near the noiseful end.</t>

<t>For MLRsearch to perform such Trial Result filtering, it needs
a configuration option to tell how frequent the &quot;infrequent&quot; big loss can be.
This option is called the <xref target="goal-exceed-ratio">Goal Exceed Ratio</xref>.
It tells MLRsearch what ratio of trials (more specifically,
what ratio of Trial Effective Duration seconds)
can have a <xref target="trial-loss-ratio">Trial Loss Ratio</xref>
larger than the <xref target="goal-loss-ratio">Goal Loss Ratio</xref>
and still be classified as a <xref target="lower-bound">Lower Bound</xref>.</t>

<t>Zero exceed ratio means all Trials must have a Trial Loss Ratio
equal to or lower than the Goal Loss Ratio.</t>

<t>When more than one Trial is intended to classify a Load,
MLRsearch also needs something that controls the number of trials needed.
Therefore, each goal also has an attribute called Goal Duration Sum.</t>

<t>The meaning of a <xref target="goal-duration-sum">Goal Duration Sum</xref> is that
when a Load has (Full-Length) Trials
whose Trial Effective Durations when summed up give a value at least as big
as the Goal Duration Sum value,
the Load is guaranteed to be classified either as an Upper Bound
or a Lower Bound for that Search Goal instance.</t>

</section>
<section anchor="short-trials-and-duration-selection"><name>Short Trials and Duration Selection</name>

<t>MLRsearch requires each Search Goal to specify its Goal Final Trial Duration.</t>

<t>Section 24 of <xref target="RFC2544"></xref> already anticipates possible time savings
when Short Trials are used.</t>

<t>An MLRsearch implementation MAY expose configuration parameters that
decide whether, when, and how short trial durations are used. The exact
heuristics and controls are left to the discretion of the implementer.</t>

<t>While MLRsearch implementations are free to use any logic to select
Trial Input values, comparability between MLRsearch implementations
is only assured when the Load Classification logic
handles any possible set of Trial Results in the same way.</t>

<t>The presence of Short Trial Results complicates
the Load Classification logic, see more details in Section
<xref target="load-classification-logic">Load Classification Logic</xref>.</t>

<t>While the Load Classification algorithm is designed to avoid any unneeded Trials,
for explainability reasons it is recommended for users to use
such Controller Input instances that lead to all Trial Duration values
selected by Controller to be the same,
e.g., by setting any Goal Initial Trial Duration to be a single value
also used in all Goal Final Trial Duration attributes.</t>

</section>
<section anchor="generalized-throughput"><name>Generalized Throughput</name>

<t>Because testing equipment takes the Intended Load
as an input parameter for a Trial measurement,
any load search algorithm needs to deal with Intended Load values internally.</t>

<t>But in the presence of Search Goals with a non-zero
<xref target="goal-loss-ratio">Goal Loss Ratio</xref>, the Load usually does not match
the user&#39;s intuition of what a throughput is.
The forwarding rate as defined in Section Section 3.6.1 of <xref target="RFC2285"></xref> is better,
but it is not obvious how to generalize it
for Loads with multiple Trials and a non-zero Goal Loss Ratio.</t>

<t>The clearest illustration - and the chief reason for adopting a
generalized throughput definition - is the presence of a hard
performance limit.</t>

<section anchor="hard-performance-limit"><name>Hard Performance Limit</name>

<t>Even if bandwidth of a medium allows higher traffic forwarding performance,
the SUT interfaces may have their additional own limitations,
e.g., a specific frames-per-second limit on the NIC (a common occurrence).</t>

<t>Those limitations should be known and provided as Max Load, Section
<xref target="max-load">Max Load</xref>.</t>

<t>But if Max Load is set larger than what the interface can receive or transmit,
there will be a &quot;hard limit&quot; behavior observed in Trial Results.</t>

<t>Consider that the hard limit is at hundred million frames per second (100 Mfps),
Max Load is larger, and the Goal Loss Ratio is 0.5%.
If DUT has no additional losses, 0.5% Trial Loss Ratio will be achieved
at Relevant Lower Bound of 100.5025 Mfps.</t>

<t>Reporting a throughput that exceeds the SUT&#39;s verified hard limit is
counter-intuitive. Accordingly, the <xref target="RFC2544"></xref> Throughput metric should
be generalized - rather than relying solely on the Relevant Lower
Bound - to reflect realistic, limit-aware performance.</t>

<t>MLRsearch defines one such generalization,
the <xref target="conditional-throughput">Conditional Throughput</xref>.
It is the Trial Forwarding Rate from one of the Full-Length Trials
performed at the Relevant Lower Bound.
The algorithm to determine which trial exactly is in
<xref target="conditional-throughput-code">Appendix B</xref>.</t>

<t>In the hard limit example, 100.5025 Mfps Load will still have
only 100.0 Mfps forwarding rate, nicely confirming the known limitation.</t>

</section>
<section anchor="performance-variability"><name>Performance Variability</name>

<t>With non-zero Goal Loss Ratio, and without hard performance limits,
Low-Loss trials at the same Load may achieve different Trial Forwarding Rate
values just due to DUT performance variability.</t>

<t>By comparing the best case (all Relevant Lower Bound trials have zero loss)
and the worst case (all Trial Loss Ratios at Relevant Lower Bound
are equal to the Goal Loss Ratio),
one can prove that Conditional Throughput
values may have up to the Goal Loss Ratio relative difference.</t>

<t>Setting the Goal Width below the Goal Loss Ratio
may cause the Conditional Throughput for a larger Goal Loss Ratio to become smaller
than a Conditional Throughput for a goal with a lower Goal Loss Ratio,
which is counter-intuitive, considering they come from the same Search.
Therefore, it is RECOMMENDED to set the Goal Width to a value no lower
than the Goal Loss Ratio of the higher-loss Search Goal.</t>

<t>Although Conditional Throughput can fluctuate from one run to the next,
it still offers a more discriminating basis for comparison than the
Relevant Lower Bound - particularly when deterministic load selection
yields the same Lower Bound value across multiple runs.</t>

</section>
</section>
</section>
<section anchor="mlrsearch-logic-and-example"><name>MLRsearch Logic and Example</name>

<t>This section uses informal language to describe two aspects of MLRsearch logic:
Load Classification and Conditional Throughput,
reflecting formal pseudocode representation provided in
<xref target="load-classification-code">Appendix A</xref>
and <xref target="conditional-throughput-code">Appendix B</xref>.
This is followed by example search.</t>

<t>The logic is equivalent but not identical to the pseudocode
on appendices. The pseudocode is designed to be short and frequently
combines multiple operations into one expression.
The logic as described in this section lists each operation separately
and uses more intuitive names for the intermediate values.</t>

<section anchor="load-classification-logic"><name>Load Classification Logic</name>

<t>Note: For explanation clarity variables are taged as (I)nput,
(T)emporary, (O)utput.</t>

<t><list style="symbols">
  <t>Collect Trial Results:  <list style="symbols">
      <t>Take all Trial Result instances (I) measured at a given load.</t>
    </list></t>
  <t>Aggregate Trial Durations:  <list style="symbols">
      <t>Full-length high-loss sum (T) is the sum of Trial Effective Duration
values of all full-length high-loss trials (I).</t>
      <t>Full-length low-loss sum (T) is the sum of Trial Effective Duration
values of all full-length low-loss trials (I).</t>
      <t>Short high-loss sum is the sum (T)  of Trial Effective Duration values
of all short high-loss trials (I).</t>
      <t>Short low-loss sum is the sum (T) of Trial Effective Duration values
of all short low-loss trials (I).</t>
    </list></t>
  <t>Derive goal-based ratios:  <list style="symbols">
      <t>Subceed ratio (T) is One minus the Goal Exceed Ratio (I).</t>
      <t>Exceed coefficient (T) is the Goal Exceed Ratio divided by the subceed
ratio.</t>
    </list></t>
  <t>Balance short-trial effects:  <list style="symbols">
      <t>Balancing sum (T) is the short low-loss sum
multiplied by the exceed coefficient.</t>
      <t>Excess sum (T) is the short high-loss sum minus the balancing sum.</t>
      <t>Positive excess sum (T) is the maximum of zero and excess sum.</t>
    </list></t>
  <t>Compute effective duration totals  <list style="symbols">
      <t>Effective high-loss sum (T) is the full-length high-loss sum
plus the positive excess sum.</t>
      <t>Effective full sum (T) is the effective high-loss sum
plus the full-length low-loss sum.</t>
      <t>Effective whole sum (T) is the larger of the effective full sum
and the Goal Duration Sum.</t>
      <t>Missing sum (T) is the effective whole sum minus the effective full sum.</t>
    </list></t>
  <t>Estimate exceed ratios:  <list style="symbols">
      <t>Pessimistic high-loss sum (T) is the effective high-loss sum
plus the missing sum.</t>
      <t>Optimistic exceed ratio (T) is the effective high-loss sum
divided by the effective whole sum.</t>
      <t>Pessimistic exceed ratio (T) is the pessimistic high-loss sum
divided by the effective whole sum.</t>
    </list></t>
  <t>Classify the Load:  <list style="symbols">
      <t>The load is classified as an Upper Bound (O) if the optimistic exceed
ratio is larger than the Goal Exceed Ratio.</t>
      <t>The load is classified as a Lower Bound (O) if the pessimistic exceed
ratio is not larger than the Goal Exceed Ratio.</t>
      <t>The load is classified as undecided (O) otherwise.</t>
    </list></t>
</list></t>

</section>
<section anchor="conditional-throughput-logic"><name>Conditional Throughput Logic</name>

<t><list style="symbols">
  <t>Collect Trial Results  <list style="symbols">
      <t>Take all Trial Result instances (I) measured at a given Load.</t>
    </list></t>
  <t>Sum Full-Length Durations:  <list style="symbols">
      <t>Full-length high-loss sum (T) is the sum of Trial Effective Duration
values of all full-length high-loss trials (I).</t>
      <t>Full-length low-loss sum (T) is the sum of Trial Effective Duration
values of all full-length low-loss trials (I).</t>
      <t>Full-length sum (T) is the full-length high-loss sum (I) plus the
full-length low-loss sum (I).</t>
    </list></t>
  <t>Derive initial thresholds:  <list style="symbols">
      <t>Subceed ratio (T) is One minus the Goal Exceed Ratio (I) is called.</t>
      <t>Remaining sum (T) initially is full-lengths sum multiplied by subceed
ratio.</t>
      <t>Current loss ratio (T) initially is 100%.</t>
    </list></t>
  <t>Iterate through ordered trials  <list style="symbols">
      <t>For each full-length trial result, sorted in increasing order by Trial
Loss Ratio:      <list style="symbols">
          <t>If remaining sum is not larger than zero, exit the loop.</t>
          <t>Set current loss ratio to this trial&#39;s Trial Loss Ratio (I).</t>
          <t>Decrease the remaining sum by this trial&#39;s Trial Effective Duration (I).</t>
        </list></t>
    </list></t>
  <t>Compute Conditional Throughput  <list style="symbols">
      <t>Current forwarding ratio (T) is One minus the current loss ratio.</t>
      <t>Conditional Throughput (T) is the current forwarding ratio multiplied
by the Load value.</t>
    </list></t>
</list></t>

<section anchor="conditional-throughput-and-load-classification"><name>Conditional Throughput and Load Classification</name>

<t>Conditional Throughput and results of Load Classification overlap but
are not identical.</t>

<t><list style="symbols">
  <t>When a load is marked as a Relevant Lower Bound, its Conditional
Throughput is taken from a trial whose loss ratio never exceeds the
Goal Loss Ratio.</t>
  <t>The reverse is not guaranteed: if the Goal Width is narrower than the
Goal Loss Ratio, Conditional Throughput can still end up higher than
the Relevant Upper Bound.</t>
</list></t>

</section>
</section>
<section anchor="sut-behaviors"><name>SUT Behaviors</name>

<t>In Section <xref target="dut-in-sut">DUT in SUT</xref>, the notion of noise has been introduced.
This section uses new terms
to describe possible SUT behaviors more precisely.</t>

<t>From measurement point of view, noise is visible as inconsistent trial results.
See <xref target="inconsistent-trial-results">Inconsistent Trial Results</xref> for general points
and <xref target="loss-ratios-and-loss-inversion">Loss Ratios and Loss Inversion</xref>
for specifics when comparing different Load values.</t>

<t>Load Classification and Conditional Throughput apply to a single Load value,
but even the set of Trial Results measured at that Trial Load value
may appear inconsistent.</t>

<t>As MLRsearch aims to save time, it executes only a small number of Trials,
getting only a limited amount of information about SUT behavior.
It is useful to introduce an &quot;SUT expert&quot; point of view to contrast
with that limited information.</t>

<section anchor="expert-predictions"><name>Expert Predictions</name>

<t>Imagine that before the Search starts, a human expert had unlimited time
to measure SUT and obtain all reliable information about it.
The information is not perfect, as there is still random noise influencing SUT.
But the expert is familiar with possible noise events, even the rare ones,
and thus the expert can do probabilistic predictions about future Trial Outputs.</t>

<t>When several outcomes are possible,
the expert can assess probability of each outcome.</t>

</section>
<section anchor="exceed-probability"><name>Exceed Probability</name>

<t>When the Controller selects new Trial Duration and Trial Load,
and just before the Measurer starts performing the Trial,
the SUT expert can envision possible Trial Results.</t>

<t>With respect to a particular Search Goal instance, the possibilities
can be summarized into a single number: Exceed Probability.
It is the probability (according to the expert) that the measured
Trial Loss Ratio will be higher than the Goal Loss Ratio.</t>

</section>
<section anchor="trial-duration-dependence"><name>Trial Duration Dependence</name>

<t>When comparing Exceed Probability values for the same Trial Load value
but different Trial Duration values,
there are several patterns that commonly occur in practice.</t>

<section anchor="strong-increase"><name>Strong Increase</name>

<t>Exceed Probability is very low at short durations but very high at full-length.
This SUT behavior is undesirable, and may hint at faulty SUT,
e.g., SUT leaks resources and is unable to sustain the desired performance.</t>

<t>But this behavior is also seen when SUT uses large amount of buffers.
This is the main reasons users may want to set large Goal Final Trial Duration.</t>

</section>
<section anchor="mild-increase"><name>Mild Increase</name>

<t>Short trials are slightly less likely to exceed the loss-ratio limit,
but the improvement is modest. This mild benefit is typical when noise
is dominated by rare, large loss spikes: during a full-length trial,
the good-performing periods cannot fully offset the heavy frame loss
that occurs in the brief low-performing bursts.</t>

</section>
<section anchor="independence"><name>Independence</name>

<t>Short trials have basically the same Exceed Probability as full-length trials.
This is possible only if loss spikes are small (so other parts can compensate)
and if Goal Loss Ratio is more than zero (otherwise, other parts
cannot compensate at all).</t>

</section>
<section anchor="decrease"><name>Decrease</name>

<t>Short trials have larger Exceed Probability than full-length trials.
This can be possible only for non-zero Goal Loss Ratio,
for example if SUT needs to &quot;warm up&quot; to best performance within each trial.
Not commonly seen in practice.</t>

</section>
</section>
</section>
</section>
<section anchor="iana-considerations"><name>IANA Considerations</name>

<t>This document does not make any request to IANA.</t>

</section>
<section anchor="security-considerations"><name>Security Considerations</name>

<t>Benchmarking activities as described in this memo are limited to
technology characterization of a DUT/SUT using controlled stimuli in a
laboratory environment, with dedicated address space and the constraints
specified in the sections above.</t>

<t>The benchmarking network topology will be an independent test setup and
MUST NOT be connected to devices that may forward the test traffic into
a production network or misroute traffic to the test management network.</t>

<t>Further, benchmarking is performed on an &quot;opaque&quot; basis, relying
solely on measurements observable external to the DUT/SUT.</t>

<t>The DUT/SUT SHOULD NOT include features that serve only to boost
benchmark scores - such as a dedicated &quot;fast-track&quot; test mode that is
never used in normal operation.</t>

<t>Any implications for network security arising from the DUT/SUT SHOULD be
identical in the lab and in production networks.</t>

</section>
<section anchor="acknowledgements"><name>Acknowledgements</name>

<t>Special wholehearted gratitude and thanks to the late Al Morton for his
thorough reviews filled with very specific feedback and constructive
guidelines. Thank You Al for the close collaboration over the years, Your Mentorship,
Your continuous unwavering encouragement full of empathy and energizing
positive attitude. Al, You are dearly missed.</t>

<t>Thanks to Gabor Lencse, Giuseppe Fioccola and BMWG contributors for good
discussions and thorough reviews, guiding and helping us to improve the
clarity and formality of this document.</t>

<t>Many thanks to Alec Hothan of the OPNFV NFVbench project for a thorough
review and numerous useful comments and suggestions in the earlier
versions of this document.</t>

</section>


  </middle>

  <back>


<references title='References' anchor="sec-combined-references">

    <references title='Normative References' anchor="sec-normative-references">

&RFC1242;
&RFC2119;
&RFC2285;
&RFC2544;
&RFC8174;


    </references>

    <references title='Informative References' anchor="sec-informative-references">

&RFC5180;
&RFC6349;
&RFC6985;
&RFC8219;
<reference anchor="TST009" target="https://www.etsi.org/deliver/etsi_gs/NFV-TST/001_099/009/03.04.01_60/gs_NFV-TST009v030401p.pdf">
  <front>
    <title>TST 009</title>
    <author >
      <organization></organization>
    </author>
    <date year="n.d."/>
  </front>
</reference>
<reference anchor="Y.1564" target="https://www.itu.int/rec/dologin_pub.asp?lang=e&amp;id=T-REC-Y.1564-201602-I!!PDF-E&amp;type=items">
  <front>
    <title>Y.1564</title>
    <author >
      <organization></organization>
    </author>
    <date year="n.d."/>
  </front>
</reference>
<reference anchor="FDio-CSIT-MLRsearch" target="https://csit.fd.io/cdocs/methodology/measurements/data_plane_throughput/mlr_search/">
  <front>
    <title>FD.io CSIT Test Methodology - MLRsearch</title>
    <author >
      <organization></organization>
    </author>
    <date year="2023" month="October"/>
  </front>
</reference>
<reference anchor="PyPI-MLRsearch" target="https://pypi.org/project/MLRsearch/1.2.1/">
  <front>
    <title>MLRsearch 1.2.1, Python Package Index</title>
    <author >
      <organization></organization>
    </author>
    <date year="2023" month="October"/>
  </front>
</reference>
<reference anchor="Lencze-Shima" target="https://datatracker.ietf.org/doc/html/draft-lencse-bmwg-rfc2544-bis-00">
  <front>
    <title>An Upgrade to Benchmarking Methodology for Network Interconnect Devices - expired</title>
    <author >
      <organization></organization>
    </author>
    <date year="n.d."/>
  </front>
</reference>
<reference anchor="Lencze-Kovacs-Shima" target="http://dx.doi.org/10.11601/ijates.v9i2.288">
  <front>
    <title>Gaming with the Throughput and the Latency Benchmarking Measurement Procedures of RFC 2544</title>
    <author >
      <organization></organization>
    </author>
    <date year="n.d."/>
  </front>
</reference>
<reference anchor="Ott-Mathis-Semke-Mahdavi" target="https://www.cs.cornell.edu/people/egs/cornellonly/syslunch/fall02/ott.pdf">
  <front>
    <title>The Macroscopic Behavior of the TCP Congestion Avoidance Algorithm</title>
    <author >
      <organization></organization>
    </author>
    <date year="n.d."/>
  </front>
</reference>
<reference anchor="Vassilev" target="https://datatracker.ietf.org/doc/draft-ietf-bmwg-network-tester-cfg/06">
  <front>
    <title>A YANG Data Model for Network Tester Management</title>
    <author >
      <organization></organization>
    </author>
    <date year="n.d."/>
  </front>
</reference>


    </references>

</references>


<?line 2708?>

<section anchor="load-classification-code"><name>Load Classification Code</name>

<t>This appendix specifies how to perform the Load Classification.</t>

<t>Any Trial Load value can be classified,
according to a given <xref target="search-goal">Search Goal</xref> instance.</t>

<t>The algorithm uses (some subsets of) the set of all available Trial Results
from Trials measured at a given Load at the end of the Search.</t>

<t>The block at the end of this appendix holds pseudocode
which computes two values, stored in variables named
<spanx style="verb">optimistic_is_lower</spanx> and <spanx style="verb">pessimistic_is_lower</spanx>.</t>

<t>Although presented as pseudocode, the listing is syntactically valid
Python and can be executed without modification.</t>

<t>If values of both variables are computed to be true, the Load in question
is classified as a Lower Bound according to the given Search Goal instance.
If values of both variables are false, the Load is classified as an Upper Bound.
Otherwise, the load is classified as Undecided.</t>

<t>Some variable names are shortened to fit expressions in one line.
Namely, variables holding sum quantities end in <spanx style="verb">_s</spanx> instead of <spanx style="verb">_sum</spanx>,
and variables holding effective quantities start in <spanx style="verb">effect_</spanx>
instead of <spanx style="verb">effective_</spanx>.</t>

<t>The pseudocode expects the following variables to hold the following values:</t>

<t><list style="symbols">
  <t><spanx style="verb">goal_duration_s</spanx>: The Goal Duration Sum value of the given Search Goal.</t>
  <t><spanx style="verb">goal_exceed_ratio</spanx>: The Goal Exceed Ratio value of the given Search Goal.</t>
  <t><spanx style="verb">full_length_low_loss_s</spanx>: Sum of Trial Effective Durations across Trials
with Trial Duration at least equal to the Goal Final Trial Duration
and with Trial Loss Ratio not higher than the Goal Loss Ratio
(across Full-Length Low-Loss Trials).</t>
  <t><spanx style="verb">full_length_high_loss_s</spanx>: Sum of Trial Effective Durations across Trials
with Trial Duration at least equal to the Goal Final Trial Duration
and with Trial Loss Ratio higher than the Goal Loss Ratio
(across Full-Length High-Loss Trials).</t>
  <t><spanx style="verb">short_low_loss_s</spanx>: Sum of Trial Effective Durations across Trials
with Trial Duration shorter than the Goal Final Trial Duration
and with Trial Loss Ratio not higher than the Goal Loss Ratio
(across Short Low-Loss Trials).</t>
  <t><spanx style="verb">short_high_loss_s</spanx>: Sum of Trial Effective Durations across Trials
with Trial Duration shorter than the Goal Final Trial Duration
and with Trial Loss Ratio higher than the Goal Loss Ratio
(across Short High-Loss Trials).</t>
</list></t>

<t>The code works correctly also when there are no Trial Results at a given Load.</t>

<figure><sourcecode type="python"><![CDATA[
<CODE BEGINS>
exceed_coefficient = goal_exceed_ratio / (1.0 - goal_exceed_ratio)
balancing_s = short_low_loss_s * exceed_coefficient
positive_excess_s = max(0.0, short_high_loss_s - balancing_s)
effect_high_loss_s = full_length_high_loss_s + positive_excess_s
effect_full_length_s = full_length_low_loss_s + effect_high_loss_s
effect_whole_s = max(effect_full_length_s, goal_duration_s)
quantile_duration_s = effect_whole_s * goal_exceed_ratio
pessimistic_high_loss_s = effect_whole_s - full_length_low_loss_s
pessimistic_is_lower = pessimistic_high_loss_s <= quantile_duration_s
optimistic_is_lower = effect_high_loss_s <= quantile_duration_s
<CODE ENDS>
]]></sourcecode></figure>

</section>
<section anchor="conditional-throughput-code"><name>Conditional Throughput Code</name>

<t>This section specifies an example of how to compute Conditional Throughput,
as referred to in Section <xref target="conditional-throughput">Conditional Throughput</xref>.</t>

<t>Any Load value can be used as the basis for the following computation,
but only the Relevant Lower Bound (at the end of the Search)
leads to the value called the Conditional Throughput for a given Search Goal.</t>

<t>The algorithm uses (some subsets of) the set of all available Trial Results
from Trials measured at a given Load at the end of the Search.</t>

<t>The block at the end of this appendix holds pseudocode
which computes a value stored as variable <spanx style="verb">conditional_throughput</spanx>.</t>

<t>Although presented as pseudocode, the listing is syntactically valid
Python and can be executed without modification.</t>

<t>Some variable names are shortened in order to fit expressions in one line.
Namely, variables holding sum quantities end in <spanx style="verb">_s</spanx> instead of <spanx style="verb">_sum</spanx>,
and variables holding effective quantities start in <spanx style="verb">effect_</spanx>
instead of <spanx style="verb">effective_</spanx>.</t>

<t>The pseudocode expects the following variables to hold the following values:</t>

<t><list style="symbols">
  <t><spanx style="verb">goal_duration_s</spanx>: The Goal Duration Sum value of the given Search Goal.</t>
  <t><spanx style="verb">goal_exceed_ratio</spanx>: The Goal Exceed Ratio value of the given Search Goal.</t>
  <t><spanx style="verb">full_length_low_loss_s</spanx>: Sum of Trial Effective Durations across Trials
with Trial Duration at least equal to the Goal Final Trial Duration
and with Trial Loss Ratio not higher than the Goal Loss Ratio
(across Full-Length Low-Loss Trials).</t>
  <t><spanx style="verb">full_length_high_loss_s</spanx>: Sum of Trial Effective Durations across Trials
with Trial Duration at least equal to the Goal Final Trial Duration
and with Trial Loss Ratio higher than the Goal Loss Ratio
(across Full-Length High-Loss Trials).</t>
  <t><spanx style="verb">full_length_trials</spanx>: An iterable of all Trial Results from Trials
with Trial Duration at least equal to the Goal Final Trial Duration
(all Full-Length Trials), sorted by increasing Trial Loss Ratio.
One item <spanx style="verb">trial</spanx> is a composite with the following two attributes available:  <list style="symbols">
      <t><spanx style="verb">trial.loss_ratio</spanx>: The Trial Loss Ratio as measured for this Trial.</t>
      <t><spanx style="verb">trial.effect_duration</spanx>: The Trial Effective Duration of this Trial.</t>
    </list></t>
</list></t>

<t>The code works correctly only when there is at least one
Trial Result measured at a given Load.</t>

<figure><sourcecode type="python"><![CDATA[
<CODE BEGINS>
full_length_s = full_length_low_loss_s + full_length_high_loss_s
whole_s = max(goal_duration_s, full_length_s)
remaining = whole_s * (1.0 - goal_exceed_ratio)
quantile_loss_ratio = None
for trial in full_length_trials:
    if quantile_loss_ratio is None or remaining > 0.0:
        quantile_loss_ratio = trial.loss_ratio
        remaining -= trial.effect_duration
    else:
        break
else:
    if remaining > 0.0:
        quantile_loss_ratio = 1.0
conditional_throughput = intended_load * (1.0 - quantile_loss_ratio)
<CODE ENDS>
]]></sourcecode></figure>

</section>
<section anchor="example-search"><name>Example Search</name>

<t>The following example Search is related to
one hypothetical run of a Search test procedure
that has been started with multiple Search Goals.
Several points in time are chosen, to show how the logic works,
with specific sets of Trial Result available.
The trial results themselves are not very realistic, as
the intention is to show several corner cases of the logic.</t>

<t>In all Trials, the Effective Trial Duration is equal to Trial Duration.</t>

<t>Only one Trial Load is in focus, its value is one million frames per second.
Trial Results at other Trial Loads are not mentioned,
as the parts of logic present here do not depend on those.
In practice, Trial Results at other Load values would be present,
e.g., MLRsearch will look for a Lower Bound smaller than any Upper Bound found.</t>

<t>At any given moment, exactly one Search Goal is designated as in focus.
This designation affects only the Trial Duration chosen for new trials;
it does not alter the rest of the decision logic.</t>

<t>An MLRsearch implementation is free to evaluate several goals
simultaneously - the &quot;focus&quot; mechanism is optional and appears here only
to show that a load can still be classified against goals that are not
currently in focus.</t>

<section anchor="example-goals"><name>Example Goals</name>

<t>The following four Search Goal instances are selected for the example Search.
Each goal has a readable name and dense code,
the code is useful to show Search Goal attribute values.</t>

<t>As the variable &quot;exceed coefficient&quot; does not depend on trial results,
it is also precomputed here.</t>

<t>Goal 1:</t>

<figure><artwork><![CDATA[
name: RFC2544
Goal Final Trial Duration: 60s
Goal Duration Sum: 60s
Goal Loss Ratio: 0%
Goal Exceed Ratio: 0%
exceed coefficient: 0% / (100% / 0%) = 0.0
code: 60f60d0l0e
]]></artwork></figure>

<t>Goal 2:</t>

<figure><artwork><![CDATA[
name: TST009
Goal Final Trial Duration: 60s
Goal Duration Sum: 120s
Goal Loss Ratio: 0%
Goal Exceed Ratio: 50%
exceed coefficient: 50% / (100% - 50%) = 1.0
code: 60f120d0l50e
]]></artwork></figure>

<t>Goal 3:</t>

<figure><artwork><![CDATA[
name: 1s final
Goal Final Trial Duration: 1s
Goal Duration Sum: 120s
Goal Loss Ratio: 0.5%
Goal Exceed Ratio: 50%
exceed coefficient: 50% / (100% - 50%) = 1.0
code: 1f120d.5l50e
]]></artwork></figure>

<t>Goal 4:</t>

<figure><artwork><![CDATA[
name: 20% exceed
Goal Final Trial Duration: 60s
Goal Duration Sum: 60s
Goal Loss Ratio: 0.5%
Goal Exceed Ratio: 20%
exceed coefficient: 20% / (100% - 20%) = 0.25
code: 60f60d0.5l20e
]]></artwork></figure>

<t>The first two goals are important for compliance reasons,
the other two cover less frequent cases.</t>

</section>
<section anchor="example-trial-results"><name>Example Trial Results</name>

<t>The following six sets of trial results are selected for the example Search.
The sets are defined as points in time, describing which Trial Results
were added since the previous point.</t>

<t>Each point has a readable name and dense code,
the code is useful to show Trial Output attribute values
and number of times identical results were added.</t>

<t>Point 1:</t>

<figure><artwork><![CDATA[
name: first short good
goal in focus: 1s final (1f120d.5l50e)
added Trial Results: 59 trials, each 1 second and 0% loss
code: 59x1s0l
]]></artwork></figure>

<t>Point 2:</t>

<figure><artwork><![CDATA[
name: first short bad
goal in focus: 1s final (1f120d.5l50e)
added Trial Result: one trial, 1 second, 1% loss
code: 59x1s0l+1x1s1l
]]></artwork></figure>

<t>Point 3:</t>

<figure><artwork><![CDATA[
name: last short bad
goal in focus: 1s final (1f120d.5l50e)
added Trial Results: 59 trials, 1 second each, 1% loss each
code: 59x1s0l+60x1s1l
]]></artwork></figure>

<t>Point 4:</t>

<figure><artwork><![CDATA[
name: last short good
goal in focus: 1s final (1f120d.5l50e)
added Trial Results: one trial 1 second, 0% loss
code: 60x1s0l+60x1s1l
]]></artwork></figure>

<t>Point 5:</t>

<figure><artwork><![CDATA[
name: first long bad
goal in focus: TST009 (60f120d0l50e)
added Trial Results: one trial, 60 seconds, 0.1% loss
code: 60x1s0l+60x1s1l+1x60s.1l
]]></artwork></figure>

<t>Point 6:</t>

<figure><artwork><![CDATA[
name: first long good
goal in focus: TST009 (60f120d0l50e)
added Trial Results: one trial, 60 seconds, 0% loss
code: 60x1s0l+60x1s1l+1x60s.1l+1x60s0l
]]></artwork></figure>

<t>Comments on point in time naming:</t>

<t><list style="symbols">
  <t>When a name contains &quot;short&quot;, it means the added trial
had Trial Duration of 1 second, which is Short Trial for 3 of the Search Goals,
but it is a Full-Length Trial for the &quot;1s final&quot; goal.</t>
  <t>Similarly, &quot;long&quot; in name means the added trial
had Trial Duration of 60 seconds, which is Full-Length Trial for 3 goals
but Long Trial for the &quot;1s final&quot; goal.</t>
  <t>When a name contains &quot;good&quot; it means the added trial is Low-Loss Trial
for all the goals.</t>
  <t>When a name contains &quot;short bad&quot; it means the added trial is High-Loss Trial
for all the goals.</t>
  <t>When a name contains &quot;long bad&quot;, it means the added trial
is a High-Loss Trial for goals &quot;RFC2544&quot; and &quot;TST009&quot;,
but it is a Low-Loss Trial for the two other goals.</t>
</list></t>

</section>
<section anchor="load-classification-computations"><name>Load Classification Computations</name>

<t>This section shows how Load Classification logic is applied
by listing all temporary values at the specific time point.</t>

<section anchor="point-1"><name>Point 1</name>

<t>This is the &quot;first short good&quot; point.
Code for available results is: 59x1s0l</t>

<texttable>
      <ttcol align='left'>Goal name</ttcol>
      <ttcol align='left'>RFC2544</ttcol>
      <ttcol align='left'>TST009</ttcol>
      <ttcol align='left'>1s final</ttcol>
      <ttcol align='left'>20% exceed</ttcol>
      <c>Goal code</c>
      <c>60f60d0l0e</c>
      <c>60f120d0l50e</c>
      <c>1f120d.5l50e</c>
      <c>60f60d0.5l20e</c>
      <c>Full-length high-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Full-length low-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>Short high-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Short low-loss sum</c>
      <c>59s</c>
      <c>59s</c>
      <c>0s</c>
      <c>59s</c>
      <c>Balancing sum</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>14.75s</c>
      <c>Excess sum</c>
      <c>0s</c>
      <c>-59s</c>
      <c>0s</c>
      <c>-14.75s</c>
      <c>Positive excess sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Effective high-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Effective full sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>Effective whole sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>120s</c>
      <c>60s</c>
      <c>Missing sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>61s</c>
      <c>60s</c>
      <c>Pessimistic high-loss sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>61s</c>
      <c>60s</c>
      <c>Optimistic exceed ratio</c>
      <c>0%</c>
      <c>0%</c>
      <c>0%</c>
      <c>0%</c>
      <c>Pessimistic exceed ratio</c>
      <c>100%</c>
      <c>100%</c>
      <c>50.833%</c>
      <c>100%</c>
      <c>Classification Result</c>
      <c>Undecided</c>
      <c>Undecided</c>
      <c>Undecided</c>
      <c>Undecided</c>
</texttable>

<t>This is the last point in time where all goals have this load as Undecided.</t>

</section>
<section anchor="point-2"><name>Point 2</name>

<t>This is the &quot;first short bad&quot; point.
Code for available results is: 59x1s0l+1x1s1l</t>

<texttable>
      <ttcol align='left'>Goal name</ttcol>
      <ttcol align='left'>RFC2544</ttcol>
      <ttcol align='left'>TST009</ttcol>
      <ttcol align='left'>1s final</ttcol>
      <ttcol align='left'>20% exceed</ttcol>
      <c>Goal code</c>
      <c>60f60d0l0e</c>
      <c>60f120d0l50e</c>
      <c>1f120d.5l50e</c>
      <c>60f60d0.5l20e</c>
      <c>Full-length high-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>1s</c>
      <c>0s</c>
      <c>Full-length low-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>Short high-loss sum</c>
      <c>1s</c>
      <c>1s</c>
      <c>0s</c>
      <c>1s</c>
      <c>Short low-loss sum</c>
      <c>59s</c>
      <c>59s</c>
      <c>0s</c>
      <c>59s</c>
      <c>Balancing sum</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>14.75s</c>
      <c>Excess sum</c>
      <c>1s</c>
      <c>-58s</c>
      <c>0s</c>
      <c>-13.75s</c>
      <c>Positive excess sum</c>
      <c>1s</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Effective high-loss sum</c>
      <c>1s</c>
      <c>0s</c>
      <c>1s</c>
      <c>0s</c>
      <c>Effective full sum</c>
      <c>1s</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>Effective whole sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>120s</c>
      <c>60s</c>
      <c>Missing sum</c>
      <c>59s</c>
      <c>120s</c>
      <c>60s</c>
      <c>60s</c>
      <c>Pessimistic high-loss sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>61s</c>
      <c>60s</c>
      <c>Optimistic exceed ratio</c>
      <c>1.667%</c>
      <c>0%</c>
      <c>0.833%</c>
      <c>0%</c>
      <c>Pessimistic exceed ratio</c>
      <c>100%</c>
      <c>100%</c>
      <c>50.833%</c>
      <c>100%</c>
      <c>Classification Result</c>
      <c>Upper Bound</c>
      <c>Undecided</c>
      <c>Undecided</c>
      <c>Undecided</c>
</texttable>

<t>Due to zero Goal Loss Ratio, RFC2544 goal must have mild or strong increase
of exceed probability, so the one lossy trial would be lossy even if measured
at 60 second duration.
Due to zero exceed ratio, one High-Loss Trial is enough to preclude this Load
from becoming a Lower Bound for RFC2544. That is why this Load
is classified as an Upper Bound for RFC2544 this early.</t>

<t>This is an example how significant time can be saved, compared to 60-second trials.</t>

</section>
<section anchor="point-3"><name>Point 3</name>

<t>This is the &quot;last short bad&quot; point.
Code for available trial results is: 59x1s0l+60x1s1l</t>

<texttable>
      <ttcol align='left'>Goal name</ttcol>
      <ttcol align='left'>RFC2544</ttcol>
      <ttcol align='left'>TST009</ttcol>
      <ttcol align='left'>1s final</ttcol>
      <ttcol align='left'>20% exceed</ttcol>
      <c>Goal code</c>
      <c>60f60d0l0e</c>
      <c>60f120d0l50e</c>
      <c>1f120d.5l50e</c>
      <c>60f60d0.5l20e</c>
      <c>Full-length high-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>Full-length low-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>Short high-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Short low-loss sum</c>
      <c>59s</c>
      <c>59s</c>
      <c>0s</c>
      <c>59s</c>
      <c>Balancing sum</c>
      <c>0s</c>
      <c>59s</c>
      <c>0s</c>
      <c>14.75s</c>
      <c>Excess sum</c>
      <c>60s</c>
      <c>1s</c>
      <c>0s</c>
      <c>45.25s</c>
      <c>Positive excess sum</c>
      <c>60s</c>
      <c>1s</c>
      <c>0s</c>
      <c>45.25s</c>
      <c>Effective high-loss sum</c>
      <c>60s</c>
      <c>1s</c>
      <c>60s</c>
      <c>45.25s</c>
      <c>Effective full sum</c>
      <c>60s</c>
      <c>1s</c>
      <c>119s</c>
      <c>45.25s</c>
      <c>Effective whole sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>120s</c>
      <c>60s</c>
      <c>Missing sum</c>
      <c>0s</c>
      <c>119s</c>
      <c>1s</c>
      <c>14.75s</c>
      <c>Pessimistic high-loss sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>61s</c>
      <c>60s</c>
      <c>Optimistic exceed ratio</c>
      <c>100%</c>
      <c>0.833%</c>
      <c>50%</c>
      <c>75.417%</c>
      <c>Pessimistic exceed ratio</c>
      <c>100%</c>
      <c>100%</c>
      <c>50.833%</c>
      <c>100%</c>
      <c>Classification Result</c>
      <c>Upper Bound</c>
      <c>Undecided</c>
      <c>Undecided</c>
      <c>Upper Bound</c>
</texttable>

<t>This is the last point for &quot;1s final&quot; goal to have this Load still Undecided.
Only one 1-second trial is missing within the 120-second Goal Duration Sum,
but its result will decide the classification result.</t>

<t>The &quot;20% exceed&quot; started to classify this load as an Upper Bound
somewhere between points 2 and 3.</t>

</section>
<section anchor="point-4"><name>Point 4</name>

<t>This is the &quot;last short good&quot; point.
Code for available trial results is: 60x1s0l+60x1s1l</t>

<texttable>
      <ttcol align='left'>Goal name</ttcol>
      <ttcol align='left'>RFC2544</ttcol>
      <ttcol align='left'>TST009</ttcol>
      <ttcol align='left'>1s final</ttcol>
      <ttcol align='left'>20% exceed</ttcol>
      <c>Goal code</c>
      <c>60f60d0l0e</c>
      <c>60f120d0l50e</c>
      <c>1f120d.5l50e</c>
      <c>60f60d0.5l20e</c>
      <c>Full-length high-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>Full-length low-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>Short high-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Short low-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Balancing sum</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>15s</c>
      <c>Excess sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>45s</c>
      <c>Positive excess sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>45s</c>
      <c>Effective high-loss sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>45s</c>
      <c>Effective full sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>120s</c>
      <c>45s</c>
      <c>Effective whole sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>120s</c>
      <c>60s</c>
      <c>Missing sum</c>
      <c>0s</c>
      <c>120s</c>
      <c>0s</c>
      <c>15s</c>
      <c>Pessimistic high-loss sum</c>
      <c>60s</c>
      <c>120s</c>
      <c>60s</c>
      <c>60s</c>
      <c>Optimistic exceed ratio</c>
      <c>100%</c>
      <c>0%</c>
      <c>50%</c>
      <c>75%</c>
      <c>Pessimistic exceed ratio</c>
      <c>100%</c>
      <c>100%</c>
      <c>50%</c>
      <c>100%</c>
      <c>Classification Result</c>
      <c>Upper Bound</c>
      <c>Undecided</c>
      <c>Lower Bound</c>
      <c>Upper Bound</c>
</texttable>

<t>The one missing trial for &quot;1s final&quot; was Low-Loss,
half of trial results are Low-Loss which exactly matches 50% exceed ratio.
This shows time savings are not guaranteed.</t>

</section>
<section anchor="point-5"><name>Point 5</name>

<t>This is the &quot;first long bad&quot; point.
Code for available trial results is: 60x1s0l+60x1s1l+1x60s.1l</t>

<texttable>
      <ttcol align='left'>Goal name</ttcol>
      <ttcol align='left'>RFC2544</ttcol>
      <ttcol align='left'>TST009</ttcol>
      <ttcol align='left'>1s final</ttcol>
      <ttcol align='left'>20% exceed</ttcol>
      <c>Goal code</c>
      <c>60f60d0l0e</c>
      <c>60f120d0l50e</c>
      <c>1f120d.5l50e</c>
      <c>60f60d0.5l20e</c>
      <c>Full-length high-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>Full-length low-loss sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>120s</c>
      <c>60s</c>
      <c>Short high-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Short low-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Balancing sum</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>15s</c>
      <c>Excess sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>45s</c>
      <c>Positive excess sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>45s</c>
      <c>Effective high-loss sum</c>
      <c>120s</c>
      <c>60s</c>
      <c>60s</c>
      <c>45s</c>
      <c>Effective full sum</c>
      <c>120s</c>
      <c>60s</c>
      <c>180s</c>
      <c>105s</c>
      <c>Effective whole sum</c>
      <c>120s</c>
      <c>120s</c>
      <c>180s</c>
      <c>105s</c>
      <c>Missing sum</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Pessimistic high-loss sum</c>
      <c>120s</c>
      <c>120s</c>
      <c>60s</c>
      <c>45s</c>
      <c>Optimistic exceed ratio</c>
      <c>100%</c>
      <c>50%</c>
      <c>33.333%</c>
      <c>42.857%</c>
      <c>Pessimistic exceed ratio</c>
      <c>100%</c>
      <c>100%</c>
      <c>33.333%</c>
      <c>42.857%</c>
      <c>Classification Result</c>
      <c>Upper Bound</c>
      <c>Undecided</c>
      <c>Lower Bound</c>
      <c>Lower Bound</c>
</texttable>

<t>As designed for TST009 goal, one Full-Length High-Loss Trial can be tolerated.
120s worth of 1-second trials is not useful, as this is allowed when
Exceed Probability does not depend on Trial Duration.
As Goal Loss Ratio is zero, it is not possible for 60-second trials
to compensate for losses seen in 1-second results.
But Load Classification logic does not have that knowledge hardcoded,
so optimistic exceed ratio is still only 50%.</t>

<t>But the 0.1% Trial Loss Ratio is lower than &quot;20% exceed&quot; Goal Loss Ratio,
so this unexpected Full-Length Low-Loss trial changed the classification result
of this Load to Lower Bound.</t>

</section>
<section anchor="point-6"><name>Point 6</name>

<t>This is the &quot;first long good&quot; point.
Code for available trial results is: 60x1s0l+60x1s1l+1x60s.1l+1x60s0l</t>

<texttable>
      <ttcol align='left'>Goal name</ttcol>
      <ttcol align='left'>RFC2544</ttcol>
      <ttcol align='left'>TST009</ttcol>
      <ttcol align='left'>1s final</ttcol>
      <ttcol align='left'>20% exceed</ttcol>
      <c>Goal code</c>
      <c>60f60d0l0e</c>
      <c>60f120d0l50e</c>
      <c>1f120d.5l50e</c>
      <c>60f60d0.5l20e</c>
      <c>Full-length high-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>Full-length low-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>180s</c>
      <c>120s</c>
      <c>Short high-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Short low-loss sum</c>
      <c>60s</c>
      <c>60s</c>
      <c>0s</c>
      <c>60s</c>
      <c>Balancing sum</c>
      <c>0s</c>
      <c>60s</c>
      <c>0s</c>
      <c>15s</c>
      <c>Excess sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>45s</c>
      <c>Positive excess sum</c>
      <c>60s</c>
      <c>0s</c>
      <c>0s</c>
      <c>45s</c>
      <c>Effective high-loss sum</c>
      <c>120s</c>
      <c>60s</c>
      <c>60s</c>
      <c>45s</c>
      <c>Effective full sum</c>
      <c>180s</c>
      <c>120s</c>
      <c>240s</c>
      <c>165s</c>
      <c>Effective whole sum</c>
      <c>180s</c>
      <c>120s</c>
      <c>240s</c>
      <c>165s</c>
      <c>Missing sum</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>0s</c>
      <c>Pessimistic high-loss sum</c>
      <c>120s</c>
      <c>60s</c>
      <c>60s</c>
      <c>45s</c>
      <c>Optimistic exceed ratio</c>
      <c>66.667%</c>
      <c>50%</c>
      <c>25%</c>
      <c>27.273%</c>
      <c>Pessimistic exceed ratio</c>
      <c>66.667%</c>
      <c>50%</c>
      <c>25%</c>
      <c>27.273%</c>
      <c>Classification Result</c>
      <c>Upper Bound</c>
      <c>Lower Bound</c>
      <c>Lower Bound</c>
      <c>Lower Bound</c>
</texttable>

<t>This is the Low-Loss Trial the &quot;TST009&quot; goal was waiting for.
This Load is now classified for all goals; the search may end.
Or, more realistically, it can focus on larger load only,
as the three goals will want an Upper Bound (unless this Load is Max Load).</t>

</section>
</section>
<section anchor="conditional-throughput-computations"><name>Conditional Throughput Computations</name>

<t>At the end of this hypothetical search, the &quot;RFC2544&quot; goal labels the
load as an Upper Bound, making it ineligible for Conditional-Throughput
calculations. By contrast, the other three goals treat the same load as
a Lower Bound; if it is also accepted as their Relevant Lower Bound, we
can compute Conditional-Throughput values for each of them.</t>

<t>(The load under discussion is 1 000 000 frames per second.)</t>

<section anchor="goal-2"><name>Goal 2</name>

<t>The Conditional Throughput is computed from sorted list
of Full-Length Trial results. As TST009 Goal Final Trial Duration is 60 seconds,
only two of 122 Trials are considered Full-Length Trials.
One has Trial Loss Ratio of 0%, the other of 0.1%.</t>

<t><list style="symbols">
  <t>Full-length high-loss sum is 60 seconds.</t>
  <t>Full-length low-loss sum is 60 seconds.</t>
  <t>Full-length is 120 seconds.</t>
  <t>Subceed ratio is 50%.</t>
  <t>Remaining sum initially is 0.5x12s = 60 seconds.</t>
  <t>Current loss ratio initially is 100%.</t>
  <t>For first result (duration 60s, loss 0%):
  <list style="symbols">
      <t>Remaining sum is larger than zero, not exiting the loop.</t>
      <t>Set current loss ratio to this trial&#39;s Trial Loss Ratio which is 0%.</t>
      <t>Decrease the remaining sum by this trial&#39;s Trial Effective Duration.</t>
      <t>New remaining sum is 60s - 60s = 0s.</t>
    </list></t>
  <t>For second result (duration 60s, loss 0.1%):</t>
  <t>Remaining sum is not larger than zero, exiting the loop.</t>
  <t>Current forwarding ratio was most recently set to 0%.</t>
  <t>Current forwarding ratio is one minus the current loss ratio, so 100%.</t>
  <t>Conditional Throughput is the current forwarding ratio multiplied by the Load value.</t>
  <t>Conditional Throughput is one million frames per second.</t>
</list></t>

</section>
<section anchor="goal-3"><name>Goal 3</name>

<t>The &quot;1s final&quot; has Goal Final Trial Duration of 1 second,
so all 122 Trial Results are considered Full-Length Trials.
They are ordered like this:</t>

<figure><artwork><![CDATA[
60 1-second 0% loss trials,
1 60-second 0% loss trial,
1 60-second 0.1% loss trial,
60 1-second 1% loss trials.
]]></artwork></figure>

<t>The result does not depend on the order of 0% loss trials.</t>

<t><list style="symbols">
  <t>Full-length high-loss sum is 60 seconds.</t>
  <t>Full-length low-loss sum is 180 seconds.</t>
  <t>Full-length is 240 seconds.</t>
  <t>Subceed ratio is 50%.</t>
  <t>Remaining sum initially is 0.5x240s = 120 seconds.</t>
  <t>Current loss ratio initially is 100%.</t>
  <t>For first 61 results (duration varies, loss 0%):
  <list style="symbols">
      <t>Remaining sum is larger than zero, not exiting the loop.</t>
      <t>Set current loss ratio to this trial&#39;s Trial Loss Ratio which is 0%.</t>
      <t>Decrease the remaining sum by this trial&#39;s Trial Effective Duration.</t>
      <t>New remaining sum varies.</t>
    </list></t>
  <t>After 61 trials, duration of 60x1s + 1x60s has been subtracted from 120s, leaving 0s.</t>
  <t>For 62-th result (duration 60s, loss 0.1%):
  <list style="symbols">
      <t>Remaining sum is not larger than zero, exiting the loop.</t>
    </list></t>
  <t>Current forwarding ratio was most recently set to 0%.</t>
  <t>Current forwarding ratio is one minus the current loss ratio, so 100%.</t>
  <t>Conditional Throughput is the current forwarding ratio multiplied by the Load value.</t>
  <t>Conditional Throughput is one million frames per second.</t>
</list></t>

</section>
<section anchor="goal-4"><name>Goal 4</name>

<t>The Conditional Throughput is computed from sorted list
of Full-Length Trial results. As &quot;20% exceed&quot; Goal Final Trial Duration
is 60 seconds, only two of 122 Trials are considered Full-Length Trials.
One has Trial Loss Ratio of 0%, the other of 0.1%.</t>

<t><list style="symbols">
  <t>Full-length high-loss sum is 60 seconds.</t>
  <t>Full-length low-loss sum is 60 seconds.</t>
  <t>Full-length is 120 seconds.</t>
  <t>Subceed ratio is 80%.</t>
  <t>Remaining sum initially is 0.8x120s = 96 seconds.</t>
  <t>Current loss ratio initially is 100%.</t>
  <t>For first result (duration 60s, loss 0%):
  <list style="symbols">
      <t>Remaining sum is larger than zero, not exiting the loop.</t>
      <t>Set current loss ratio to this trial&#39;s Trial Loss Ratio which is 0%.</t>
      <t>Decrease the remaining sum by this trial&#39;s Trial Effective Duration.</t>
      <t>New remaining sum is 96s - 60s = 36s.</t>
    </list></t>
  <t>For second result (duration 60s, loss 0.1%):
  <list style="symbols">
      <t>Remaining sum is larger than zero, not exiting the loop.</t>
      <t>Set current loss ratio to this trial&#39;s Trial Loss Ratio which is 0.1%.</t>
      <t>Decrease the remaining sum by this trial&#39;s Trial Effective Duration.</t>
      <t>New remaining sum is 36s - 60s = -24s.</t>
    </list></t>
  <t>No more trials (and remaining sum is not larger than zero), exiting loop.</t>
  <t>Current forwarding ratio was most recently set to 0.1%.</t>
  <t>Current forwarding ratio is one minus the current loss ratio, so 99.9%.</t>
  <t>Conditional Throughput is the current forwarding ratio multiplied by the Load value.</t>
  <t>Conditional Throughput is 999 thousand frames per second.</t>
</list></t>

<t>Due to stricter Goal Exceed Ratio, this Conditional Throughput
is smaller than Conditional Throughput of the other two goals.</t>

</section>
</section>
</section>


  </back>

<!-- ##markdown-source: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-->

</rfc>

